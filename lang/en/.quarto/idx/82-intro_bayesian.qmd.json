{"title":"Introduction to Bayesian Inference","markdown":{"headingText":"Introduction to Bayesian Inference","containsRefs":false,"markdown":"\n## Lecture\n\nAmazing beasties and crazy animals\n\n```{r}\n#| echo: false\n#| out-width: 50%\n#| fig-align: center\n#| fig-cap: Dream pet dragon\nknitr::include_graphics(\"images/fun_dragon.jpg\")\n```\n\n\nneed to add stuff here\n\n### Bayes' theorem\n\nFirst, let's review the theorem. Mathematically, it says how to convert one conditional probability into another one.\n\n$$ P(B \\mid A) = \\frac{ P(A \\mid B) * P(B)}{P(A)} $$\n\nThe formula becomes more interesting in the context of statistical modeling. We\nhave some model that describes a data-generating process and we have some\n*observed* data, but we want to estimate some *unknown* model parameters. \nIn that case, the formula reads like:\n\n$$ P(\\text{hypothesis} \\mid \\text{data}) = \\frac{ P(\\text{data} \\mid \\text{hypothesis}) * P(\\text{hypothesis})}{P(\\text{data})} $$\n\nThese terms have conventional names:\n\n$$ \\text{posterior} = \\frac{ \\text{likelihood} * \\text{prior}}{\\text{evidence}} $$\n\n*Prior* and *posterior* describe when information is obtained: what we know pre-data is our\nprior information, and what we learn post-data is the updated information\n(\"posterior\"). \n\nThe *likelihood* in the equation says how likely the data is given the model\nparameters. I think of it as *fit*: How well do the parameters fit the data?\nClassical regression's line of best fit is the maximum likelihood line. The\nlikelihood also encompasses the data-generating process behind the model. For\nexample, if we assume that the observed data is normally distributed, then we\nevaluate the likelihood by using the normal probability density function. You\ndon't need to know what that last sentence means. What's important is that the\nlikelihood contains our built-in assumptions about how the data is distributed.\n\nThe *evidence* (sometimes called *average likelihood*) is hareder to grasp. I am not sure how to describe it in an intuitive way.\nIt's there to make sure the math works out so that the posterior probabilities sum to 1.\nSome presentations of Bayes' theorem gloss over it and I am not the exception `r emoji::emoji(\"smile\")`.\nThe important thing to note is that the posterior is proportional to the\nlikelihood and prior information.\n\n$$ \n\\text{posterior information} \\propto \n  \\text{likelihood of data} * \\text{prior information} \n$$\n\nSo simply put, **you update your prior information in proportion to how well it fits\nthe observed data**. So essentially you are doing that on a daily basis for everything except when you ar doing frequentist stats `r emoji::emoji(\"smile\")`.\n\n\n\n```{r}\n#| eval: false\n#| echo: false\n#| fig-width: 10.5\n#| fig-height: 3.5\n#| out-width: 100%\n#| fig-cap: Bayesian Triptych\n\ndata <- tibble(\n  age = c(38, 45, 52, 61, 80, 74),\n  prop = c(0.146, 0.241, 0.571, 0.745, 0.843, 0.738)\n)\n\ninv_logit <- function(x) 1 / (1 + exp(-x))\n\nmodel_formula <- bf(\n  # Logistic curve\n  prop ~ inv_logit(asymlogit) * inv(1 + exp((mid - age) * exp(scale))),\n  # Each term in the logistic equation gets a linear model\n  asymlogit ~ 1,\n  mid ~ 1,\n  scale ~ 1,\n  # Precision\n  phi ~ 1,\n  # This is a nonlinear Beta regression model\n  nl = TRUE,\n  family = Beta(link = identity)\n)\n\nprior_fixef <- c(\n  # Point of steepest growth is age 4 plus/minus 2 years\n  prior(normal(48, 12), nlpar = \"mid\", coef = \"Intercept\"),\n  prior(normal(1.25, .75), nlpar = \"asymlogit\", coef = \"Intercept\"),\n  prior(normal(-2, 1), nlpar = \"scale\", coef = \"Intercept\")\n)\n\nprior_phi <- c(\n  prior(normal(2, 1), dpar = \"phi\", class = \"Intercept\")\n)\n\nfit_prior <- brm(\n  model_formula,\n  data = data,\n  prior = c(prior_fixef, prior_phi),\n  iter = 2000,\n  chains = 4,\n  sample_prior = \"only\",\n  cores = 1,\n  control = list(adapt_delta = 0.9, max_treedepth = 15)\n)\ndraws_prior <- data %>%\n  tidyr::expand(age = 0:100) %>%\n  tidybayes::add_fitted_draws(fit_prior, n = 300)\n\np1 <- ggplot(draws_prior) +\n  aes(x = age, y = .value) +\n  geom_line(aes(group = .draw), alpha = .2) +\n  theme(\n    axis.ticks = element_blank(),\n    axis.text = element_blank(),\n    axis.title = element_blank()\n  ) +\n  expand_limits(y = 0:1) +\n  ggtitle(\"Plausible curves before seeing data\")\n\nfm1 <- nls(prop ~ SSlogis(age, Asym, xmid, scal), data)\nnew_data <- tibble(age = 0:100) %>%\n  mutate(\n    fit = predict(fm1, newdata = .)\n  )\n\npoint_orange <- \"#FB6542\"\n\np2 <- ggplot(data) +\n  aes(x = age, y = prop) +\n  geom_line(aes(y = fit), data = new_data, size = 1) +\n  geom_point(color = point_orange, size = 2) +\n  theme(\n    axis.ticks = element_blank(),\n    axis.text = element_blank(),\n    axis.title = element_blank()\n  ) +\n  expand_limits(y = 0:1) +\n  expand_limits(x = c(0, 100)) +\n  ggtitle(\"How well do the curves fit the data\")\n\nfit <- brm(\n  model_formula,\n  data = data,\n  prior = c(prior_fixef, prior_phi),\n  iter = 2000,\n  chains = 4,\n  cores = 1,\n  control = list(adapt_delta = 0.9, max_treedepth = 15)\n)\n\ndraws_posterior <- data %>%\n  tidyr::expand(age = 0:100) %>%\n  tidybayes::add_fitted_draws(fit, n = 100)\n\np3 <- ggplot(draws_posterior) +\n  aes(x = age, y = .value) +\n  geom_line(aes(group = .draw), alpha = .2) +\n  geom_point(\n    aes(y = prop),\n    color = point_orange, size = 2,\n    data = data\n  ) +\n  theme(\n    axis.ticks = element_blank(),\n    axis.text = element_blank(),\n    axis.title = element_blank()\n  ) +\n  expand_limits(y = 0:1) +\n  ggtitle(\"Plausible curves after seeing data\")\n\np1 + p2 + p3\nggsave(\"bayestriptic.png\", width = 10.4, height = 5.1)\n```\n\n```{r}\n#| echo: false\n#| out-width: 100%\n#| fig-align: center\n#| fig-cap: Bayesian Triptych\nknitr::include_graphics(\"images/bayestriptic.png\")\n```\n\n::: {.callout-warning}\n\n**A word of encouragement!** The prior is an intimidating part of Bayesian\nstatistics. It seems highly subjective, as though we are pulling numbers from\nthin air, and it can be overwhelming for complex models. But if we are familiar\nwith the kind of data we are modeling, we have prior information. We can have\nthe model simulate new observations using the prior distribution and then\nplot the hypothetical data. Does anything look wrong or implausible about the\nsimulated data? If so, then we have some prior information that we can include\nin our model. Note that we do not evaluate the plausibility of the simulated\ndata based on the data we have in hand (the data we want to model); that's not \n\n:::\n\n\n### Intro to MCMC\n\nWe will now walk through a simple example coded in `R` to illustrate how an MCMC algorithm works.\n\n\nSuppose you are interested in the mean heart rate is of students when asked a question in a stat course. You are not sure what the exact mean value is, but you know the values are normally distributed with a standard deviation of 15. You have observed 5 individuals to have heart rate of `104, 120,160,90,130`. You could use MCMC sampling to draw samples from the target distribution.\nWe need to specify:\n\n1. the starting value for the chain. \n2. the length of the chain. In general, more iterations will give you more accurate output.\n\n\n```{r}\nlibrary(coda)\nlibrary(bayesplot)\nset.seed(170)\nhr_obs <- c(104, 112, 132, 115, 110)\n\nstart_value <- 250\n\nn_iter <- 2500 # define number of iterations\n\npd_mean <- numeric(n_iter) # create vector for sample values\n\npd_mean[1] <- start_value # define starting value\n\nfor (i in 2:n_iter) {\n  proposal <- pd_mean[i - 1] + MASS::mvrnorm(1, 0, 5) # proposal\n  lprop <- sum(dnorm(proposal, hr_obs, 15)) # likelihood of proposed parameter\n  lprev <- sum(dnorm(pd_mean[i - 1], hr_obs, 15))\n  if (lprop / lprev > runif(1)) { # if likelihood of prosposed > likehood previous accept\n    # and if likelihood is lower accept with random noise\n    pd_mean[i] <- proposal\n  } # if true sample the proposal\n  else {\n    (pd_mean[i] <- pd_mean[i - 1])\n  } # if false sample the current value\n}\npd_mean <- as.mcmc(data.frame(mean = pd_mean))\nmcmc_combo(pd_mean, combo = c(\"trace\", \"dens\"))\nsummary(pd_mean)\n```\n\n\n```{r}\nset.seed(170)\nhr_obs <- c(104, 112, 132, 115, 110)\nn_iter <- 2500 # define number of iterations\n\nn_chain <- 3\nstart_value <- c(250, 100, 50)\n\npd_mean <- array(NA, dim = c(n_iter, n_chain, 1), dimnames = list(iter = NULL, chain = NULL, params = \"beta\")) # create vector for sample values\n\nfor (j in seq_len(n_chain)) {\n  pd_mean[1, j, 1] <- start_value[j] # define starting value\n  for (i in 2:n_iter) {\n    proposal <- pd_mean[i - 1, j, 1] + MASS::mvrnorm(1, 0, 5) # proposal\n    if (sum(dnorm(proposal, hr_obs, 15)) # likelihood of proposed parameter\n    / sum(dnorm(pd_mean[i - 1, j, 1], hr_obs, 15)) > runif(1, 0, 1)) {\n      pd_mean[i, j, 1] <- proposal\n    } # if true sample the proposal\n    else {\n      (pd_mean[i, j, 1] <- pd_mean[i - 1, j, 1])\n    } # if false sample the current value\n  }\n}\ncolor_scheme_set(\"mix-blue-red\")\nmcmc_combo(pd_mean, combo = c(\"trace\", \"dens_overlay\"))\nsummary(pd_mean)\n\nmcmc_combo(pd_mean, combo = c(\"trace\", \"dens_overlay\"), n_warmup = 500)\n\npd_burn <- pd_mean[-c(1:500), , , drop = FALSE]\nsummary(pd_burn)\n\nmcmc_combo(pd_burn, combo = c(\"trace\", \"dens_overlay\"), iter1 = 501)\n```\n\n\n### Inferences\n\n#### Fixed effects\n\nEasy peazy lemon squeezy just have a look at the posteriro distribution, does it overlap 0 yes or no.\n\ntalk about mean, median and mode of a distribution as well as credible intervals\n\n#### Random effects\n\nQuite a bit more harder. because constrained to be positive\n\n- Interpreting posterior distribution\n- DIC\n- WAIC\n\n\n## Practical\n\nIn this practical, we will revisit our analysis on unicorn aggressivity.\nHonestly, we can use any other data with repeated measures for this exercise\nbut I just love unicorns `r emoji::emoji(\"heart\")`.\nHowever, instead of fittng the model using `lmer()` from the `lmerTest` \n`r emoji::emoji(\"package\")` [@lmerTest], we will refit the model using 2 excellent \nsoftwares fitting models with a Bayesian approach: `MCMCglmm` [@MCMCglmm] and\n`brms` [@brms2021].\n\n\n### R packages needed\n\nFirst we load required libraries\n```{r}\n#| label: loadlibs_bayes\n#| message: false\n#| results: hide\n#| warning: false\nlibrary(lmerTest)\nlibrary(tidyverse)\nlibrary(rptR)\nlibrary(brms)\nlibrary(MCMCglmm)\nlibrary(bayesplot)\n```\n\n### A refresher on unicorn ecology\n\nThe last model on unicorns was:\n\n```r\naggression ~ opp_size + scale(body_size, center = TRUE, scale = TRUE)\n              + scale(assay_rep, scale = FALSE) + block\n              + (1 | ID)\n```\n\nThose scaled terms are abit a sore for my eyes and way too long if we need to type them multiple times in this practical.\nSo first let's recode them.\n- \n```{r}\nunicorns <- read.csv(\"data/unicorns_aggression.csv\")\nunicorns <- unicorns %>%\n  mutate(\n    body_size_sc = scale(body_size),\n    assay_rep_sc = scale(assay_rep, scale = FALSE)\n  )\n```\n\nOk now we can fit the same model by just using:\n\n```r\naggression ~ opp_size + body_size_sc + assay_rep_sc + block\n              + (1 | ID)\n```\n\nWe can now fit a model using `lmer()`. Since we want to compare a bit `REML` and `Bayesian` aproaches, I am going to wrap the model function in a function called `system.time()`.\nThis function simply estimate the `user` and `computer` time use by the function.\n\n```{r}\nmer_time <- system.time(\n  m_mer <- lmer(\n    aggression ~ opp_size + body_size_sc + assay_rep_sc + block\n      + (1 | ID),\n    data = unicorns\n  )\n)\nmer_time\nsummary(m_mer)\n```\n\nOk so it took no time at all to do it and we got our \"classic\" results.\n\n### MCMCglmm\n\nWhat makes `MCMCglmm` so useful and powerful `r emoji::emoji(\"muscle\")` in ecology and for *practical Bayesian people* is that:\n\n1. it is blazing fast `r emoji::emoji(\"fast\")` (for Bayesian analysis) for some models particularly models with structured covariances\n2. it is fairly intuitive to code\n\n**but** it also has some inconvenients:\n\n1. it is blazing fast for **Bayesian analysis** meaning it is `r emoji::emoji(\"snail\")` compared to *maximum likelihood* approaches\n2. it has some limitations in terms of functionality, distribution availability and model specifications compared to other *Bayesian* softwares\n3. the priors, *oh, the priors* `r emoji::emoji(\"loudly_crying_face\")`, are a bit tricky to code and understand `r emoji::emoji(\"exploding_head\")`.\n\n\n#### Fitting the Model\n\nSo here is how we can code the model in `MCMCglmm()`. It is fairly similar to `lmer()` except that the random effects are specified in a different *argument*.\n\n```{r}\n#| cache: true\nmcglm_time <- system.time(\n  m_mcmcglmm <- MCMCglmm(\n    aggression ~ opp_size + body_size_sc + assay_rep_sc + block,\n    random = ~ID,\n    data = unicorns\n  )\n)\nsummary(m_mcmcglmm)\nmcglm_time\n```\n\nModel is slow and not good. We need more iteration and maybe even a longer burnin, and honestly maybe better priors.\n\nWe can still take the time to have a look at the R object output from `MCMCglmm()`. The 2 main parts we are interrested in are:\n\n- `Sol` which stand for the model solution and includes the posteriro distribution of the fixed effects\n- `VCV`, for the variance covariance estimates, which includes the posterior distribution of all (co)variances estimates for both random effects and residual variance.\n\n```{r}\n#| fig.cap: \"Posterior trace and distribution of the parameters in m_mcmcglmm using default settings\"\n#| warning: false\nomar <- par()\npar(mar = c(4, 2, 1.5, 2))\nplot(m_mcmcglmm$Sol)\nplot(m_mcmcglmm$VCV)\npar(omar)\nautocorr.diag(m_mcmcglmm$VCV)\n```\n\nTalk about autocorrelation, mixing, convergence and priors here\n```{r}\n#| cache: true\nn_samp <- 1000\nthin <- 500\nburnin <- 20000\nmcglm_time <- system.time(\n  m_mcmcglmm <- MCMCglmm(\n    aggression ~ opp_size + body_size_sc + assay_rep_sc + block,\n    random = ~ID,\n    data = unicorns,\n    nitt = n_samp * thin + burnin, thin = thin, burnin = burnin,\n    verbose = FALSE,\n    prior = list(\n      R = list(V = 1, nu = 0.002),\n      G = list(\n        G1 = list(V = 1, nu = 0.002)\n      )\n    )\n  )\n)\nsummary(m_mcmcglmm)\nmcglm_time\n```\n evaluate model here\n```{r}\n#| fig.cap: \"Posterior trace and distribution of the paremeters in m_mcmcglmm with better settings\"\n#| warning: false\nomar <- par()\npar(mar = c(4, 2, 1.5, 2))\nplot(m_mcmcglmm$Sol)\nplot(m_mcmcglmm$VCV)\npar(omar)\nautocorr.diag(m_mcmcglmm$VCV)\n```\n\n### Inferences\n\n#### Fixed effects\n\nEasy peazy lemon squeezy just have a look at the posterior distribution, does it overlap 0 yes or no.\n\n```{r}\nposterior.mode(m_mcmcglmm$Sol)\nHPDinterval(m_mcmcglmm$Sol)\n```\n\n#### Random effects\n\nQuite a bit more harder. because constrained to be positive\n\n```{r}\nposterior.mode(m_mcmcglmm$VCV)\nHPDinterval(m_mcmcglmm$VCV)\n```\n\n### brms\n\n**brms** is an acronym for *Bayesian Regression Models using 'Stan'* [@brms2021]. It is a package developed to fit regression models with a Bayesian approach using the amazing `stan` software [@stan2021]. \n\nWhat makes `brms` so useful and powerful `r emoji::emoji(\"muscle\")` in ecology is that:\n\n1. it is really intuitive to code (same syntax as `glmer()`)\n2. it is incredibly flexible since it is essentially a front end for `stan` via its `rstan` interface [@rstan]\n\n**but** with *great powers come great responsability* `r emoji::emoji(\"spider\")`\n\n\n```{r}\n#| cache: true\n#| fig-cap: Autocorrelation in the chain for variance parameters in model m_brm\nbrm_time <- system.time(\n  m_brm <- brm(\n    aggression ~ opp_size + body_size_sc + assay_rep_sc + block\n      + (1 | ID),\n    data = unicorns, iter = 4750, warmup = 1000, thin = 15, cores = 4\n    # refresh = 0\n  )\n)\nbrm_time\nsummary(m_brm)\nmcmc_acf_bar(m_brm, regex_pars = c(\"sd\"))\n```\n\n#### Hunder the hood \nhave a look at the `stan` code\n\n```{r}\nstancode(m_brm)\n```\n\n#### using shiny\n\n\n```{r}\n#| eval: false\nlaunch_shinystan(m_brm)\n```\n```{r}\n#| echo: false\n#| out-width: 50%\n#| fig-align: center\n#| fig-cap: Shinystan interface\nknitr::include_graphics(\"images/shinystan.png\")\n```\n\n### Inferences\n\n#### Fixed effects\n\n```{r}\n#| fig-cap: Fixed effect estimates (with 95% credible intervals) from model m_brm\nsummary(m_brm)\nmcmc_plot(m_brm, regex_pars = \"b_\")\n```\n\n#### Random effects\n\n```{r}\n#| fig-cap: Among-individual and residual standard deviance ( with 95% credible intervals)\n#|   estimated from model m_brm\nsummary(m_brm)\nmcmc_plot(m_brm, pars = c(\"sd_ID__Intercept\", \"sigma\"))\n```\n\n\n### Happy Bayesian stats\n\n```{r}\n#| echo: false\n#| out-width: 50%\n#| fig-align: center\n#| fig-cap: Sherlock Holmes, a truly bayesian detective\nknitr::include_graphics(\"images/sherlock.jpg\")\n```\n\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":true,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","from":"markdown+emoji","number-sections":true,"output-file":"82-intro_bayesian.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en-CA","fig-responsive":true,"quarto-version":"1.5.45","version":"0.6.0","year":2024,"bibliography":["biblio/book.bib","biblio/grateful-refs.bib"],"biblio-style":"apalike","csl":"biblio/ecology.csl","params":{"echo_sol":true,"longrun":false,"html_pdf":true},"cit-title":"Do what you think is interesting,  \ndo something that you think is fun and worthwhile,  \nbecause otherwise you won’t do it well anyway.\n","cit-author":"Brian W. Kernighan","theme":{"light":"cosmo","dark":["cosmo","css/theme-dark.scss"]},"author-meta":"Julien Martin"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"paged","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"lualatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","from":"markdown+emoji","number-sections":true,"output-file":"82-intro_bayesian.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"block-headings":false,"version":"0.6.0","year":2024,"bibliography":["biblio/book.bib","biblio/grateful-refs.bib"],"biblio-style":"apalike","csl":"biblio/ecology.csl","params":{"echo_sol":true,"longrun":false,"html_pdf":true},"lang":"en-CA","cit-title":"Do what you think is interesting,  \ndo something that you think is fun and worthwhile,  \nbecause otherwise you won’t do it well anyway.\n","cit-author":"Brian W. Kernighan","documentclass":"scrreprt","classoption":["chapterprefix=true","headings=big","twoside=semi"],"papersize":"letter","fontsize":"11pt","geometry":["top=2cm","bottom=2cm","left=2cm","right=2cm","footskip=1cm"],"colorlinks":true,"linestretch":1.5,"template-partials":["latex/before-title.tex","latex/before-body.tex"]},"extensions":{"book":{"selfContainedOutput":true}}},"epub":{"identifier":{"display-name":"ePub","target-format":"epub","base-format":"epub"},"execute":{"fig-width":5,"fig-height":4,"fig-format":"png","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"epub","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":false,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"default-image-extension":"png","html-math-method":"mathml","to":"epub","from":"markdown+emoji","toc":true,"output-file":"82-intro_bayesian.epub"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"version":"0.6.0","year":2024,"bibliography":["biblio/book.bib","biblio/grateful-refs.bib"],"biblio-style":"apalike","csl":"biblio/ecology.csl","params":{"echo_sol":true,"longrun":false,"html_pdf":true},"lang":"en-CA","cit-title":"Do what you think is interesting,  \ndo something that you think is fun and worthwhile,  \nbecause otherwise you won’t do it well anyway.\n","cit-author":"Brian W. Kernighan","dev":"svglite","stylesheet":"css/epub.css"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf","epub"]}