{"title":"Introduction to linear mixed models","markdown":{"headingText":"Introduction to linear mixed models","containsRefs":false,"markdown":"\n## Lecture\n\n### Testing fixed effects\n\nmaking a note that LRT on fixed effects should not be the preferred method and more inportantly should eb done using ML and not REML Fitsee pinheiro & Bates \n2000 p76\n\n### Shrinkage\n\n\n```{r}\n#| label: setup_shrin\n#| include: false\noptions(gganimate.dev_args = list(\n  width = 600,\n  height = 450\n))\nlibrary(tidyverse)\n```\n\nThe following is an example of **shrinkage**, sometimes called **partial-pooling**, as it occurs in **mixed effects models**.\n <!-- For some background, one can see the section of my document on mixed models [here](https://m-clark.github.io/mixed-models-with-R/random_slopes.html#comparison-to-many-regressions), and the document in general for an introduction to mixed models.  Part of the inspiration of this document comes from some of the visuals seen [here](https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/). -->\n\nIt is often the case that we have data such that observations are clustered in some way (e.g. repeated observations for units over time, students within schools, etc.).  In mixed models, we obtain cluster-specific effects in addition to those for standard coefficients of our regression model. The former are called **random effects**, while the latter are typically referred to as **fixed effects** or **population-average** effects.\n\nIn other circumstances, we could ignore the clustering, and run a basic regression model.  Unfortunately this assumes that all observations behave in the same way, i.e. that there are no cluster-specific effects, which would often be an untenable assumption.  Another approach would be to run separate models for each cluster.  However, aside from being problematic due to potentially small cluster sizes in common data settings, this ignores the fact that clusters are not isolated and potentially have some commonality.\n\nMixed models provide an alternative where we have cluster specific effects, but 'borrow strength' from the population-average effects.  In general, this borrowing is more apparent for what would otherwise be more extreme clusters, and those that have less data.  The following will demonstrate how shrinkage arises in different data situations.\n\n#### Analysis\n\nFor the following we run a basic mixed model with a random intercept and random slopes for a single predictor variable. There are a number of ways  to write such models, and the following does so for a single cluster $c$ and observation $i$. $y$ is a function of the covariate $x$, and otherwise we have a basic linear regression model.  In this formulation, the random effects for a given cluster ($u_{* c}$) are added to each fixed effect (intercept $b_0$ and the effect of $x$, $b_1$). The random effects are multivariate normally distributed with some covariance.  The per observation noise $\\sigma$ is assumed constant across observations.\n\n$$\\mu_{ic} = (b_0 + \\mathrm{u}_{0c})+ (b_1+\\mathrm{u}_{1c}) * x_{ic}$$\n$$\\mathrm{u}_{0}, \\mathrm{u}_{1} \\sim \\mathcal{N}(0, \\Sigma)$$\n$$y \\sim \\mathcal{N}(\\mu, \\sigma^2)$$\n\nSuch models are highly flexible and have many extensions, but this simple model is enough for our purposes.\n\n\n#### Data\n\nDefault settings for data creation are as follows:\n\n- `obs_per_cluster` (observations per cluster) = 10\n- `n_cluster` (number of clusters) = 100\n- `intercept` (intercept) = 1\n- `beta` (coefficient for x) = .5\n- `sigma` (observation level standard deviation) = 1\n- `sd_int` (standard deviation for intercept random effect)= .5\n- `sd_slope` (standard deviation for x random effect)= .25\n- `cor` (correlation of random effect) = 0\n- `balanced` (fraction of overall sample size) = 1\n- `seed` (for reproducibility) = 1024\n\nIn this setting, $x$ is a standardized variable with mean zero and standard deviation of 1. Unless a fraction is provided for `balanced`, the $N$, i.e. the total sample size, is equal to `n_cluster` * `obs_per_cluster`. The following is the function that will be used to create the data, which tries to  follow the model depiction above. It requires the tidyverse package to work.\n\n```{r}\n#| label: create_data\n#| echo: false\n#| eval: true\ncreate_data <- function(\n                        obs_per_cluster = 10,\n                        n_cluster = 100,\n                        intercept = 1,\n                        beta = .5,\n                        sigma = 1,\n                        sd_int = .5,\n                        sd_slope = .25,\n                        cor = 0,\n                        balanced = 1,\n                        seed = 888) {\n  set.seed(seed)\n\n  cluster <- rep(1:n_cluster, each = obs_per_cluster)\n  N <- n_cluster * obs_per_cluster\n  x <- rnorm(N)\n\n  varmat <- matrix(c(sd_int^2, cor, cor, sd_slope^2), 2, 2)\n\n  u <- mvtnorm::rmvnorm(n_cluster, sigma = varmat)\n  colnames(u) <- c(\"Intercept\", \"x\")\n\n  y <- (intercept + u[cluster, \"Intercept\"]) + (beta + u[cluster, \"x\"]) * x +\n    rnorm(N, sd = sigma)\n\n  df <- data.frame(\n    y,\n    x,\n    cluster\n  )\n\n  if (balanced < 0 | balanced > 1) {\n    stop(\"Balanced should be a proportion to sample.\")\n  } else {\n    df <- slice_sample(df, prop = balanced)\n  }\n\n  df\n}\n```\n\n\n```{r}\n#| label: create_plot_data\n#| echo: false\n#| eval: false\ncreate_plot_data <- function(model, data = df) {\n  # bind re + lm by group results\n  plot_data_re_lm <-\n    bind_rows(\n      coef(mod)$cluster %>%\n        rownames_to_column(var = \"cluster\") %>%\n        mutate(Model = \"mixed\"),\n      map_df(lmList(y ~ x | cluster, data),\n        function(x) as.data.frame(t(coef(x))),\n        .id = \"cluster\"\n      ) %>%\n        mutate(Model = \"by-cluster\")\n    ) %>%\n    rename(Intercept = `(Intercept)`)\n\n  # fixed effect estimates\n  fe_data <- fixef(mod) %>%\n    t() %>%\n    data.frame() %>%\n    rename(Intercept = X.Intercept.) %>%\n    mutate(\n      cluster = 1,\n      Model = \"by-cluster\"\n    )\n\n  list(\n    coefficients = plot_data_re_lm,\n    fixed_effects = fe_data\n  )\n}\n```\n\n\n#### Run the baseline model\n\nWe will use **lme4** to run the analysis.  We can see that the model recovers the parameters fairly well, even with the default of only 1000 observations.\n\n```{r}\n#| label: run_baseline_model\n#| eval: true\ndf <- create_data()\n\nlibrary(lme4)\nmod <- lmer(y ~ x + (x | cluster), df)\nsummary(mod, cor = F)\n```\n\n<!-- put data creating and plotting fucntion in a file to be sourced.\nstart with variance in intercept only then variance in both slope and intercept, then unbalanced sample -->\n\n\n#### Visualize the baseline model\n\nNow it is time to visualize the results.  We will use **gganimate** to bring the shrinkage into focus.  We start with the estimates that would be obtained by a 'regression-by-cluster' approach or a linear regression for each cluster.  The movement shown will be of those cluster-specific estimates toward the mixed model estimates.  On the x axis is the estimate for the intercepts, on the y axis are the estimated slopes of the `x` covariate.\n\n```{r}\n#| label: vis_baseline_model\n#| echo: false\n#| eval: !expr F\nplot_data <- create_plot_data(model = mod)\nplot_fun(\n  plot_data = plot_data,\n  end_pause = 30,\n  duration = 12,\n  nframes = 120\n)\n\nanim_save(\"images/shrinkage/baseline.gif\")\n\nplot_fun(plot_data = plot_data, animate = F)\nggsave(\"images/shrinkage/baseline_static.png\")\n```\n\n```{r}\n#| label: baseline_gif\n#| echo: !expr F\n#| eval: !expr T\n#| cache: false\n#| dev-args: !expr list(bg = \"transparent\")\nif (knitr::is_html_output(excludes = \"epub\")) {\n  knitr::include_graphics(\"images/shrinkage_1.gif\")\n} else {\n  knitr::include_graphics(\"images/shrinkage_1_static.png\")\n}\n```\n\n\nWe see more clearly what the mixed model does.  The general result  is that cluster-specific effects (lighter color) are shrunk back toward the population-average effects (the 'black hole'), as the imposed normal distribution for the random effects makes the extreme values less probable. Likewise, those more extreme cluster-specific effects, some of which are not displayed as they are so far from the population average, will generally have the most shrinkage imposed.  In terms of prediction, it is akin to introducing bias for the cluster specific effects while lowering variance for prediction of new data, and allows us to make predictions on new categories we have not previously seen - we just assume an 'average' cluster effect, i.e. a random effect of 0.\n\n\n#### Summary\n\nMixed models incorporate some amount of shrinkage for cluster-specific effects.  Data nuances will determine the relative amount of 'strength borrowed', but in general, such models provide a good way for the data to speak for itself when it should, and reflect an 'average' when there is little information.  An additional benefit is that thinking about models in this way can be seen as a precursor to Bayesian approaches, which can allow for even more flexibility via priors, and more control over how shrinkage is added to the model.\n\n<!--\n#################################################################################################################\n-->\n\n## Practical\n\n### Overview\nThis practical is intended to get you started fitting some simple mixed models with so called *random intercepts*. The tutorial is derived from one that accompanied the paper [@houslay_avoiding_2017], \"[Avoiding the misuse of BLUP in behavioral ecology](https://doi.org/10.1093/beheco/arx023)\". Here, you will be working through  a simplified version in which I have taken more time to cover the basic mixed models and don't cover  multivariate models which were really the main point of that paper. So if you find this material interesting don't worry we will go through a more advanced version of the original paper on multivariate models in [chapter XX](#to_be_written). The original version will be worth a work through to help you break into multivariate mixed models anyway! Here we will:\n\n* Learn how to fit - and interpret the results of - a simple univariate mixed effect model\n* See how to add fixed and random effects to your model, and to test their significance in the normal frequentists sense\n\n<!-- * Use random regression or random slope models as extensions of the simple mixed model. We will do this in a hypothetical investigation of  behavioural plasticity, adopting a 'reaction norm perspective' and asking whether individuals differ in phenotypic plasticity (a phenomenon sometimes called IxE)\n * Try and flag some common pitfalls with random regression models, and in particular show you why you need to be careful interpreting effect sizes and why you need to think a bit about if (and how) to scale and centre covariates.\n * Finally, as a lead in why you really should learn about multivariate models after this, we will highlight how character state views of plasticity are really just approximations of multivariate 'character state' approaches. This is a bit mind blowing at first, but once you understand you will start to see just how far the rabbit hole goes...\n -->\n\nWe are going to use the `r emoji::emoji(\"package\")` `lme4` [@lme4] which is widely used and great for simple mixed models. However, since, for philosophical reasons, `lme4` does not provide any p-values for either fixed or random effects, we are going to use the `r emoji::emoji(\"package\")` `lmerTest` [@lmerTest], which add a bunch a nice goodies to `lme4`  For slightly more complex models, including multivariate ones, generalised models, and random effects of things like shared space, pedigree, phylogeny I tend to use different `r emoji::emoji(\"package\")` like `MCMCglmm` [@MCMCglmm] (which is Bayesian, look at Jarrod Hadfield's excellent course notes [@MCMCglmm]) or ASReml-R [@asreml] (which is likelihood based/frequentist but sadly is not free).\n\n\n<!-- Further data sets and tutorials written by Tom can be found at [https://tomhouslay.com/tutorials/](https://tomhouslay.com/tutorials/). -->\n\n### R packages needed\n\nFirst we load required libraries\n```{r}\n#| label: loadlibs\n#| message: false\n#| results: hide\n#| warning: false\n\nlibrary(lmerTest)\nlibrary(performance)\nlibrary(tidyverse)\nlibrary(rptR)\n\n```\n\n### The superb wild unicorns of the Scottish Highlands\n\nUnicorns, a legendary animal and also symbol or Scotland, are frequently described as extremely wild woodland creature but also a symbol of purity and grace. Here is one of most accurate representation of the lengendary animal.\n\n```{r}\n#| echo: false\n#| out-width: 50%\n#| fig-align: center\n#| fig-cap: The superb unicorn of the Scottish Highlands\nknitr::include_graphics(\"images/unicorn.png\")\n```\n\n\nDespite their image of purity and grace, unicorns (*Unicornus legendaricus*) are raging fighter when it comes to compete for the best sweets you can find at the bottom of rainbows (unicorn favourite source of food).\n\nWe want to know:\n\n* If aggressiveness differs among individuals\n* If aggressive behaviour is plastic (change with the environment)\n* If aggressive behaviour depends on body condition of focal animal\n<!-- * If individuals differ in their plasticity -->\n\nWith respect to plasticity, we will focus on rival size as an 'environment'. Common sense, and animal-contest theory, suggest a small animal would be wise not to escalate an aggressive contest against a larger, stronger rival. However, there are reports in the legendary beasty literature that they get more aggressive as rival size increases. Those reports are based on small sample sizes and uncontrolled field observations by foreigners Munro baggers enjoying their whisky after a long day in the hills.\n\n#### Experimental design \n\nHere, we have measured aggression in a population of wild unicorns. We brought some (n=80) individual into the lab, tagged them so they were individually identifiable, then repeatedly observed their aggression when presented with  model 'intruders' (animal care committe approved). There were three models; one of average unicorn (calculated as the population mean body length), one that was build to be 1 standard deviation below the population mean, and one that was 1 standard deviation above.\n\nData were collected on all individuals in two block of lab work. Within each block, each animal was tested 3 times, once against an 'intruder' of each size. The test order in which each animal experienced the three instruder sizes was randomised in each block. The body size of all focal individuals was measured at the beginning of each block so we know that too (and have two separate measures per individual).\n\n#### looking at the data\n\nLet's load the data file `unicorns_aggression.csv` in a R object named `unicorns` and make sure we understand what it contains\n\n::: {.callout-tip collapse='true'}\n\n# Solution\n\n```{r}\n#| label: load_data_aggr\n#| message: false\n#| results: hide\n#| warning: false\n\nunicorns <- read.csv(\"data/unicorns_aggression.csv\")\n```\n\nYou can use `summary(unicorns)` to get an overview of the data and/or `str(unicorns)` to see the structure in the first few lines. This data frame has 6 variables:\n\n```{r}\nstr(unicorns)\nsummary(unicorns)\n```\n\n:::\n\nSo the different columns in the data set are:\n\n* Individual __ID__\n* Experimental __Block__, denoted for now as a continuous variable with possible values of -0.5 (first block) or +0.5 (second block)\n* Individual __body_size__, as measured at the start of each block in kg\n* The repeat number for each behavioural test, __assay_rep__\n* Opponent size (__opp_size__), in standard deviations from the mean (i.e., -1,0,1)\n* __aggression__, our behavioural trait, measured 6 times in total per individual (2 blocks of 3 tests)\n\n\n*maybe add something on how to look at data structure closely using tables*\n\n### Do unicorns differ in aggressiveness? Your first mixed model\n\nFit a first mixed model with `lmer` that have only individual identity as a random effect and only a population mean.\n\nWhy, so simple? Because we simply want to partition variance around the mean into a component that among-individual variance and one that is within-individual variance.\n\n::: {.callout-important}\n\nWe are going to use the function `lmer()` from the  `r emoji::emoji(\"package\")` `lme4` package. The notation of the model formula is similar as the notation for a linear model but now we also add random effects using the notation `(1 | r_effect)` which indicates that we want to fit the variable `r_effect` as a random effect for the intercept. Thus, in lmer notation a simploe model would be :\n\n`lmer(Y ~ x1 + x2 + (1 | r_effect), data = data)`\n\n:::\n\n::: {.callout-tip collapse='true'}\n\n# Solution\n\nA sensible researcher would probably take the time to do some exploratory data plots here. So let's write a mixed model. This one is going to have no fixed effects except the mean, and just one random effect - individual identity.\n\n```{r}\n#| label: mod1\n\nm_1 <- lmer(aggression ~ 1 + (1 | ID), data = unicorns)\n```\n\nThere is a warning... something about \"singularities\". Ignore that for a moment. \n\n:::\n\nNow you need to get the model output. By that I just mean use `summary(model_name)`.\n\n::: {.callout-tip collapse='true'}\n\n# Solution\n\n```{r}\n#| label: mod1_summary\n\nsummary(m_1)\n```\n:::\n\n\nIn the summary you will  find a table of fixed effects. \n\n```\nFixed effects:\n             Estimate Std. Error        df t value Pr(>|t|)    \n(Intercept)   9.00181    0.05272 479.00000   170.7   <2e-16 ***\n```\n\nThe intercept (here the mean) is about 9 and is significantly >0 - fine, but not very interesting to us.\n\nYou will also find a random effect table that contains estimates of the among individual (ID) and residual variances. \n\n```\nRandom effects:\n Groups   Name        Variance Std.Dev.\n ID       (Intercept) 0.000    0.000   \n Residual             1.334    1.155   \nNumber of obs: 480, groups:  ID, 80\n```\n\nThe among individual (ID) is estimated as zero. In fact this is what the cryptic warning was about: in most situations the idea of a random effect explaining less than zero variance is not sensible (strangely there are exception!).  So by default the variance estimates are constrained to lie in positive parameter space. Here in trying to find the maximum likelihood solution for among-individual variance, our model has run up against this constraint.\n\n#### Testing for random effects\n\nWe can  test the statistical significance of the random effect using the `ranova()` command in `lmerTest`. This function is actually doing a *likelihood ratio test* (LRT) of the random effect. The premise of which is that twice the difference in log-likelihood of the full and reduced (i.e. with the random effect dropped) is itself distributed as $\\chi^2$$ with DF equal to the number of parameters dropped (here 1). Actually, there is a good argument that this is too conservative, but we can discuss that later. So let's do the LRT for the random effect using `ranova()`\n\n::: {.callout-tip collapse='true'}\n\n# Solution\n\n```{r}\n#| label: mod1_ranova\n\nranova(m_1)\n```\n:::\n\nThere is apparently no among-individual variance in aggressiveness.\n\nSo this is a fairly rubbish and underwhelming model. Let's improve it.\n\n### Do unicorns differ in aggressiveness? A better mixed model\n\nThe answer we got from our first model is **not** wrong, it estimated the parameters we asked for and that might be informative or not and that might be representative or not of the true biology. Anyway all models are **wrong** but as models go this one is fairly rubbish. In fact we have explained no variation at all as we have no fixed effects (except the mean) and our random effect variance is zero. We woud have seen just how pointless this model was if we'd plotted it\n\n```{r}\n#| label: mod1_plot\n#| fig-cap: Fitted values vs residuals for a simple mixed model of unicorn aggression\n\nplot(m_1)\n```\n\nSo we can probably do better at modelling the data, which may or may not change our view on whether there is any real variation among unicorns in aggressiveness.\n\nFor instance, we can (and should have started with) an initial plot of the phenotypic data against opponent size indicates to have a look at our prediction.\n\n \n::: {.callout-tip collapse='true'}\n\n# Solution\n\nThe code below uses the excellent `r emoji::emoji(\"package\")` `ggplot2` but the same figure can be done using base R code.\n\n```{r}\n#| label: plot_aggr\n#| echo: true\n#| eval: false\n#| purl: false\nggplot(unicorns, aes(x = opp_size, y = aggression)) +\n  geom_jitter(\n    alpha = 0.5,\n    width = 0.05\n  ) +\n  scale_x_continuous(breaks = c(-1, 0, 1)) +\n  labs(\n    x = \"Opponent size (SD)\",\n    y = \"Aggression\"\n  ) +\n  theme_classic()\n```\n:::\n\n```{r}\n#| label: rplotaggr\n#| eval: true\n#| warning: false\n#| fig-cap: Unicorn aggressivity as a function of opponent size when fighting for sweets\n#| fig-align: center\nggplot(unicorns, aes(x = opp_size, y = aggression)) +\n  geom_jitter(\n    alpha = 0.5,\n    width = 0.05\n  ) +\n  scale_x_continuous(breaks = c(-1, 0, 1)) +\n  labs(\n    x = \"Opponent size (SD)\",\n    y = \"Aggression\"\n  ) +\n  theme_classic()\n```\n\nAs predicted, there is a general increase in aggression with opponent size (points are lightly jittered on the x-axis to show the spread of data a little better)\n\nYou can see the same thing from a quick look at the population means for aggression at opponent size. Here we do it with the `kable` function that makes nice tables in `rmarkdown` documents.\n\n```{r}\n#| label: mean_aggr\n#| echo: true\n\nunicorns %>%\n  group_by(opp_size) %>%\n  summarise(mean_aggr = mean(aggression)) %>%\n  knitr::kable(digits = 2)\n```\n\nSo, there does appear to be plasticity of aggression with changing size of the model opponent. But other things may explain variation in aggressiveness too - what about block for instance? Block effects may not be the subject of any biologically interesting hypotheses, but accounting for any differences between blocks could remove noise.\n\nThere may also be systematic change in behaviour as an individual experiences more repeat observations (i.e. exposure to the model). Do they get sensitised or habituated to the model intruder for example?\n\nSo let's  run a mixed model with the same random effect of individual, but with a fixed effects of opponent size (our predictor of interest) and experimental block.\n\n::: {.callout-tip collapse='true'}\n\n# Solution\n\n```{r}\n#| label: mod2\n\nm_2 <- lmer(aggression ~ opp_size + block + (1 | ID), data = unicorns)\n```\n\n:::\n\n#### Diagnostic plots\n\nRun a few diagnostic plots before we look at the answers. In diagnostic plots, we want to check the condition of applications of the linear mixed model which are the same 4 as the linear model plus 2 extra:\n\n1. Linearity of the relation between covariates and the response\n\n::: {.callout-tip collapse='true'}\n\n# Solution\nDone with data exploration graph (i.e. just plot the data see if it is linear)\n    - see previous graph \\@ref(fig:rplotaggr).\n:::\n\n2. No error on measurement of covariates\n\n::: {.callout-tip collapse='true'}\n\n# Solution\nassumed to be correct if measurement error is lower than 10% of variance in the variable\n    - I know this sounds pretty bad\n:::\n\n3. Residual have a Gaussian distribution\n\n::: {.callout-tip collapse='true'}\n\n# Solution\nusing quantile-quantile plot or histogram of residuals\n\n```{r}\n#| fig-cap: Checking residuals have Gaussian distribution\npar(mfrow = c(1, 2)) # multiple graphs in a window\nqqnorm(residuals(m_2)) # a q-q plot\nqqline(residuals(m_2))\nhist(resid(m_2)) # are the residuals roughly Gaussian?\n```\n:::\n\n4. Homoscedasticty (variance of residuals is constant across covariates)\n\n::: {.callout-tip collapse='true'}\n\n# Solution\nUsing plot of residuals by fitted values\n\n```{r}\n#| fig-cap: Residuals by fitted values for model m_2 to check homoscedasticity\nplot(m_2)\n```\n:::\n\n5. Random effects have a Gaussian distribution\n\n::: {.callout-tip collapse='true'}\n\n# Solution\nhistogram of the predictions for the random effects (BLUPs)\n\n```{r}\n#| fig-cap: Checking random effects are gaussian\n# extracting blups\nr1 <- as.data.frame(ranef(m_2, condVar = TRUE))\npar(mfrow = c(1, 2))\nhist(r1$condval)\nqqnorm(r1$condval)\nqqline(r1$condval)\n```\n\n:::\n\n6. Residual variance is constant across all levels of a random effect\n\n::: {.callout-tip collapse='true'}\n\n# Solution\nNo straightforward solution to deal with that. We can just do a plot is absolutely not-informative for that problem but I always like to look at. It is the plot of the sorted BLUPs with their associated errors.\n\n```{r}\n#| label: mod2_plots\n#| eval: true\nr1 <- r1[order(r1$condval), ] # sorting the BLUPs\nggplot(r1, aes(y = grp, x = condval)) +\n  geom_point() +\n  geom_pointrange(\n    aes(xmin = condval - condsd * 1.96, xmax = condval + condsd * 1.96)\n  ) +\n  geom_vline(aes(xintercept = 0, color = \"red\")) +\n  theme_classic() +\n  theme(legend.position = \"none\")\n```\n:::\n\n\n\nHere is a great magic trick `r emoji::emoji(\"sparkler\")` because 3-5 and more can be done in one step\n\n::: {.callout-tip collapse='true'}\n\n# Solution\nYou need to use the function `check_model()` from the `r emoji::emoji(\"package\")` performance package.\n```{r}\n#| fig-cap: Graphical check of model assumptions\n#| fig-asp: 2\ncheck_model(m_2)\n```\n:::\n\n#### Inferences\n\n**Now summarise this model. We will pause here for you to think about and discuss a few things:**\n* What can you take from the fixed effect table?\n* How do you interpret the intercept now that there are other effects in the model?\n* What would happen if we scaled our fixed covariates differently? Why?\n\n::: {.callout-tip collapse='true'}\n\n# Solution\n```{r}\nsummary(m_2)\n```\n\n:::\n\n\n::: {.callout-caution}\n# Exercise\n**Try tweaking the fixed part of your model:**\n\n- What happens if you add more fixed effects? Try it!\n- Could focal body size also matter? If so, should you rescale before adding it to the model?\n- Should you add interactions (e.g. block:opp_size)?\n- Should you drop non-significant fixed effects?\n:::\n\n\n::: {.callout-caution}\n# Exercise\n**Having changed the fixed part of your model, do the variance estimates change at all?**\n\n* Is among-individual variance always estimated as zero regardless of fixed effects?\n* Is among-individual variance significant with some fixed effets structures but not others?\n:::\n\n### What is the repeatability?\n\nAs a reminder, repeatability is the proportion of variance explained by a random effect and it is estimate as the ratio of the variance associated to a random effect by the total variance, or the sum of the residual variance and the different variance compoentn associated with the random effects.\nIn our first model among-individual variance was zero, so R was zero. If we have a different model of aggression and get a non-zero value of the random effect variance, we can obviously calculate a repeatability estimate (R). So we are all working from the same starting point, let's all stick with a common set of fixed effects from here on:\n\n```{r}\n#| label: mod3\n\nm_3 <- lmer(\n  aggression ~ opp_size + scale(body_size, center = TRUE, scale = TRUE)\n    + scale(assay_rep, scale = FALSE) + block\n    + (1 | ID),\n  data = unicorns\n)\nsummary(m_3)\n```\n\nSo we'd probably calculate R using the individual and residual variance simply as:\n\n```{r}\n0.02538 / (0.02538 + 0.58048)\n```\n\n::: {.callout-caution}\n# Exercise\nDo you see where I took the numbers ?\n:::\n\nWe can use some more fancy coding to extract the estimates and plugged them in a formula to estimate the repeatbility\n\n```{r}\n#| label: mod3_Rcalc\nv_id <- VarCorr(m_3)$ID[1, 1]\nv_r <- attr(VarCorr(m_3), \"sc\")^2\nr_man <- v_id / (v_id + v_r)\nr_man\n```\n\nWhich yields an estimate of approximately R=4%. Strictly speaking we should make clear this a **conditional repeatability** estimate.\n\nConditional on what you might ask...  on the fixed effects in your model. So our best estimate of 4% refers to the proportion of variance in aggressiveness *not explained by fixed effects* that is explained by individual identity. This isn't much and still won't be significant, but illustrates the point that conditional repeatabilities often have a tendency to go up as people explain more of the residual variance by adding fixed effects. This is fine and proper, but can mislead the unwary reader.\nIt also means that decisions about which fixed effects to include in your model need to be based on how you want to interpret R not just on, for instance, whether fixed effects are deemed significant.\n\n### A quick note on uncertainty\n\nUsing `lmer` in the `r emoji::emoji(\"package\")` `lme4` `r emoji::emoji(\"package\")` there isn't a really simple way to put some measure of uncertainty (SE or CI) on derived parameters like repeatabilities. This is a bit annoying. Such things are more easily done with other mixed model `r emoji::emoji(\"package\")` like `MCMCglmm` and `asreml` which are a bit more specialist. If you are using `lmer` for models you want to publish then you could look into the `r emoji::emoji(\"package\")` `rptR` [@rptR]. This  acts as a 'wrapper' for `lmer` models and adds some nice functionality including options to boostrap confidence intervals. Regardless, of how you do it, if you want to put a repeatability in one of your papers as a key result - it really should be accompanied by a measure of uncertainty just like any other effect size estimate.\n\nHere I am estimating the repeatability and using bootstrap to estimate a confidence interval and a probability associated with the repeatability with the `rptR` `r emoji::emoji(\"package\")`. For more information about the use of the package and the theory behind it suggest the excellent paper associated with the package [@rptR]\n\n```{r}\n#| echo: true\n#| warning: false\n#| message: false\nr_rpt <- rptGaussian(\n  aggression ~ opp_size + block + (1 | ID),\n  grname = \"ID\", data = unicorns\n)\nr_rpt\n```\n\n###  An easy way to mess up your mixed models\nWe will try some more advanced mixed models in a moment to explore plasticity in aggressiveness a bit more. First let's quickly look for among-individual variance in focal body size. Why not? We have the data handy, everyone says morphological traits are very repeatable and - lets be honest - who wouldn't like to see a small P value after striking out with aggressiveness.\n\nInclude a random effect of ID as before and maybe a fixed effect of block, just to see if the beasties were growing a bit between data collection periods.\n\n```{r}\n#| label: mod_size_wrong\n\nlmer_size <- lmer(body_size ~ block + (1 | ID),\n  data = unicorns\n)\n```\nSummarise and test the random effect.\n\n::: {.callout-tip collapse='true'}\n\n# Solution\n\n```{r}\nsummary(lmer_size)\nranova(lmer_size)\n```\n\n:::\n\n\n::: {.callout-caution}\n# Exercise\n**What might you conclude, and why would this be foolish?**\n:::\n\n::: {.callout-tip collapse='true'}\n\n# Solution\n\nHopefully you spotted the problem here. You have fed in a data set with 6 records per individual (with 2 sets of 3 identical values per unicorns), when you know size was only measured twice in reality. This means you'd expect to get a (potentially very) upwardly biased estimate of R and a (potentially very) downwardly biased P value when testing among-individual variance. \n\n:::\n\n::: {.callout-caution}\n# Exercise\n**How can we do it properly?**\n:::\n\n::: {.callout-tip collapse='true'}\n\n# Solution\nWe can prune the data to the two actual observations per unicorns by just selecting the first assay in each block.\n\n```{r}\n#| label: mod_size_right\n\nunicorns2 <- unicorns[unicorns$assay_rep == 1, ]\n\nlmer_size2 <- lmer(body_size ~ block + (1 | ID),\n  data = unicorns2\n)\nsummary(lmer_size2)\nranova(lmer_size2)\n```\n\nSummarise and test your random effect and you'll see the qualitative conclusions will actually be very similar using the pruned data set. Of course this won't generallty but be true, so just be careful. Mixed models are intended to help you model repeated measures data with non-independence, but they won't get you out of trouble if you mis-represent the true structure of observations on your dependent variable.\n:::\n\n\n### Happy mixed-modelling\n\n```{r}\n#| echo: false\n#| out-width: 20%\n#| fig-align: center\n#| fig-cap: The superb unicorn\nknitr::include_graphics(\"images/unicorn.png\")\n```\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":true,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","from":"markdown+emoji","number-sections":true,"output-file":"51-lmm.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en-CA","fig-responsive":true,"quarto-version":"1.5.45","version":"0.6.0","year":2024,"bibliography":["biblio/book.bib","biblio/grateful-refs.bib"],"biblio-style":"apalike","csl":"biblio/ecology.csl","params":{"echo_sol":true,"longrun":false,"html_pdf":true},"cit-title":"Do what you think is interesting,  \ndo something that you think is fun and worthwhile,  \nbecause otherwise you won’t do it well anyway.\n","cit-author":"Brian W. Kernighan","theme":{"light":"cosmo","dark":["cosmo","css/theme-dark.scss"]},"author-meta":"Julien Martin"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"paged","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"lualatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","from":"markdown+emoji","number-sections":true,"output-file":"51-lmm.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"block-headings":false,"version":"0.6.0","year":2024,"bibliography":["biblio/book.bib","biblio/grateful-refs.bib"],"biblio-style":"apalike","csl":"biblio/ecology.csl","params":{"echo_sol":true,"longrun":false,"html_pdf":true},"lang":"en-CA","cit-title":"Do what you think is interesting,  \ndo something that you think is fun and worthwhile,  \nbecause otherwise you won’t do it well anyway.\n","cit-author":"Brian W. Kernighan","documentclass":"scrreprt","classoption":["chapterprefix=true","headings=big","twoside=semi"],"papersize":"letter","fontsize":"11pt","geometry":["top=2cm","bottom=2cm","left=2cm","right=2cm","footskip=1cm"],"colorlinks":true,"linestretch":1.5,"template-partials":["latex/before-title.tex","latex/before-body.tex"]},"extensions":{"book":{"selfContainedOutput":true}}},"epub":{"identifier":{"display-name":"ePub","target-format":"epub","base-format":"epub"},"execute":{"fig-width":5,"fig-height":4,"fig-format":"png","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"epub","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":false,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"default-image-extension":"png","html-math-method":"mathml","to":"epub","from":"markdown+emoji","toc":true,"output-file":"51-lmm.epub"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"version":"0.6.0","year":2024,"bibliography":["biblio/book.bib","biblio/grateful-refs.bib"],"biblio-style":"apalike","csl":"biblio/ecology.csl","params":{"echo_sol":true,"longrun":false,"html_pdf":true},"lang":"en-CA","cit-title":"Do what you think is interesting,  \ndo something that you think is fun and worthwhile,  \nbecause otherwise you won’t do it well anyway.\n","cit-author":"Brian W. Kernighan","dev":"svglite","stylesheet":"css/epub.css"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf","epub"]}