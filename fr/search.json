[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "",
    "text": "PrÃ©face",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "index.html#lobjectif-de-ce-livre",
    "href": "index.html#lobjectif-de-ce-livre",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "Lâ€™objectif de ce livre",
    "text": "Lâ€™objectif de ce livre\nLâ€™objectif de ce livre est de te prÃ©senter R, un environnement interactif puissant et flexible pour le calcul et la recherche statistiques. R nâ€™est pas difficile Ã  apprendre en soi, mais comme pour lâ€™apprentissage de toute nouvelle langue (parlÃ©e ou informatique), la courbe dâ€™apprentissage initiale peut Ãªtre abrupte et quelque peu dÃ©courageante. Il ne sâ€™agit pas de tout couvrir, mais simplement de tâ€™aider Ã  gravir la courbe dâ€™apprentissage initiale (potentiellement plus rapidement) et de te fournir les compÃ©tences de base (et la confiance !) nÃ©cessaires pour commencer ton propre voyage avec R.",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "index.html#livre-multilingue",
    "href": "index.html#livre-multilingue",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "Livre multilingue",
    "text": "Livre multilingue\nLe livre est fourni comme un livre multilingue qui brise la barriÃ¨re de la langue et permet potentiellement de faciliter lâ€™apprentissage de R et de son environnement principalement anglophone. Nous sommes toujours Ã  la recherche de bÃ©nÃ©voles pour nous aider Ã  dÃ©velopper le livre et Ã  ajouter dâ€™autres langues Ã  la liste qui ne cesse de sâ€™allonger . Nâ€™hÃ©site pas Ã  Contacte-nous si tu veux nous aider\nSur la page web, tu peux changer de langue via le  dans la barre de navigation. AprÃ¨s avoir changer de langue, tu peux tÃ©lÃ©charger le document en pdf ou epub pour cet langue .\nListe des langues :\n\nanglais (publiÃ© mais Ã  peaufiner)\nfranÃ§ais (en dÃ©veloppement, en attendant que lâ€™anglais soit peaufinÃ©)\nespagnol (en dÃ©veloppement, en attendant que lâ€™anglais soit peaufinÃ©)",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "index.html#comment-utiliser-ce-livre",
    "href": "index.html#comment-utiliser-ce-livre",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "Comment utiliser ce livre",
    "text": "Comment utiliser ce livre\nPour une meilleure expÃ©rience, nous te recommandons de lire la version web de ce livre que tu peux trouver Ã  https://biostats-uottawa.github.io/R/fr.\nLa version web inclut une barre de navigation incluant des options pour faciliter la lecture , de recherche , pour changer la couleur  et pour suggÃ©rer des modifications ou reporter des problÃ¨mes . Tu peux aussi tÃ©lÃ©charger le document  au format pdf ou epub.\nNous utilisons quelques conventions typographiques tout au long de ce livre.\nLe code R et la sortie qui en rÃ©sulte sont prÃ©sentÃ©s dans des blocs de code dans notre livre.\n\n2 + 2\n\n[1] 4\n\n\nLes fonctions dans le texte sont prÃ©sentÃ©es avec des parenthÃ¨ses Ã  la fin en utilisant la police de code, câ€™est-Ã -dire mean() ou sd() etc.\nLes objets sont reprÃ©sentÃ©s Ã  lâ€™aide de la police de code sans les parenthÃ¨ses, câ€™est-Ã -dire obj1, obj2 etc.\nLes paquets R dans le texte sont indiquÃ©s en utilisant la police de code et suivis de lâ€™icone ğŸ“¦, exemple tidyverse ğŸ“¦.\nUne sÃ©rie dâ€™actions nÃ©cessaires pour accÃ©der aux commandes de menu dans RStudio ou VSCode sont identifiÃ©es comme suit File -&gt; New File -&gt; R Script ce qui se traduit par â€œclique sur le menu Fichier, puis clique sur Nouveau fichier et sÃ©lectionne R Scriptâ€.\nLorsque nous faisons rÃ©fÃ©rence Ã  IDE (IntÃ©grÃ©e DdÃ©veloppement Environnement) dans la suite du texte, il sâ€™agit de RStudio ou de VScode.\nLorsque nous parlons de .[Rq]md Nous entendons par lÃ  les documents R markdown (.Rmd) ou Quarto (.qmd) et nous parlerons gÃ©nÃ©ralement des documents R markdown en faisant rÃ©fÃ©rence Ã  lâ€™un ou lâ€™autre des fichiers .Rmd ou .qmd.\nLe manuel tente de mettre en Ã©vidence certaines parties du texte Ã  lâ€™aide des encadrÃ©s et icÃ´nes suivants.\n\n\n\n\n\n\nExercices\n\n\n\nDes choses Ã  faire pour toi\n\n\n\n\n\n\n\n\nSolutions\n\n\n\nCode R et explications\n\n\n\n\n\n\n\n\nAvertissement\n\n\n\navertissements\n\n\n\n\n\n\n\n\nImportant\n\n\n\npoints importants\n\n\n\n\n\n\n\n\nNote\n\n\n\nnotes",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "index.html#sec-qui",
    "href": "index.html#sec-qui",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "Qui sommes-nous ?",
    "text": "Qui sommes-nous ?\n\n\n\n\n\n\n\n\n\n\n\n\nÂ \n\n\nJulien Martin est professeur Ã  lâ€™UniversitÃ© dâ€™Ottawa en Ã‰cologie Ã©volutive. Il a dÃ©couvert le merveilleux monde R avec la version 1.8.1 et lâ€™enseigne depuis R v2.4.0.\n\n\n: site uOttawa, site labo\n\n\n: jgamartin\n\n\n: juliengamartin",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "index.html#remerciements",
    "href": "index.html#remerciements",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "Remerciements",
    "text": "Remerciements\nCe livre a commencÃ© comme un fork sur github Ã  partir de lâ€™excellent An introduction to Rde Douglas, Roos, Mancini, Couto et Lusseau. (Douglas 2023). Il a Ã©tÃ© forkÃ© le 23 avril 2023 Ã  partir de DÃ©pÃ´t github Alexd106 puis modifiÃ© et mis Ã  jour en suivant mes propres besoins et ma perspective dâ€™enseignement de R. Cela fait Ã©galement partie dâ€™un projet de livre R multilingue visant Ã  amÃ©liorer lâ€™Ã©quitÃ© et la diversitÃ©. Il a commencÃ© par une traduction en franÃ§ais et a Ã©tÃ©/sera Ã©tendu Ã  de nombreuses autres langues.",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "index.html#licence",
    "href": "index.html#licence",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "Licence",
    "text": "Licence\nJe partage cette version modifiÃ©e du livre original sous la licence Licence Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International.\n\n\nLicence Creative Commons\n\nSi tu enseignes R, nâ€™hÃ©site pas Ã  utiliser tout ou partie du contenu de ce livre pour aider tes propres Ã©lÃ¨ves. La seule chose que je te demande, câ€™est de citer la source originale et les auteurs. Si tu trouves ce livre utile ou si tu as des commentaires ou des suggestions, jâ€™aimerais beaucoup que tu me les fasses parvenir (contact info).",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "index.html#citer-le-livre",
    "href": "index.html#citer-le-livre",
    "title": "Sur le chemin de lâ€™enf-R",
    "section": "Citer le livre",
    "text": "Citer le livre\nJulien Martin. (2024). Sur le chemin de lâ€™enf-R. Un livre multilingue dâ€™introduction Ã  R. Version: 0.6.0 (2024-06-21).DOI: 10.5281/zenodo.10929585\n\n\n\n\nDouglas, A. 2023. An introduction to R.",
    "crumbs": [
      "DonnÃ©es",
      "PrÃ©face"
    ]
  },
  {
    "objectID": "01-debut.html",
    "href": "01-debut.html",
    "title": "1Â  Pour commencer",
    "section": "",
    "text": "Quelques conseils sur R\nBonne chance et nâ€™oublie pas de tâ€™amuser.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#quelques-conseils-sur-r",
    "href": "01-debut.html#quelques-conseils-sur-r",
    "title": "1Â  Pour commencer",
    "section": "",
    "text": "Utilise R souvent et rÃ©guliÃ¨rement. Cela tâ€™aidera Ã  crÃ©er et Ã  maintenir une dynamique trÃ¨s importante.\nApprendre R nâ€™est pas un test de mÃ©moire. Lâ€™un des avantages dâ€™un langage de script est que tu auras toujours ton code (bien annotÃ©) auquel te rÃ©fÃ©rer lorsque tu auras oubliÃ© comment faire quelque chose.\nTu nâ€™as pas besoin de tout savoir sur R pour Ãªtre productif.\nSi tu es bloquÃ©, fais des recherches en ligne, ce nâ€™est pas de la triche et Ã©crire une bonne requÃªte de recherche est une compÃ©tence en soi.\nSi tu te retrouves Ã  fixer du code pendant des heures en essayant de comprendre pourquoi il ne fonctionne pas, alors va tâ€™Ã©loigner pendant quelques minutes.\nEn R, il existe de nombreuses faÃ§ons dâ€™aborder un problÃ¨me particulier. Si ton code fait ce que tu veux quâ€™il fasse dans un temps raisonnable et de maniÃ¨re robuste, alors ne tâ€™inquiÃ¨te pas.\nR nâ€™est quâ€™un outil pour tâ€™aider Ã  rÃ©pondre Ã  tes questions intÃ©ressantes. Ne perds pas de vue ce qui est important : ta ou tes questions de recherche et tes donnÃ©es. Aucune compÃ©tence en matiÃ¨re dâ€™utilisation de R ne te sera utile si ta collecte de donnÃ©es est fondamentalement dÃ©fectueuse ou si ta question est vague.\nReconnais quâ€™il y aura des moments oÃ¹ les choses deviendront un peu difficiles ou frustrantes. Essaie dâ€™accepter ces pÃ©riodes comme faisant partie du processus naturel dâ€™apprentissage dâ€™une nouvelle compÃ©tence (nous sommes tous passÃ©s par lÃ ) et souviens-toi que le temps et lâ€™Ã©nergie que tu investis maintenant seront largement remboursÃ©s dans un avenir pas trop lointain.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#installation",
    "href": "01-debut.html#installation",
    "title": "1Â  Pour commencer",
    "section": "\n1.1 Installation",
    "text": "1.1 Installation\n\n1.1.1 Installer R\nPour Ãªtre opÃ©rationnel, la premiÃ¨re chose Ã  faire est dâ€™installer R. R est disponible gratuitement pour les systÃ¨mes dâ€™exploitation Windows, Mac et Linux Ã  partir du [site Web du Comprehensive R Archive Network (C]RAN) CRAN. Pour les utilisateurs de Windows et de Mac, nous te suggÃ©rons de tÃ©lÃ©charger et dâ€™installer les versions binaires prÃ©compilÃ©es. Il existe des instructions assez complÃ¨tes pour installer R pour chaque systÃ¨me dâ€™exploitation (Windows,Mac ou linux ).\nQuel que soit le systÃ¨me dâ€™exploitation que tu utilises, une fois que tu as installÃ© R, tu dois vÃ©rifier quâ€™il fonctionne correctement. Le plus simple est de lancer R en double-cliquant sur lâ€™icÃ´ne R (Windows ou Mac) ou en tapant R dans la console (Linux). Tu devrais voir apparaÃ®tre la Console R et tu devrais pouvoir taper des commandes R dans la Console aprÃ¨s lâ€™invite de commande &gt;. Essaie de taper le code R suivant et appuie sur EntrÃ©e :\n\nplot(1:10)\n\n\n\n\n\n\n\nUn graphique des nombres 1 Ã  10 sur les axes x et y devrait apparaÃ®tre. Si câ€™est le cas, tu peux commencer. Si ce nâ€™est pas le cas, nous te suggÃ©rons de noter toutes les erreurs produites et dâ€™utiliser Google pour rÃ©soudre le problÃ¨me.\n\n1.1.2 Installation dâ€™un IDE\nNous recommandons fortement dâ€™utiliser un IntÃ©grÃ©e DdÃ©veloppement Environnement de dÃ©veloppement (IDE) pour travailler avec R. Un IDE simple et extrÃªmement populaire est RStudio. Une alternative Ã  RStudio est Visual Studio Code, ou VSCode. Un IDE peut Ãªtre considÃ©rÃ© comme un complÃ©ment Ã  R qui fournit une interface plus conviviale, incorporant la console R, un Ã©diteur de scripts et dâ€™autres fonctionnalitÃ©s utiles (comme R markdown et lâ€™intÃ©gration de Git Hub).\n\n\n\n\n\n\nMise en garde\n\n\n\nTu dois installer R avant dâ€™installer un IDE (voir Section 1.1.1 pour plus de dÃ©tails).\n\n\n\n\n\n\n\n\nNote\n\n\n\nLorsque nous nous rÃ©fÃ©rons Ã  Lâ€™IDE dans la suite du texte, il sâ€™agit de RStudio ou de VScode.\n\n\n\n1.1.2.1 RStudio\nRStudio est disponible gratuitement pour les systÃ¨mes dâ€™exploitation Windows, Mac et Linux et peut Ãªtre tÃ©lÃ©chargÃ© Ã  partir du site de RStudio. Tu dois sÃ©lectionner la version â€˜RStudio Desktopâ€™.\n\n1.1.2.2 VSCode\nVSCode est disponible gratuitement pour les systÃ¨mes dâ€™exploitation Windows, Mac et Linux et peut Ãªtre tÃ©lÃ©chargÃ© Ã  partir du site de VS Code.\nEn outre, tu dois installer le lâ€™extension R de VSCode. Pour faire de VSCode une vÃ©ritable centrale pour travailler avec R, nous te recommandons fortement dâ€™installer Ã©galement :\n\n\nradian radian : Une console R moderne qui corrige de nombreuses limitations du terminal R officiel et prend en charge de nombreuses fonctionnalitÃ©s telles que la coloration syntaxique et lâ€™autocomplÃ©tion.\n\nVSCode-R-Debugger VSCode-R-Debugger : Une extension de VS Code pour prendre en charge les capacitÃ©s de dÃ©bogage de R.\n\nhttpgd: Un paquetage R ğŸ“¦ pour fournir un dispositif graphique qui sert de faÃ§on asynchrone des graphiques SVG via HTTP et WebSockets.\n\n1.1.2.3 Alternatives Ã  RStudio et VSCode\nPlutÃ´t que dâ€™utiliser un IDE â€œtout en unâ€, de nombreuses personnes choisissent dâ€™utiliser R et un Ã©diteur de script sÃ©parÃ© pour Ã©crire et exÃ©cuter le code R. Si tu ne sais pas ce quâ€™est un Ã©diteur de script, tu peux lâ€™assimiler Ã  un traitement de texte, mais spÃ©cialement conÃ§u pour Ã©crire du code. Heureusement, de nombreux Ã©diteurs de scripts sont disponibles gratuitement, alors nâ€™hÃ©site pas Ã  les tÃ©lÃ©charger et Ã  expÃ©rimenter jusquâ€™Ã  ce que tu en trouves un qui te plaise. Certains Ã©diteurs de scripts ne sont disponibles que pour certains systÃ¨mes dâ€™exploitation et tous ne sont pas spÃ©cifiques Ã  R. Tu trouveras ci-dessous des suggestions dâ€™Ã©diteurs de scripts. Câ€™est Ã  toi de choisir celui que tu veux : lâ€™une des grandes qualitÃ©s de R est que TU câ€™est que tu peux choisir comment tu veux utiliser R.\n\n1.1.2.3.1 Ã‰diteurs de texte avancÃ©s\nUn moyen lÃ©ger mais efficace de travailler avec R est dâ€™utiliser des Ã©diteurs de texte avancÃ©s tels que :\n\n\nAtom (tous les systÃ¨mes dâ€™exploitation)\n\nBBedit (Mac OS)\n\ngedit (Linux ; livrÃ© avec la plupart des distributions Linux)\n\nMacVim (Mac OS)\n\nNano (Linux)\n\nNotepad++ [bloc-notes] (Windows)\n\nSublime Text (tous les systÃ¨mes dâ€™exploitation)\n\nvim et son extension NVim-R (Linux)\n\n1.1.2.3.2 Environnements de dÃ©veloppement intÃ©grÃ©s\nCes environnements sont plus puissants que de simples Ã©diteurs de texte, et sont similaires Ã  RStudio :\n\n\nEmacs et son extension Emacs parle statistiques (tous les systÃ¨mes dâ€™exploitation)\n\nRKWard (Linux)\n\nTinn-R (Windows)",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#sec-orient",
    "href": "01-debut.html#sec-orient",
    "title": "1Â  Pour commencer",
    "section": "\n1.2 Orientation de lâ€™IDE",
    "text": "1.2 Orientation de lâ€™IDE\n\n1.2.1 RStudio\nLorsque tu ouvres R studio pour la premiÃ¨re fois, tu devrais voir la prÃ©sentation suivante (elle peut Ãªtre lÃ©gÃ¨rement diffÃ©rente sur un ordinateur Windows).\n\n\n\n\n\n\n\n\nLa grande fenÃªtre (ou volet) sur la gauche est le Console de la console. La fenÃªtre en haut Ã  droite est la fenÃªtre Environnement / Histoire / Connexions et la fenÃªtre en bas Ã  droite est la fenÃªtre Fichiers / TracÃ©s / Paquets / Aide / Visionneuse de la fenÃªtre. Nous aborderons chacun de ces volets ci-dessous. Tu peux personnaliser lâ€™emplacement de chaque volet en cliquant sur le menu â€œOutilsâ€ puis en sÃ©lectionnant Options globales â€“&gt; Disposition des volets. Tu peux redimensionner les volets en cliquant sur le milieu des bords de la fenÃªtre et en le faisant glisser dans la direction souhaitÃ©e. Il existe une multitude dâ€™autres faÃ§ons de personnaliser RStudio.\n\n1.2.1.1 Console\nLa console est le cheval de bataille de R. Câ€™est lÃ  que R Ã©value tout le code que tu Ã©cris. Tu peux taper du code R directement dans la console Ã  lâ€™invite de la ligne de commande, &gt;. Par exemple, si tu tapes 2 + 2 dans la console, tu devrais obtenir la rÃ©ponse 4 (rassurante). Ne tâ€™inquiÃ¨te pas pour le [1] au dÃ©but de la ligne pour lâ€™instant.\n\n\n\n\n\n\n\n\nCependant, dÃ¨s que tu commences Ã  Ã©crire plus de code R, cela devient plutÃ´t encombrant. Au lieu de taper le code R directement dans la console, une meilleure approche consiste Ã  crÃ©er un script R. Un script R est un simple fichier texte avec une balise .R qui contient tes lignes de code R. Ces lignes de code sont ensuite introduites dans la console R, ligne par ligne. Pour crÃ©er un nouveau script R, clique sur le menu â€œFichierâ€ puis sÃ©lectionne Nouveau fichier â€“&gt; Script R.\n\n\n\n\n\n\n\n\nTu remarqueras quâ€™une nouvelle fenÃªtre (appelÃ©e volet Source) apparaÃ®t en haut Ã  gauche de RStudio et que la console se trouve maintenant en bas Ã  gauche. La nouvelle fenÃªtre est un Ã©diteur de script et câ€™est lÃ  que tu Ã©criras ton code.\n\n\n\n\n\n\n\n\nPour faire passer ton code de ton Ã©diteur de script Ã  la console, place ton curseur sur la ligne de code, puis clique sur le bouton â€œExÃ©cuterâ€ en haut Ã  droite de la fenÃªtre de lâ€™Ã©diteur de script.\n\n\n\n\n\n\n\n\nTu devrais voir le rÃ©sultat dans la fenÃªtre de la console. Si le fait de cliquer sur le bouton â€œExÃ©cuterâ€ devient fastidieux, tu peux utiliser le raccourci clavier â€œctrl + entrÃ©eâ€ (sous Windows et Linux) ou â€œcmd + entrÃ©eâ€ (sous Mac). Tu peux enregistrer tes scripts R sous la forme dâ€™un fichier .R en sÃ©lectionnant le menu â€˜Fichierâ€™ et en cliquant sur enregistrer. Remarque que le nom du fichier dans lâ€™onglet devient rouge pour te rappeler que tu as des modifications non enregistrÃ©es. Pour ouvrir ton script R dans RStudio, sÃ©lectionne le menu â€˜Fichierâ€™ puis â€˜Ouvrir le fichierâ€¦â€™. Enfin, il est bon de noter que, bien que les scripts R soient enregistrÃ©s avec un nom de fichier .R il sâ€™agit en fait de simples fichiers texte qui peuvent Ãªtre ouverts avec nâ€™importe quel Ã©diteur de texte.\n\n1.2.1.2 Environnement/Histoire/Connexions\nLa fenÃªtre Environnement / Historique / Connexions te montre de nombreuses informations utiles. Tu peux accÃ©der Ã  chaque composant en cliquant sur lâ€™onglet appropriÃ© dans le volet.\n\nLâ€™onglet â€˜Environnementâ€™ affiche tous les objets que tu as crÃ©Ã©s dans lâ€™environnement actuel (global). Ces objets peuvent Ãªtre des donnÃ©es que tu as importÃ©es ou des fonctions que tu as Ã©crites. Les objets peuvent Ãªtre affichÃ©s sous forme de liste ou de grille en sÃ©lectionnant ton choix dans le bouton dÃ©roulant situÃ© en haut Ã  droite de la fenÃªtre. Si tu es dans le format Grille, tu peux supprimer des objets de lâ€™environnement en cochant la case vide Ã  cÃ´tÃ© du nom de lâ€™objet, puis en cliquant sur lâ€™icÃ´ne du balai. Il existe Ã©galement un bouton â€œImporter un ensemble de donnÃ©esâ€ qui permet dâ€™importer des donnÃ©es sauvegardÃ©es dans diffÃ©rents formats de fichiers. Cependant, nous te conseillons de ne pas utiliser cette approche pour importer tes donnÃ©es car elle nâ€™est pas reproductible et donc pas robuste (voir ?sec-data-r pour plus de dÃ©tails).\nLâ€™onglet â€˜Historiqueâ€™ contient une liste de toutes les commandes que tu as entrÃ©es dans la console R. Tu peux rechercher dans ton historique la ligne de code que tu as oubliÃ©e, renvoyer le code sÃ©lectionnÃ© dans la Console ou la fenÃªtre Source. En gÃ©nÃ©ral, nous nâ€™utilisons jamais cette fonction car nous nous rÃ©fÃ©rons toujours Ã  notre script R.\nLâ€™onglet â€œConnexionsâ€ te permet de te connecter Ã  diverses sources de donnÃ©es telles que des bases de donnÃ©es externes.\n\n1.2.1.3 Fichiers/Plots/Packages/Aide/Viewer\n\nLâ€™onglet â€˜Fichiersâ€™ rÃ©pertorie tous les fichiers et rÃ©pertoires externes dans le rÃ©pertoire de travail actuel de ton ordinateur. Il fonctionne comme lâ€™explorateur de fichiers (Windows) ou le Finder (Mac). Tu peux ouvrir, copier, renommer, dÃ©placer et supprimer les fichiers listÃ©s dans la fenÃªtre.\nLâ€™onglet â€˜TracÃ©sâ€™ est lâ€™endroit oÃ¹ tous les tracÃ©s que tu as crÃ©Ã©s dans R sont affichÃ©s (Ã  moins que tu ne dises le contraire Ã  R). Tu peux â€œzoomerâ€ sur les tracÃ©s pour les agrandir Ã  lâ€™aide du bouton de la loupe, et faire dÃ©filer les tracÃ©s crÃ©Ã©s prÃ©cÃ©demment Ã  lâ€™aide des boutons flÃ©chÃ©s. Il est Ã©galement possible dâ€™exporter les tracÃ©s vers un fichier externe Ã  lâ€™aide du menu dÃ©roulant â€œExporterâ€. Les tracÃ©s peuvent Ãªtre exportÃ©s dans diffÃ©rents formats de fichiers tels que jpeg, png, pdf, tiff ou copiÃ©s dans le presse-papiers (bien quâ€™il soit probablement prÃ©fÃ©rable dâ€™utiliser les fonctions R appropriÃ©es pour ce faire - voir ?sec-graphics_r pour plus de dÃ©tails).\nLâ€™onglet â€˜Paquetsâ€™ rÃ©pertorie tous les paquets que tu as installÃ©s sur ton ordinateur. Tu peux Ã©galement installer de nouveaux paquets et mettre Ã  jour les paquets existants en cliquant respectivement sur les boutons â€˜Installerâ€™ et â€˜Mettre Ã  jourâ€™.\nLâ€™onglet â€˜Aideâ€™ affiche la documentation dâ€™aide R pour nâ€™importe quelle fonction. Nous verrons comment afficher les fichiers dâ€™aide et comment rechercher de lâ€™aide dans le ?sec-basics_r.\nLâ€™onglet â€˜Visionneuseâ€™ affiche le contenu web local tel que les graphiques web gÃ©nÃ©rÃ©s par certains paquets.\n\n1.2.2 VSCode\n\n\n\n\n\n\n\n\n\n1.2.2.1 Panneau gauche\nContient :\n\nGestionnaire de fichiers et aperÃ§u des fichiers.\nSupport R incluant lâ€™environnement R / la recherche R / lâ€™aide R / lâ€™installation de paquets\nInteraction avec Github\n\n\n\n\n\n\n\n\n\n\n(a) fichier\n\n\n\n\n\n\n\n\n\n(b) git\n\n\n\n\n\n\n\n\n\n(c) r-ext\n\n\n\n\n\n\nFigureÂ 1.1: VS Code panneau de gauche\n\n\n\n1.2.2.2 Onglets de lâ€™Ã©diteur\nComprend :\n\npanneau de tracÃ© (avec historique et navigation)\nÃ©dition de scripts\npanneaux de prÃ©visualisation\n\n\n\n\n\n\n\n\n\n\n1.2.2.3 FenÃªtre du terminal\nContient :\n\nle terminal permettant dâ€™avoir une session R ou tout autre type de terminaux nÃ©cessaires (bash/tmux/). Il peut Ãªtre divisÃ© et exÃ©cuter plusieurs sessions en mÃªme temps.\nun panneau de problÃ¨mes mettant en Ã©vidence les problÃ¨mes de grammaire et de codage",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#sec-packages",
    "href": "01-debut.html#sec-packages",
    "title": "1Â  Pour commencer",
    "section": "\n1.3 Paquets R",
    "text": "1.3 Paquets R\nLâ€™installation de base de R est livrÃ©e en standard avec de nombreux paquets utiles. Ces paquets contiennent de nombreuses fonctions que tu utiliseras au quotidien. Cependant, lorsque tu commenceras Ã  utiliser R pour des projets plus variÃ©s (et que ton utilisation de R Ã©voluera), tu verras quâ€™il arrivera un moment oÃ¹ tu auras besoin dâ€™Ã©tendre les capacitÃ©s de R. Heureusement, plusieurs milliers dâ€™utilisateurs de R ont dÃ©veloppÃ© un code utile et lâ€™ont partagÃ© sous forme de paquets installables. Tu peux considÃ©rer un paquet comme une collection de fonctions, de donnÃ©es et de fichiers dâ€™aide rassemblÃ©s dans une structure standard bien dÃ©finie que tu peux tÃ©lÃ©charger et installer dans R. Ces paquets peuvent Ãªtre tÃ©lÃ©chargÃ©s Ã  partir de diverses sources, mais les plus populaires sont les suivantes CRAN, Bioconductor et GitHub. Actuellement, le CRAN hÃ©berge plus de 15 000 paquets et est le dÃ©pÃ´t officiel des paquets R fournis par les utilisateurs. Bioconductor fournit des logiciels open source orientÃ©s vers la bio-informatique et hÃ©berge plus de 1800 paquets R. GitHub est un site Web qui hÃ©berge des dÃ©pÃ´ts git pour toutes sortes de logiciels et de projets (pas seulement R). Souvent, les versions de dÃ©veloppement de pointe des paquets R sont hÃ©bergÃ©es sur GitHub, donc si tu as besoin de toutes les nouvelles cloches et sifflets, cela peut Ãªtre une option. Cependant, lâ€™inconvÃ©nient potentiel de lâ€™utilisation de la version de dÃ©veloppement dâ€™un paquetage R est quâ€™elle peut ne pas Ãªtre aussi stable que la version hÃ©bergÃ©e sur CRAN (elle est en cours de dÃ©veloppement !) et que la mise Ã  jour des paquets nâ€™est pas automatique.\n\n1.3.1 Paquets CRAN\nPour installer un paquet Ã  partir du CRAN, tu peux utiliser la commande install.packages() fonction. Par exemple, si tu veux installer le paquet remotes entre le code suivant dans la fenÃªtre Console de RStudio (note : tu auras besoin dâ€™une connexion internet pour faire cela)\n\ninstall.packages(\"remotes\", dependencies = TRUE)\n\nIl te sera peut-Ãªtre demandÃ© de choisir un miroir CRAN, sÃ©lectionne simplement â€˜0-cloudâ€™ ou un miroir proche de ton emplacement. Le dependencies = TRUE permet de sâ€™assurer que les paquets supplÃ©mentaires nÃ©cessaires seront Ã©galement installÃ©s.\nCâ€™est une bonne pratique de mettre rÃ©guliÃ¨rement Ã  jour tes paquets prÃ©cÃ©demment installÃ©s pour avoir accÃ¨s aux nouvelles fonctionnalitÃ©s et aux corrections de bogues. Pour mettre Ã  jour les paquets CRAN, tu peux utiliser la commande update.packages() (tu auras besoin dâ€™une connexion Internet fonctionnelle pour cela)\n\nupdate.packages(ask = FALSE)\n\nLa fonction ask = FALSE Ã©vite dâ€™avoir Ã  confirmer chaque tÃ©lÃ©chargement de paquet, ce qui peut Ãªtre pÃ©nible si tu as beaucoup de paquets installÃ©s.\n\n1.3.2 Paquets Bioconductor\nPour installer les paquets de Bioconductor, le processus est un peu diffÃ©rent. Tu dois dâ€™abord installer le BiocManager ğŸ“¦ paquet. Tu ne dois le faire quâ€™une seule fois, Ã  moins que tu ne rÃ©installes ou mettes Ã  jour R.\n\ninstall.packages(\"BiocManager\", dependencies = TRUE)\n\nUne fois que le BiocManager ğŸ“¦ a Ã©tÃ© installÃ©, tu peux soit installer tous les paquets â€œde baseâ€ de Bioconductor Ã  lâ€™aide de la commande\n\nBiocManager::install()\n\nou installer des paquets spÃ©cifiques tels que le GenomicRanges ğŸ“¦ et edgeR ğŸ“¦ paquets\n\nBiocManager::install(c(\"GenomicRanges\", \"edgeR\"))\n\nPour mettre Ã  jour les paquets de Bioconductor, il suffit dâ€™utiliser la commande BiocManager::install() Ã  nouveau\n\nBiocManager::install(ask = FALSE)\n\nEncore une fois, tu peux utiliser la fonction ask = FALSE pour Ã©viter dâ€™avoir Ã  confirmer chaque tÃ©lÃ©chargement de paquet.\n\n1.3.3 Paquets GitHub\nIl existe de multiples options pour installer des paquets hÃ©bergÃ©s sur GitHub. La mÃ©thode la plus efficace est sans doute dâ€™utiliser la fonction install_github() de la fonction remotes ğŸ“¦ (tu as installÃ© ce paquet prÃ©cÃ©demment, Section 1.3.1). Avant dâ€™utiliser la fonction, tu devras connaÃ®tre le nom dâ€™utilisateur GitHub du propriÃ©taire du dÃ©pÃ´t ainsi que le nom du dÃ©pÃ´t. Par exemple, la version de dÃ©veloppement de dplyr ğŸ“¦ de Hadley Wickham est hÃ©bergÃ©e sur le compte GitHub de tidyverse et porte le nom de dÃ©pÃ´t â€ dplyr â€ (il suffit de taper â€ github dplyr â€ sur Google). Pour installer cette version depuis GitHub, utilise\n\nremotes::install_github(\"tidyverse/dplyr\")\n\nLe moyen le plus sÃ»r (Ã  notre connaissance) de mettre Ã  jour un paquetage installÃ© depuis GitHub est de le rÃ©installer en utilisant la commande ci-dessus.\n\n1.3.4 Utilisation des paquets\nUne fois que tu as installÃ© un paquet sur ton ordinateur, il nâ€™est pas immÃ©diatement disponible pour que tu puisses lâ€™utiliser. Pour utiliser un paquet, tu dois dâ€™abord le charger Ã  lâ€™aide de la commande library() en utilisant la fonction Par exemple, pour charger le paquet remotes ğŸ“¦ que tu as prÃ©cÃ©demment installÃ©\n\nlibrary(remotes)\n\nLe library() chargera Ã©galement tous les paquets supplÃ©mentaires nÃ©cessaires et pourra imprimer des informations supplÃ©mentaires sur les paquets. Il est important de savoir quâ€™Ã  chaque fois que tu dÃ©marres une nouvelle session R (ou que tu restaures une session prÃ©cÃ©demment sauvegardÃ©e), tu dois charger les paquets que tu vas utiliser. Nous avons tendance Ã  mettre tous nos library() nÃ©cessaires Ã  notre analyse en haut de nos scripts R pour les rendre facilement accessibles et faciles Ã  complÃ©ter au fur et Ã  mesure que notre code se dÃ©veloppe. Si tu essaies dâ€™utiliser une fonction sans avoir au prÃ©alable chargÃ© le package R correspondant, tu recevras un message dâ€™erreur indiquant que R nâ€™a pas pu trouver la fonction. Par exemple, si tu essaies dâ€™utiliser la fonction install_github() sans charger le paquetage remotes ğŸ“¦ tu recevras lâ€™erreur suivante\n\ninstall_github(\"tidyverse/dplyr\")\n\n# Error in install_github(\"tidyverse/dplyr\") :\n#  could not find function \"install_github\"\n\nParfois, il peut Ãªtre utile dâ€™utiliser une fonction sans utiliser dâ€™abord le package library() fonction. Si, par exemple, tu nâ€™utilises quâ€™une ou deux fonctions dans ton script et que tu ne veux pas charger toutes les autres fonctions dâ€™un paquet, tu peux accÃ©der directement Ã  la fonction en spÃ©cifiant le nom du paquet suivi de deux points, puis du nom de la fonction.\n\nremotes::install_github(\"tidyverse/dplyr\")\n\nCâ€™est ainsi que nous avons pu utiliser le install() et install_github()fonctions ci-dessus sans charger les paquets au prÃ©alableBiocManager ğŸ“¦ et remotes ğŸ“¦ . La plupart du temps, nous recommandons dâ€™utiliser le library() fonction.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#sec-work-d",
    "href": "01-debut.html#sec-work-d",
    "title": "1Â  Pour commencer",
    "section": "\n1.4 RÃ©pertoires de travail",
    "text": "1.4 RÃ©pertoires de travail\nLe rÃ©pertoire de travail est lâ€™emplacement par dÃ©faut oÃ¹ R cherchera les fichiers que tu veux charger et oÃ¹ il mettra les fichiers que tu enregistres. Lâ€™un des avantages de lâ€™utilisation des projets RStudio est que lorsque tu ouvres un projet, il dÃ©finit automatiquement ton rÃ©pertoire de travail Ã  lâ€™emplacement appropriÃ©. Tu peux vÃ©rifier le chemin dâ€™accÃ¨s de ton rÃ©pertoire de travail en utilisant lâ€™une des deux mÃ©thodes suivantes getwd() ou here() fonctions.\n\ngetwd()\n\n[1] \"/home/julien/Documents/courses/biostats/R_way/lang/fr\"\n\n\nDans lâ€™exemple ci-dessus, le rÃ©pertoire de travail est un dossier appelÃ© â€˜R_wayâ€™ qui est un sous-dossier de â€˜biostatsâ€™ dans le dossier â€˜coursesâ€™ qui lui-mÃªme se trouve dans un dossier â€˜Documentsâ€™ situÃ© dans le dossier â€˜julienâ€™ qui lui-mÃªme se trouve dans le dossier â€˜homeâ€™. Sur un ordinateur fonctionnant sous Windows, notre rÃ©pertoire de travail comprendrait Ã©galement une lettre de lecteur (par ex. C:\\home\\julien\\Documents\\courses\\biostats\\R_way).\nSi tu nâ€™utilises pas dâ€™IDE, tu dois dÃ©finir ton rÃ©pertoire de travail Ã  lâ€™aide de la commande setwd() au dÃ©but de chaque script R (ce que nous avons fait pendant de nombreuses annÃ©es).\n\nsetwd(\"/home/julien/Documents/courses/biostats/R_way/\")\n\nCependant, le problÃ¨me avec setwd() est quâ€™il utilise un absolu qui est spÃ©cifique Ã  lâ€™ordinateur sur lequel tu travailles. Si tu veux envoyer ton script Ã  quelquâ€™un dâ€™autre (ou si tu travailles sur un autre ordinateur), ce chemin dâ€™accÃ¨s absolu ne fonctionnera pas sur lâ€™ordinateur de ton ami/collÃ¨gue car la configuration de son rÃ©pertoire sera diffÃ©rente (il est peu probable que tu aies une structure de rÃ©pertoire /home/julien/Documents/courses/biostats/ sur ton ordinateur). Il en rÃ©sulte un projet qui nâ€™est pas autonome et qui nâ€™est pas facilement transportable. Les IDE rÃ©solvent ce problÃ¨me en te permettant dâ€™utiliser relatif qui sont relatifs au fichier racine du projet. Le rÃ©pertoire du projet racine est simplement le rÃ©pertoire qui contient le fichier .Rproj dans Rstudio (first_project.Rproj dans notre cas) ou le dossier de base de ton espace de travail dans VScode. Si tu veux partager ton analyse avec quelquâ€™un dâ€™autre, il te suffit de copier lâ€™ensemble du rÃ©pertoire du projet et de lâ€™envoyer Ã  ton Ã  ton collaborateur. Il lui suffira alors dâ€™ouvrir le fichier du projet et tous les scripts R qui contiennent des rÃ©fÃ©rences Ã  des chemins de fichiers relatifs fonctionneront tout simplement. Par exemple, disons que tu as crÃ©Ã© un sous-rÃ©pertoire appelÃ© data dans ton rÃ©pertoire de projet racine qui contient un fichier dÃ©limitÃ© en csv appelÃ© mydata.csv (nous aborderons les structures de rÃ©pertoire ci-dessous (Section 1.5)). Pour importer cette base de donnÃ©es dans un projet RStudio Ã  lâ€™aide de la fonction read.csv() (ne tâ€™inquiÃ¨te pas pour lâ€™instant, nous aborderons ce sujet de faÃ§on beaucoup plus dÃ©taillÃ©e dans le ?sec-data-r), tout ce que tu dois inclure dans ton script R est\n\ndat &lt;- read.csv(\"data/mydata.csv\")\n\nParce que le chemin dâ€™accÃ¨s au fichier data/mydata.csv est relatif au rÃ©pertoire du projet, peu importe lâ€™endroit oÃ¹ ton collaborateur enregistre le rÃ©pertoire du projet sur son ordinateur, il fonctionnera toujours.\nSi tu nâ€™utilises pas un projet RStudio ou un espace de travail VScode, tu devras soit dÃ©finir le rÃ©pertoire de travail en fournissant le chemin complet de ton rÃ©pertoire, soit spÃ©cifier le chemin complet du fichier de donnÃ©es. Aucune de ces deux options nâ€™est reproductible sur dâ€™autres ordinateurs.\n\nsetwd(\"/home/julien/Documents/courses/biostats/R_way\")\n\ndat &lt;- read.csv(\"data/mydata.csv\")\n\nou\n\ndat &lt;- read.csv(\"/home/julien/Documents/courses/biostats/R_way/data/mydata.csv\")\n\nPour ceux qui veulent pousser plus loin la notion de chemins dâ€™accÃ¨s relatifs, jette un coup dâ€™Å“il Ã  lâ€™option here() de la fonction here[paquet][ici]. Les here() te permet de construire des chemins dâ€™accÃ¨s pour nâ€™importe quel fichier par rapport au rÃ©pertoire racine du projet qui sont Ã©galement indÃ©pendants du systÃ¨me dâ€™exploitation (fonctionne sur une machine Mac, Windows ou Linux). Par exemple, pour importer notre mydata.csv Ã  partir du rÃ©pertoire data il suffit dâ€™utiliser :\n\nlibrary(here) # you may need to install the here package first\ndat &lt;- read.csv(here(\"data\", \"mydata.csv\"))",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#sec-dir-struc",
    "href": "01-debut.html#sec-dir-struc",
    "title": "1Â  Pour commencer",
    "section": "\n1.5 Structure du rÃ©pertoire",
    "text": "1.5 Structure du rÃ©pertoire\nEn plus dâ€™utiliser RStudio Projects, câ€™est aussi une trÃ¨s bonne pratique de structurer ton rÃ©pertoire de travail dâ€™une maniÃ¨re cohÃ©rente et logique pour tâ€™aider et aider tes collaborateurs. Nous utilisons frÃ©quemment la structure de rÃ©pertoire suivante dans nos projets basÃ©s sur R.\n\n\n\n\n\nroot\nracinedot01\nroot-&gt;dot01\ndot1\nroot-&gt;dot1\ndata\nDonnÃ©esdot21\ndata-&gt;dot21\nfunctions\nFonctionsdot22\nfunctions-&gt;dot22\noutputs\nSortiesdot23\noutputs-&gt;dot23\nscripts\nScriptsdot24\nscripts-&gt;dot24\nwd\nrÃ©pertoire de travailLOT1\nbrutes traitÃ©es metadonnÃ©esLOT2\nfonctions RLOT4\nscripts analyse documents R markdownLOT3\npdf html figuresdot01-&gt;wd\ndot1-&gt;data\ndot2\ndot1-&gt;dot2\ndot2-&gt;functions\ndot3\ndot2-&gt;dot3\ndot3-&gt;outputs\ndot4\ndot3-&gt;dot4\ndot4-&gt;scripts\ndot21-&gt;LOT1\ndot22-&gt;LOT2\ndot23-&gt;LOT3\ndot24-&gt;LOT4\n\n\n\n\n\n\nDans notre rÃ©pertoire de travail, nous avons les rÃ©pertoires suivants :\n\nRacine - Câ€™est le rÃ©pertoire de ton projet qui contient tes .Rprojfichier . Nous avons tendance Ã  garder tous les scripts R ou [Rq]md nÃ©cessaires Ã  lâ€™analyse/au rapport dans ce dossier racine ou dans le dossier scripts lorsquâ€™il y en a trop.\ndonnÃ©es - Nous stockons toutes nos donnÃ©es dans ce rÃ©pertoire. Le sous-rÃ©pertoire appelÃ© data contient des fichiers de donnÃ©es brutes et uniquement des fichiers de donnÃ©es brutes. Ces fichiers doivent Ãªtre traitÃ©s comme des en lecture seule et ne doivent en aucun cas Ãªtre modifiÃ©s. Si tu as besoin de traiter/nettoyer/modifier tes donnÃ©es, fais-le dans R (et non dans MS Excel) car tu pourras documenter (et justifier) toutes les modifications apportÃ©es. Toutes les donnÃ©es traitÃ©es doivent Ãªtre sauvegardÃ©es dans un fichier sÃ©parÃ© et stockÃ©es dans le fichier processed_data et stockÃ©es dans le sous-rÃ©pertoire Les informations sur les mÃ©thodes de collecte des donnÃ©es, les dÃ©tails du tÃ©lÃ©chargement des donnÃ©es et toute autre mÃ©tadonnÃ©e utile doivent Ãªtre sauvegardÃ©s dans un document texte (voir les fichiers texte README ci-dessous) dans le sous-rÃ©pertoire metadata dans le sous-rÃ©pertoire\nfonctions - Il sâ€™agit dâ€™un rÃ©pertoire facultatif dans lequel nous enregistrons toutes les fonctions R personnalisÃ©es que nous avons Ã©crites pour lâ€™analyse en cours. Celles-ci peuvent ensuite Ãªtre importÃ©es dans R Ã  lâ€™aide de la commande source() fonction.\nscripts - Un rÃ©pertoire facultatif dans lequel nous enregistrons nos documents R markdown et/ou les principaux scripts R que nous avons Ã©crits pour le projet en cours sont enregistrÃ©s ici si ce nâ€™est pas dans le dossier racine.\nsortie - Les sorties de nos scripts R, telles que les tracÃ©s, les fichiers HTML et les rÃ©sumÃ©s de donnÃ©es, sont enregistrÃ©es dans ce rÃ©pertoire. Cela nous aide, ainsi que nos collaborateurs, Ã  distinguer les fichiers qui sont des sorties et ceux qui sont des fichiers sources.\n\nBien sÃ»r, la structure dÃ©crite ci-dessus est juste ce qui fonctionne pour nous la plupart du temps et doit Ãªtre considÃ©rÃ©e comme un point de dÃ©part pour tes propres besoins. Nous avons tendance Ã  avoir une structure de rÃ©pertoire assez cohÃ©rente dans tous nos projets, car cela nous permet de nous orienter rapidement lorsque nous revenons Ã  un projet aprÃ¨s un certain temps. Cela dit, les besoins varient dâ€™un projet Ã  lâ€™autre, câ€™est pourquoi nous ajoutons et supprimons des rÃ©pertoires selon les besoins.\nTu peux crÃ©er ta structure de rÃ©pertoires Ã  lâ€™aide de lâ€™Explorateur Windows (ou du Finder sur Mac) ou dans ton IDE en cliquant sur le bouton â€œNouveau dossierâ€ dans le panneau â€œFichiersâ€.\nUne autre approche consiste Ã  utiliser la fonction dir.create() de la console R.\n\n# create directory called 'data'\ndir.create(\"data\")",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#sec-rsprojs",
    "href": "01-debut.html#sec-rsprojs",
    "title": "1Â  Pour commencer",
    "section": "\n1.6 Organisation des projets",
    "text": "1.6 Organisation des projets\nComme pour la plupart des choses dans la vie, lorsquâ€™il sâ€™agit de traiter des donnÃ©es et de les analyser, les choses sont tellement plus simples si tu es organisÃ©. Une organisation claire du projet permet Ã  la fois Ã  toi (et surtout au futur toi) et Ã  tes collaborateurs de donner un sens Ã  ce que tu as fait. Il nâ€™y a rien de plus frustrant que de revenir Ã  un projet des mois (parfois des annÃ©es) plus tard et de devoir passer des jours (ou des semaines) Ã  comprendre oÃ¹ tout se trouve, ce que tu as fait et pourquoi tu lâ€™as fait. Un projet bien documentÃ© qui a une structure cohÃ©rente et logique augmente la probabilitÃ© que tu puisses reprendre lÃ  oÃ¹ tu tâ€™es arrÃªtÃ© avec un minimum dâ€™agitation, peu importe le temps qui sâ€™est Ã©coulÃ©. En outre, il est beaucoup plus facile dâ€™Ã©crire du code pour automatiser des tÃ¢ches lorsque les fichiers sont bien organisÃ©s et portent des noms judicieux. Cela est dâ€™autant plus vrai aujourdâ€™hui quâ€™il nâ€™a jamais Ã©tÃ© aussi facile de collecter de grandes quantitÃ©s de donnÃ©es qui peuvent Ãªtre sauvegardÃ©es dans des milliers, voire des centaines de milliers de fichiers de donnÃ©es distincts. Enfin, un projet bien organisÃ© rÃ©duit le risque dâ€™introduire des bogues ou des erreurs dans ton flux de travail et, sâ€™ils se produisent (ce qui arrivera inÃ©vitablement Ã  un moment ou Ã  un autre), il est plus facile de repÃ©rer ces erreurs et de les traiter efficacement.\nIl y a aussi quelques mesures simples que tu peux prendre dÃ¨s le dÃ©but dâ€™un projet pour aider Ã  maintenir les choses en bon Ã©tat.\nUne bonne faÃ§on dâ€™organiser les choses est dâ€™utiliser les espaces de travail RStudio Projects ou VSCode, appelÃ©s par la suite project. A project conserve tous tes scripts R, tes documents R markdown, tes fonctions R et tes donnÃ©es en un seul endroit. Ce quâ€™il y a de bien avec project est que chacun a son propre rÃ©pertoire, son propre historique et ses propres documents sources, de sorte que les diffÃ©rentes analyses sur lesquelles tu travailles restent complÃ¨tement sÃ©parÃ©es les unes des autres. Cela signifie que tu peux trÃ¨s facilement passer dâ€™une analyse Ã  lâ€™autre. projects sans craindre quâ€™elles nâ€™interfÃ¨rent lâ€™une avec lâ€™autre.\n\n1.6.1 RStudio\nPour crÃ©er un projet, ouvre RStudio et sÃ©lectionne File -&gt; New Project... dans le menu. Tu peux crÃ©er soit un tout nouveau projet, soit un projet Ã  partir dâ€™un rÃ©pertoire existant, soit un projet Ã  version contrÃ´lÃ©e (voir ?sec-github_r pour plus de dÃ©tails Ã  ce sujet). Dans ce chapitre, nous allons crÃ©er un projet dans un nouveau rÃ©pertoire.\n\n\n\n\n\n\n\n\nTu peux Ã©galement crÃ©er un nouveau projet en cliquant sur le bouton â€œProjetâ€ en haut Ã  droite de RStudio et en sÃ©lectionnant â€œNouveau projetâ€¦\n\n\n\n\n\n\n\n\nDans la fenÃªtre suivante, sÃ©lectionne â€˜Nouveau projetâ€™.\n\n\n\n\n\n\n\n\nSaisis maintenant le nom du rÃ©pertoire que tu veux crÃ©er dans le champ â€œNom du rÃ©pertoire :â€ (nous lâ€™appellerons first_project pour ce chapitre). Si tu veux changer lâ€™emplacement du rÃ©pertoire sur ton ordinateur, clique sur le bouton â€˜Parcourirâ€¦â€™ et navigue jusquâ€™Ã  lâ€™endroit oÃ¹ tu souhaites crÃ©er le rÃ©pertoire. Nous cochons toujours la case â€œOuvrir dans une nouvelle sessionâ€. Enfin, clique sur â€˜CrÃ©er un projetâ€™ pour crÃ©er le nouveau projet.\n\n\n\n\n\n\n\n\nUne fois ton nouveau projet crÃ©Ã©, tu auras un nouveau dossier sur ton ordinateur qui contiendra un fichier de projet RStudio appelÃ© first_project.Rproj. Ce projet .Rproj contient diverses options de projet (mais tu ne devrais pas vraiment interagir avec lui) et peut Ã©galement Ãªtre utilisÃ© comme raccourci pour ouvrir le projet directement Ã  partir du systÃ¨me de fichiers (il suffit de double-cliquer dessus). Tu peux le vÃ©rifier dans lâ€™onglet â€˜Fichiersâ€™ de RStudio (ou dans Finder si tu es sur un Mac ou dans lâ€™Explorateur de fichiers sous Windows).\n\n\n\n\n\n\n\n\nLa derniÃ¨re chose que nous te suggÃ©rons de faire est de sÃ©lectionner Tools -&gt; Project Options... dans le menu. Clique sur lâ€™onglet â€˜GÃ©nÃ©ralâ€™ sur le cÃ´tÃ© gauche et modifie les valeurs de â€˜Restaurer .RData dans lâ€™espace de travail au dÃ©marrageâ€™ et â€˜Sauvegarder lâ€™espace de travail dans .RData Ã  la sortieâ€™ de â€˜Par dÃ©fautâ€™ Ã  â€˜Nonâ€™. Ainsi, Ã  chaque fois que tu ouvres ton projet, tu dÃ©marres avec une session R propre. Tu nâ€™es pas obligÃ© de faire cela (beaucoup de gens ne le font pas) mais nous prÃ©fÃ©rons commencer avec un espace de travail complÃ¨tement propre chaque fois que nous ouvrons nos projets pour Ã©viter tout conflit potentiel avec des choses que nous avons faites dans des sessions prÃ©cÃ©dentes (ce qui conduit parfois Ã  des rÃ©sultats surprenants et Ã  des maux de tÃªte pour trouver le problÃ¨me). Lâ€™inconvÃ©nient de cette mÃ©thode est que tu devras rÃ©exÃ©cuter ton code R Ã  chaque fois que tu ouvriras ton projet.\n\n\n\n\n\n\n\n\nMaintenant que tu as mis en place un projet RStudio, tu peux commencer Ã  crÃ©er des scripts R (ou R markdown/ Quarto, ?sec-rmarkdown_r) ou tout ce dont tu as besoin pour complÃ©ter ton projet. Tous les scripts R seront maintenant contenus dans le projet RStudio et enregistrÃ©s dans le dossier du projet.\n\n1.6.2 VSCode\nsont similaires aux projets RStudio. Tu dois cependant crÃ©er un nouveau dossier avec un fichier R (ou un fichier texte) et lâ€™enregistrer en tant quâ€™espace de travail.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#sec-file_names",
    "href": "01-debut.html#sec-file_names",
    "title": "1Â  Pour commencer",
    "section": "\n1.7 Noms des fichiers",
    "text": "1.7 Noms des fichiers\nLe nom que tu donnes Ã  tes fichiers a plus dâ€™importance que tu ne le penses. Nommer les fichiers est Ã©galement plus difficile que tu ne le penses. Pour quâ€™un nom de fichier soit â€œbonâ€, il faut quâ€™il soit informatif et relativement court. Ce nâ€™est pas toujours un compromis facile et il faut souvent y rÃ©flÃ©chir. Dans lâ€™idÃ©al, tu devrais essayer dâ€™Ã©viter les Ã©lÃ©ments suivants !\n\n\n\n\nsource:https://xkcd.com/1459/\n\n\n\nBien quâ€™il nâ€™y ait pas vraiment dâ€™approche standard reconnue pour nommer les fichiers (en fait il y a mais tout le monde ne lâ€™utilise pas), il y a quelques points Ã  garder Ã  lâ€™esprit.\n\nTout dâ€™abord, Ã©vite dâ€™utiliser des espaces dans les noms de fichiers en les remplaÃ§ant par des traits de soulignement ou mÃªme des traits dâ€™union. Pourquoi cela est-il important ? Lâ€™une des raisons est que certains logiciels de ligne de commande (en particulier de nombreux outils bioinformatiques) ne reconnaissent pas un nom de fichier comportant un espace et que tu devras te livrer Ã  toutes sortes de manigances en utilisant des caractÃ¨res dâ€™Ã©chappement pour tâ€™assurer que les espaces sont traitÃ©s correctement. MÃªme si tu ne penses pas utiliser un jour un logiciel de ligne de commande, il se peut que tu le fasses indirectement. Prends R markdown par exemple, si tu veux convertir un document R markdown en pdf en utilisant la commande rmarkdown ğŸ“¦ tu utiliseras en fait un moteur \\(\\LaTeX\\) en ligne de commande sous le capot (appelÃ© Pandoc). Une autre bonne raison de ne pas utiliser dâ€™espaces dans les noms de fichiers est que cela rend la recherche de noms de fichiers (ou de parties de noms de fichiers) Ã  lâ€™aide dâ€™expressions rÃ©guliÃ¨res dans R (ou tout autre langage).\nPour les raisons Ã©voquÃ©es plus haut, Ã©vite Ã©galement dâ€™utiliser des caractÃ¨res spÃ©ciaux (câ€™est-Ã -dire @Â£$%^&*(:/)) dans tes noms de fichiers.\nSi tu mets en place des versions de tes fichiers avec des numÃ©ros sÃ©quentiels (par ex. fichier1, fichier2, fichier3, â€¦) et que tu as plus de 9 fichiers, tu dois utiliser 01, 02, 03 â€¦ 10 pour tâ€™assurer que les fichiers sont imprimÃ©s dans le bon ordre (vois ce qui se passe si tu ne le fais pas). Si tu as plus de 99 fichiers, utilise 001, 002, 003â€¦ etc.\nSi les noms de tes fichiers contiennent des dates, utilise le format ISO 8601 AAAA-MM-JJ (ou AAAAMMJJ) pour tâ€™assurer que tes fichiers sont classÃ©s dans le bon ordre chronologique.\nNâ€™utilise jamais le mot final dans un nom de fichier - il ne lâ€™est jamais !\n\nQuelle que soit la convention de dÃ©nomination des fichiers que tu dÃ©cides dâ€™utiliser, essaie de lâ€™adopter rapidement, de tâ€™y tenir et dâ€™Ãªtre cohÃ©rent. Tu nous remercieras !",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#sec-proj_doc",
    "href": "01-debut.html#sec-proj_doc",
    "title": "1Â  Pour commencer",
    "section": "\n1.8 Documentation sur les scripts",
    "text": "1.8 Documentation sur les scripts\nUn petit mot ou deux sur lâ€™Ã©criture du code R et la crÃ©ation de scripts R. Ã€ moins que tu ne fasses quelque chose de vraiment rapide et sale, nous te suggÃ©rons de toujours Ã©crire ton code R sous la forme dâ€™un script R. Les scripts R sont ce qui rend R si utile. Non seulement tu as un enregistrement complet de ton analyse, de la manipulation des donnÃ©es Ã  la visualisation et Ã  lâ€™analyse statistique, mais tu peux aussi partager ce code (et ces donnÃ©es) avec tes amis, tes collÃ¨gues et, surtout, lorsque tu soumets et publies tes recherches dans une revue. Dans cette optique, assure-toi dâ€™inclure dans ton script R toutes les informations nÃ©cessaires pour rendre ton travail reproductible (noms des auteurs, dates, plan dâ€™Ã©chantillonnage, etc). Ces informations peuvent Ãªtre incluses sous la forme dâ€™une sÃ©rie de commentaires # ou, mieux encore, en mÃ©langeant le code exÃ©cutable et la narration dans un script R markdown (?sec-rmarkdown_r). Câ€™est aussi une bonne pratique dâ€™inclure la sortie de la fonction sessionInfo() Ã  la fin de tout script qui imprime la version de R, les dÃ©tails du systÃ¨me dâ€™exploitation et les paquets chargÃ©s. Une trÃ¨s bonne alternative consiste Ã  utiliser la fonction session_info() de la fonction xfun ğŸ“¦ pour obtenir un rÃ©sumÃ© plus concis de lâ€™environnement de notre session.\nVoici un exemple dâ€™inclusion de mÃ©ta-informations au dÃ©but dâ€™un script R\n\n# Title: Time series analysis of lasagna consumption\n\n# Purpose : This script performs a time series analyses on\n#           lasagna meals kids want to have each week.\n#           Data consists of counts of (dreamed) lasagna meals per week\n#           collected from 24 kids at the \"Food-dreaming\" school\n#           between 2042 and 2056.\n\n# data file: lasagna_dreams.csv\n\n# Author: A.\nStomach\n# Contact details: a.stomach@food.uni.com\n\n# Date script created: Fri Mar 29 17:06:44 2010 -----------\n# Date script last modified: Thu Dec 12 16:07:12 2019 ----\n\n# package dependencies\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nprint(\"put your lovely R code here\")\n\n# good practice to include session information\n\nxfun::session_info()\n\nCe nâ€™est quâ€™un exemple et il nâ€™y a pas de rÃ¨gles strictes, alors nâ€™hÃ©site pas Ã  mettre au point un systÃ¨me qui te convient. Un raccourci trÃ¨s utile dans RStudio consiste Ã  inclure automatiquement un horodatage dans ton script R. Pour ce faire, Ã©cris ts Ã  lâ€™endroit oÃ¹ tu veux insÃ©rer ton horodateur dans ton script R, puis appuie sur les touches â€˜shift + tabâ€™. RStudio convertira comme par magie ts en date et heure actuelles et commentera automatiquement cette ligne avec un #. Un autre raccourci RStudio trÃ¨s utile consiste Ã  commenter plusieurs lignes de ton script Ã  lâ€™aide dâ€™un # symbole. Pour ce faire, surligne les lignes de texte que tu veux commenter et appuie sur â€˜ctrl + shift + câ€™ (ou â€˜cmd + shift + câ€™ sur un mac). Pour dÃ©commenter les lignes, utilise Ã  nouveau â€˜ctrl + shift + câ€™.\nEn plus dâ€™inclure des mÃ©tadonnÃ©es dans tes scripts R, il est Ã©galement courant de crÃ©er un fichier texte sÃ©parÃ© pour enregistrer les informations importantes. Par convention, ces fichiers texte sont nommÃ©s README. Nous incluons souvent un README dans le rÃ©pertoire oÃ¹ nous conservons nos donnÃ©es brutes. Dans ce fichier, nous incluons des dÃ©tails sur le moment oÃ¹ les donnÃ©es ont Ã©tÃ© collectÃ©es (ou tÃ©lÃ©chargÃ©es), la maniÃ¨re dont elles ont Ã©tÃ© collectÃ©es, des informations sur le matÃ©riel spÃ©cialisÃ©, les mÃ©thodes de conservation, le type et la version de toute machine utilisÃ©e (câ€™est-Ã -dire. Ã©quipement de sÃ©quenÃ§age), etc. Tu peux crÃ©er un fichier README pour ton projet dans RStudio en cliquant sur le bouton File -&gt; New File -&gt; Text File menu.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#guide-de-style-r",
    "href": "01-debut.html#guide-de-style-r",
    "title": "1Â  Pour commencer",
    "section": "\n1.9 Guide de style R",
    "text": "1.9 Guide de style R\nLa faÃ§on dont tu Ã©cris ton code dÃ©pend plus ou moins de toi, mÃªme si ton objectif doit Ãªtre de le rendre aussi facile Ã  lire que possible (pour toi et pour les autres). Bien quâ€™il nâ€™y ait pas de rÃ¨gles (ni de police du code), nous tâ€™encourageons Ã  prendre lâ€™habitude dâ€™Ã©crire un code R lisible en adoptant un style particulier. Nous te suggÃ©rons de suivre le guide de style Rde Google style-google dans la mesure du possible. Ce guide de style tâ€™aidera Ã  dÃ©cider oÃ¹ utiliser les espaces, comment indenter le code et comment utiliser les carrÃ©s. [ ] et du curly { } entre autres choses.\nPour tâ€™aider Ã  formater ton code :\n\nVSCode il y a un formateur intÃ©grÃ© dans lâ€™extension R pour VSCode. Il te suffit dâ€™utiliser le raccourci clavier pour reformater joliment et automatiquement le code.\nPour RStudio, tu peux installer lâ€™extension styler ğŸ“¦ qui comprend un complÃ©ment RStudio te permettant de remanier automatiquement le code sÃ©lectionnÃ© (ou des fichiers et des projets entiers) dâ€™un simple clic de souris. Tu peux trouver plus dâ€™informations sur le styler ğŸ“¦y compris comment lâ€™installer [ici][styliste]. Une fois installÃ©, tu peux mettre en Ã©vidence le code que tu veux remanier, cliquer sur le bouton â€œAddinsâ€ en haut de RStudio et sÃ©lectionner lâ€™option â€œStyle Selectionâ€. Voici un exemple de code R mal formatÃ©\n\n\n\n\n\n\n\n\n\nMets maintenant le code en surbrillance et utilise lâ€™option styler ğŸ“¦ pour reformater\n\n\n\n\n\n\n\n\nPour produire un code joliment formatÃ©",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#sauvegarde-des-projets",
    "href": "01-debut.html#sauvegarde-des-projets",
    "title": "1Â  Pour commencer",
    "section": "\n1.10 Sauvegarde des projets",
    "text": "1.10 Sauvegarde des projets\nNe sois pas cette personne qui perd des donnÃ©es et des analyses durement gagnÃ©es (et souvent coÃ»teuses). Ne sois pas cette personne qui pense que Ã§a ne mâ€™arrivera jamais - Ã§a arrivera ! Pense toujours au pire scÃ©nario absolu, Ã  quelque chose qui te donne des sueurs froides en te rÃ©veillant la nuit, et fais tout ton possible pour que cela nâ€™arrive jamais. Pour Ãªtre clair, si tu comptes copier tes prÃ©cieux fichiers sur un disque dur externe ou une clÃ© USB, ce nâ€™estâ€¦ PAS une stratÃ©gie de sauvegarde efficace. Ces choses tournent mal tout le temps lorsque tu les glisses dans ton sac Ã  dos ou ton â€œsac pour la vieâ€ et que tu les trimballes entre ton bureau et ta maison. MÃªme si tu les laisses branchÃ©s sur ton ordinateur, que se passe-t-il lorsque le bÃ¢timent brÃ»le (nous avons bien dit le pire des cas !) ?\nIdÃ©alement, tes sauvegardes devraient Ãªtre hors site et incrÃ©mentielles. Heureusement, il existe de nombreuses options pour sauvegarder tes fichiers. La premiÃ¨re chose Ã  faire est de chercher dans ton propre institut. La plupart (toutes ?) des universitÃ©s disposent dâ€™une forme de stockage en rÃ©seau qui devrait Ãªtre facilement accessible et qui est Ã©galement soutenue par un plan complet de reprise aprÃ¨s sinistre. Dâ€™autres options incluent des services basÃ©s sur le cloud tels que Google Drive et Dropbox (pour nâ€™en citer que quelques-uns), mais assure-toi que tu ne stockes pas de donnÃ©es sensibles sur ces services et que tu es Ã  lâ€™aise avec les politiques de confidentialitÃ© qui font souvent lâ€™effet dâ€™une douche froide.\nAlors que ces services sont plutÃ´t bons pour stocker des fichiers, ils ne sont pas vraiment utiles pour les sauvegardes incrÃ©mentielles. Pour trouver les versions prÃ©cÃ©dentes des fichiers, il faut souvent passer un temps fou Ã  parcourir plusieurs fichiers nommÃ©s â€˜final.docâ€™, â€˜final_v2.docâ€™ et â€˜final_usethisone.docâ€™ etc. jusquâ€™Ã  ce que tu trouves celui que tu cherches. Le meilleur moyen que nous connaissons pour Ã  la fois sauvegarder les fichiers et gÃ©rer les diffÃ©rentes versions des fichiers est dâ€™utiliser Git et GitHub. Pour en savoir plus sur la faÃ§on dont tu peux utiliser RStudio, Git et GitHub ensemble, consulte le ?sec-github_r.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "01-debut.html#citation-de-r",
    "href": "01-debut.html#citation-de-r",
    "title": "1Â  Pour commencer",
    "section": "\n1.11 Citation de R",
    "text": "1.11 Citation de R\nDe nombreuses personnes ont investi Ã©normÃ©ment de temps et dâ€™Ã©nergie pour faire de R lâ€™excellent logiciel que tu utilises aujourdâ€™hui. Si tu utilises R dans ton travail (et nous espÃ©rons que tu le feras), nâ€™oublie pas de le citer. Pour obtenir la citation la plus rÃ©cente de R, tu peux utiliser le site citation() fonction.\n\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2024). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  &lt;https://www.R-project.org/&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2024},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\nSi tu veux citer un logiciel particulier que tu as utilisÃ© pour lâ€™analyse de tes donnÃ©es.\n\ncitation(package = \"here\")\n\nTo cite package 'here' in publications use:\n\n  MÃ¼ller K (2020). _here: A Simpler Way to Find Your Files_. R package\n  version 1.0.1, &lt;https://CRAN.R-project.org/package=here&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {here: A Simpler Way to Find Your Files},\n    author = {Kirill MÃ¼ller},\n    year = {2020},\n    note = {R package version 1.0.1},\n    url = {https://CRAN.R-project.org/package=here},\n  }\n\n\nPour citer plusieurs paquets, le paquet grateful ğŸ“¦ est extrÃªmement utile. Voir TableÂ 1 pour un exemple de rÃ©sultat produit avec grateful.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Pour commencer</span>"
    ]
  },
  {
    "objectID": "02-introR.html",
    "href": "02-introR.html",
    "title": "\n2Â  Introduction Ã  R\n",
    "section": "",
    "text": "2.1 Paquets et donnÃ©es requises pour le labo\nCe laboratoire nÃ©cessite:",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Introduction Ã  R</span>"
    ]
  },
  {
    "objectID": "02-introR.html#set-intro",
    "href": "02-introR.html#set-intro",
    "title": "\n2Â  Introduction Ã  R\n",
    "section": "",
    "text": "les paquets R:\n\nquestionr\nggplot2\n\n\nles fichiers de donnÃ©es\n\nErablesGatineau.csv\nsturgeon.csv",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Introduction Ã  R</span>"
    ]
  },
  {
    "objectID": "02-introR.html#premier-pas-avec-r",
    "href": "02-introR.html#premier-pas-avec-r",
    "title": "\n2Â  Introduction Ã  R\n",
    "section": "\n2.2 Premier pas avec R",
    "text": "2.2 Premier pas avec R\nUne fois R et RStudio installÃ©s sur votre machine, nous nâ€™allons pas lancer R mais plutÃ´t RStudio.\nRStudio nâ€™est pas Ã  proprement parler une interface graphique qui permettrait dâ€™utiliser R de maniÃ¨re â€œclassiqueâ€ via la souris, des menus et des boÃ®tes de dialogue. Il sâ€™agit plutÃ´t de ce quâ€™on appelle un Environnement de dÃ©veloppement intÃ©grÃ© (IDE) qui facilite lâ€™utilisation de R et le dÃ©veloppement de scripts.\n\n2.2.1 La console\n\n2.2.1.1 Lâ€™invite de commandes\nAu premier lancement de RStudio, lâ€™Ã©cran principal est dÃ©coupÃ© en trois grandes zonesÂ :\n\n\n\n\n\nInterface de RStudio\n\n\n\nLa zone de gauche se nomme Console. Ã€ son dÃ©marrage, RStudio a lancÃ© une nouvelle session de R et câ€™est dans cette fenÃªtre que nous allons pouvoir interagir avec lui.\nLa Console doit normalement afficher un texte de bienvenue ressemblant Ã  ceciÂ :\nR version 4.0.2 (2020-06-22) -- \"Taking Off Again\"\nCopyright (C) 2020 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu (64-bit)\n\nR est un logiciel libre livrÃ© sans AUCUNE GARANTIE.\nVous pouvez le redistribuer sous certaines conditions.\nTapez 'license()' ou 'licence()' pour plus de dÃ©tails.\n\nR est un projet collaboratif avec de nombreux contributeurs.\nTapez 'contributors()' pour plus d'information et\n'citation()' pour la faÃ§on de le citer dans les publications.\n\nTapez 'demo()' pour des dÃ©monstrations, 'help()' pour l'aide\nen ligne ou 'help.start()' pour obtenir l'aide au format HTML.\nTapez 'q()' pour quitter R.\nsuivi dâ€™une ligne commenÃ§ant par le caractÃ¨re &gt; et sur laquelle devrait se trouver votre curseur. Cette ligne est appelÃ©e lâ€™invite de commande (ou prompt en anglais). Elle signifie que R est disponible et en attente de votre prochaine commande.\nNous pouvons tout de suite lui fournir une premiÃ¨re commande, en saisissant le texte suivant puis en appuyant sur EntrÃ©eÂ :\n\n2 + 2\n\n[1] 4\n\n\nR nous rÃ©pond immÃ©diatement, et nous pouvons constater avec soulagement quâ€™il sait faire des additions Ã  un chiffre1. On peut donc continuer avec dâ€™autres opÃ©rationsÂ :\n\n5 - 7\n\n[1] -2\n\n4 * 12\n\n[1] 48\n\n-10 / 3\n\n[1] -3.333333\n\n5^2\n\n[1] 25\n\n\nCette derniÃ¨re opÃ©ration utilise le symbole ^ qui reprÃ©sente lâ€™opÃ©ration puissance. 5^2 signifie donc â€œ5 au carrÃ©â€, soit 25.\n\n2.2.1.2 PrÃ©cisions concernant la saisie des commandes\nLorsquâ€™on saisit une commande, les espaces autour des opÃ©rateurs nâ€™ont pas dâ€™importance. Les trois commandes suivantes sont donc Ã©quivalentes, mais on privilÃ©gie en gÃ©nÃ©ral la deuxiÃ¨me pour des raisons de lisibilitÃ© du code.\n\n10+2\n10 + 2\n10       +       2\n\nQuand vous Ãªtes dans la console, vous pouvez utiliser les flÃ¨ches vers le haut et vers le bas pour naviguer dans lâ€™historique des commandes que vous avez tapÃ©es prÃ©cÃ©demment. Vous pouvez Ã  tout moment modifier la commande affichÃ©e, et lâ€™exÃ©cuter en appuyant sur EntrÃ©e.\nEnfin, il peut arriver quâ€™on saisisse une commande de maniÃ¨re incomplÃ¨teÂ : oubli dâ€™une parenthÃ¨se, faute de frappe, etc. Dans ce cas, R remplace lâ€™invite de commande habituel par un signe +Â :\n\n4 *\n+\n\nCela signifie quâ€™il â€œattend la suiteâ€. On peut alors soit complÃ©ter la commande sur cette nouvelle ligne et appuyer sur EntrÃ©e, soit, si on est perdu, tout annuler et revenir Ã  lâ€™invite de commandes normal en appuyant sur Esc ou Ã‰chap.\n\n2.2.2 Objets\n\n2.2.2.1 Objets simples\nFaire des calculs câ€™est bien, mais il serait intÃ©ressant de pouvoir stocker un rÃ©sultat quelque part pour pouvoir le rÃ©utiliser ultÃ©rieurement sans avoir Ã  faire du copier/coller.\nPour conserver le rÃ©sultat dâ€™une opÃ©ration, on peut le stocker dans un objet Ã  lâ€™aide de lâ€™opÃ©rateur dâ€™assignation &lt;-. Cette â€œflÃ¨cheâ€ stocke ce quâ€™il y a Ã  sa droite dans un objet dont le nom est indiquÃ© Ã  sa gauche.\nPrenons tout de suite un exempleÂ :\n\nx &lt;- 2\n\nCette commande peut se lire â€œprend la valeur 2 et mets la dans un objet qui sâ€™appelle xâ€.\nSi on exÃ©cute une commande comportant juste le nom dâ€™un objet, R affiche son contenuÂ :\n\nx\n\n[1] 2\n\n\nOn voit donc que notre objet x contient bien la valeur 2.\nOn peut Ã©videmment rÃ©utiliser cet objet dans dâ€™autres opÃ©rations. R le remplacera alors par sa valeurÂ :\n\nx + 4\n\n[1] 6\n\n\nOn peut crÃ©er autant dâ€™objets quâ€™on le souhaite.\n\nx &lt;- 2\ny &lt;- 5\nresultat &lt;- x + y\nresultat\n\n[1] 7\n\n\n\n\n\n\n\n\nImportant\n\n\n\nLes noms dâ€™objets peuvent contenir des lettres, des chiffres, les symboles . et _. Ils ne peuvent pas commencer par un chiffre. Attention, R fait la diffÃ©rence entre minuscules et majuscules dans les noms dâ€™objets, ce qui signifie que x et X seront deux objets diffÃ©rents, tout comme resultat et Resultat.\nDe maniÃ¨re gÃ©nÃ©rale, il est prÃ©fÃ©rable dâ€™Ã©viter les majuscules (pour les risques dâ€™erreur) et les caractÃ¨res accentuÃ©s (pour des questions dâ€™encodage) dans les noms dâ€™objets.\nDe mÃªme, il faut essayer de trouver un Ã©quilibre entre clartÃ© du nom (comprendre Ã  quoi sert lâ€™objet, ce quâ€™il contient) et sa longueur. Par exemple, on prÃ©fÃ¨rera comme nom dâ€™objet taille_conj1 Ã  taille_du_conjoint_numero_1 (trop long) ou Ã  t1 (pas assez explicite).\n\n\nQuand on assigne une nouvelle valeur Ã  un objet dÃ©jÃ  existant, la valeur prÃ©cÃ©dente est perdue. Les objets nâ€™ont pas de mÃ©moire.\n\nx &lt;- 2\nx &lt;- 5\nx\n\n[1] 5\n\n\nDe la mÃªme maniÃ¨re, assigner un objet Ã  un autre ne crÃ©e pas de â€œlienâ€ entre les deux. Cela copie juste la valeur de lâ€™objet de droite dans celui de gaucheÂ :\n\nx &lt;- 1\ny &lt;- 3\nx &lt;- y\nx\n\n[1] 3\n\n## Si on modifie y, cela ne modifie pas x\ny &lt;- 4\nx\n\n[1] 3\n\n\nOn le verra, les objets peuvent contenir tout un tas dâ€™informations. Jusquâ€™ici on nâ€™a stockÃ© que des nombres, mais ils peuvent aussi contenir des chaÃ®nes de caractÃ¨res (du texte), quâ€™on dÃ©limite avec des guillemets simples ou doubles (' ou \")Â :\n\nchien &lt;- \"Chihuahua\"\nchien\n\n[1] \"Chihuahua\"\n\n\n\n2.2.3 Vecteurs\nImaginons maintenant quâ€™on a demandÃ© la taille en centimÃ¨tres de 5 personnes et quâ€™on souhaite calculer leur taille moyenne. On pourrait crÃ©er autant dâ€™objets que de tailles et faire lâ€™opÃ©ration mathÃ©matique qui va bienÂ :\n\ntaille1 &lt;- 156\ntaille2 &lt;- 164\ntaille3 &lt;- 197\ntaille4 &lt;- 147\ntaille5 &lt;- 173\n(taille1 + taille2 + taille3 + taille4 + taille5) / 5\n\n[1] 167.4\n\n\nCette maniÃ¨re de faire nâ€™est Ã©videmment pas pratique du tout. On va plutÃ´t stocker lâ€™ensemble de nos tailles dans un seul objet, de type vecteur, avec la syntaxe suivanteÂ :\n\ntailles &lt;- c(156, 164, 197, 147, 173)\n\nSi on affiche le contenu de cet objet, on voit quâ€™il contient bien lâ€™ensemble des tailles saisiesÂ :\n\ntailles\n\n[1] 156 164 197 147 173\n\n\nUn vecteur dans R est un objet qui peut contenir plusieurs informations du mÃªme type, potentiellement en trÃ¨s grand nombre.\nLâ€™avantage dâ€™un vecteur est que lorsquâ€™on lui applique une opÃ©ration, celle-ci sâ€™applique Ã  toutes les valeurs quâ€™il contient. Ainsi, si on veut la taille en mÃ¨tres plutÃ´t quâ€™en centimÃ¨tres, on peut faireÂ :\n\ntailles_m &lt;- tailles / 100\ntailles_m\n\n[1] 1.56 1.64 1.97 1.47 1.73\n\n\nCela fonctionne pour toutes les opÃ©rations de baseÂ :\n\ntailles + 10\n\n[1] 166 174 207 157 183\n\ntailles^2\n\n[1] 24336 26896 38809 21609 29929\n\n\nImaginons maintenant quâ€™on a aussi demandÃ© aux cinq mÃªmes personnes leur poids en kilos. On peut alors crÃ©er un deuxiÃ¨me vecteurÂ :\n\npoids &lt;- c(45, 59, 110, 44, 88)\n\nOn peut alors effectuer des calculs utilisant nos deux vecteurs tailles et poids. On peut par exemple calculer lâ€™indice de masse corporelle (IMC) de chacun de nos enquÃªtÃ©s en divisant leur poids en kilo par leur taille en mÃ¨tre au carrÃ©Â :\n\nimc &lt;- poids / (tailles / 100) ^ 2\nimc\n\n[1] 18.49112 21.93635 28.34394 20.36189 29.40292\n\n\nUn vecteur peut contenir des nombres, mais il peut aussi contenir du texte. Imaginons quâ€™on a demandÃ© aux 5 mÃªmes personnes leur niveau de diplÃ´meÂ : on peut regrouper lâ€™information dans un vecteur de chaÃ®nes de caractÃ¨res. Une chaÃ®ne de caractÃ¨re contient du texte libre, dÃ©limitÃ© par des guillemets simples ou doublesÂ :\n\ndiplome &lt;- c(\"PHD\", \"Bac\", \"MSc\", \"MSc\", \"Bac\")\ndiplome\n\n[1] \"PHD\" \"Bac\" \"MSc\" \"MSc\" \"Bac\"\n\n\nLâ€™opÃ©rateur :, lui, permet de gÃ©nÃ©rer rapidement un vecteur comprenant tous les nombres entre deux valeurs, opÃ©ration assez courante sous RÂ :\n\nx &lt;- 1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nEnfin, notons quâ€™on peut accÃ©der Ã  un Ã©lÃ©ment particulier dâ€™un vecteur en faisant suivre le nom du vecteur de crochets contenant le numÃ©ro de lâ€™Ã©lÃ©ment dÃ©sirÃ©. Par exempleÂ :\n\ndiplome[2]\n\n[1] \"Bac\"\n\n\nCette opÃ©ration, qui utilise lâ€™opÃ©rateur [], permet donc la sÃ©lection dâ€™Ã©lÃ©ments dâ€™un vecteur.\nDerniÃ¨re remarque, si on affiche dans la console un vecteur avec beaucoup dâ€™Ã©lÃ©ments, ceux-ci seront rÃ©partis sur plusieurs lignes. Par exemple, si on a un vecteur de 50 nombres on peut obtenir quelque chose commeÂ :\n [1] 294 425 339 914 114 896 716 648 915 587 181 926 489\n[14] 848 583 182 662 888 417 133 146 322 400 698 506 944\n[27] 237 324 333 443 487 658 793 288 897 588 697 439 697\n[40] 914 694 126 969 744 927 337 439 226 704 635\nOn remarque que R ajoute systÃ©matiquement un nombre entre crochets au dÃ©but de chaque ligneÂ : il sâ€™agit en fait de la position du premier Ã©lÃ©ment de la ligne dans le vecteur. Ainsi, le 848 de la deuxiÃ¨me ligne est le 14e Ã©lÃ©ment du vecteur, le 914 de la derniÃ¨re ligne est le 40e, etc.\nCeci explique le [1] quâ€™on obtient quand on affiche un simple nombre et permet de constater que pour R, un nombre est un vecteur Ã  un seul Ã©lÃ©mentÂ :\n [1] 4\n\n2.2.4 Fonctions\n\n2.2.4.1 Principe\nNous savons dÃ©sormais effectuer des opÃ©rations arithmÃ©tiques de base sur des nombres et des vecteurs, et stocker des valeurs dans des objets pour pouvoir les rÃ©utiliser plus tard.\nPour aller plus loin, nous devons aborder les fonctions qui sont, avec les objets, un deuxiÃ¨me concept de base de R. On utilise des fonctions pour effectuer des calculs, obtenir des rÃ©sultats et accomplir des actions.\nFormellement, une fonction a un nom, elle prend en entrÃ©e entre parenthÃ¨ses un ou plusieurs arguments (ou paramÃ¨tres), et retourne un rÃ©sultat.\nPrenons tout de suite un exemple. Si on veut connaÃ®tre le nombre dâ€™Ã©lÃ©ments du vecteur tailles que nous avons construit prÃ©cÃ©demment, on peut utiliser la fonction length, de cette maniÃ¨reÂ :\n\nlength(tailles)\n\n[1] 5\n\n\nIci, length est le nom de la fonction, on lâ€™appelle en lui passant un argument entre parenthÃ¨ses (en lâ€™occurrence notre vecteur tailles), et elle nous renvoie un rÃ©sultat, Ã  savoir le nombre dâ€™Ã©lÃ©ments du vecteur passÃ© en paramÃ¨tre.\nAutre exemple, les fonctions min et max retournent respectivement les valeurs minimales et maximales dâ€™un vecteur de nombresÂ :\n\nmin(tailles)\n\n[1] 147\n\nmax(tailles)\n\n[1] 197\n\n\nLa fonction mean calcule et retourne la moyenne dâ€™un vecteur de nombresÂ :\n\nmean(tailles)\n\n[1] 167.4\n\n\nLa fonction sum retourne la somme de tous les Ã©lÃ©ments du vecteurÂ :\n\nsum(tailles)\n\n[1] 837\n\n\nJusquâ€™Ã  prÃ©sent on nâ€™a vu que des fonctions qui calculent et retournent un unique nombre. Mais une fonction peut renvoyer dâ€™autres types de rÃ©sultats. Par exemple, la fonction range (Ã©tendue) renvoie un vecteur de deux nombres, le minimum et le maximumÂ :\n\nrange(tailles)\n\n[1] 147 197\n\n\nOu encore, la fonction unique, qui supprime toutes les valeurs en double dans un vecteur, quâ€™il sâ€™agisse de nombres ou de chaÃ®nes de caractÃ¨resÂ :\n\ndiplome\n\n[1] \"PHD\" \"Bac\" \"MSc\" \"MSc\" \"Bac\"\n\nunique(diplome)\n\n[1] \"PHD\" \"Bac\" \"MSc\"\n\n\n\n2.2.4.2 Arguments\nUne fonction peut prendre plusieurs arguments, dans ce cas on les indique toujours entre parenthÃ¨ses, sÃ©parÃ©s par des virgules.\nOn a dÃ©jÃ  rencontrÃ© un exemple de fonction acceptant plusieurs argumentsÂ : la fonction c, qui combine lâ€™ensemble de ses arguments en un vecteur2Â :\n\ntailles &lt;- c(156, 164, 197, 181, 173)\n\nIci, c est appelÃ©e en lui passant cinq arguments, les cinq tailles sÃ©parÃ©es par des virgules, et elle renvoie un vecteur numÃ©rique regroupant ces cinq valeurs.\nSupposons maintenant que dans notre vecteur tailles nous avons une valeur manquante (une personne a refusÃ© de rÃ©pondre, ou notre mÃ¨tre mesureur Ã©tait en panne). On symbolise celle-ci dans R avec le code interne NAÂ :\n\ntailles &lt;- c(156, 164, 197, NA, 173)\ntailles\n\n[1] 156 164 197  NA 173\n\n\n\n\n\n\n\n\nNote\n\n\n\nNA est lâ€™abbrÃ©viation de Not available, non disponible. Cette valeur particuliÃ¨re peut Ãªtre utilisÃ©e pour indiquer une valeur manquante, quâ€™il sâ€™agisse dâ€™un nombre, dâ€™une chaÃ®ne de caractÃ¨res, etc.\n\n\nSi je calcule maintenant la taille moyenne Ã  lâ€™aide de la fonction mean, jâ€™obtiensÂ :\n\nmean(tailles)\n\n[1] NA\n\n\nEn effet, R considÃ¨re par dÃ©faut quâ€™il ne peut pas calculer la moyenne si une des valeurs nâ€™est pas disponible. Il considÃ¨re alors que cette moyenne est elle-mÃªme â€œnon disponibleâ€ et renvoie donc comme rÃ©sultat NA.\nOn peut cependant indiquer Ã  mean dâ€™effectuer le calcul en ignorant les valeurs manquantes. Ceci se fait en ajoutant un argument supplÃ©mentaire, nommÃ© na.rm (abbrÃ©viation de NA remove, â€œenlever les NAâ€), et de lui attribuer la valeur TRUE (code interne de R signifiant vrai)Â :\n\nmean(tailles, na.rm = TRUE)\n\n[1] 172.5\n\n\nPositionner le paramÃ¨tre na.rm Ã  TRUE indique Ã  la fonction mean de ne pas tenir compte des valeurs manquantes dans le calcul.\nSi on ne dit rien Ã  la fonction mean, cet argument a une valeur par dÃ©faut, en lâ€™occurrence FALSE (faux), qui fait quâ€™il ne supprime pas les valeurs manquantes. Les deux commandes suivantes sont donc rigoureusement Ã©quivalentesÂ :\n\nmean(tailles)\n\n[1] NA\n\nmean(tailles, na.rm = FALSE)\n\n[1] NA\n\n\n\n\n\n\n\n\nNote\n\n\n\nLorsquâ€™on passe un argument Ã  une fonction de cette maniÃ¨re, câ€™est-Ã -dire sous la forme nom = valeur, on parle dâ€™argument nommÃ©.\n\n\n\n2.2.4.3 Aide sur une fonction\nIl est frÃ©quent de ne pas savoir (ou dâ€™avoir oubliÃ©) quels sont les arguments dâ€™une fonction, ou comment ils se nomment. On peut Ã  tout moment faire appel Ã  lâ€™aide intÃ©grÃ©e Ã  R en passant le nom de la fonction (entre guillemets) Ã  la fonction helpÂ :\n\nhelp(\"mean\")\n\nOn peut aussi utiliser le raccourci ?mean.\nCes deux commandes affichent une page (en anglais) dÃ©crivant la fonction, ses paramÃ¨tres, son rÃ©sultat, le tout accompagnÃ© de diverses notes, rÃ©fÃ©rences et exemples. Ces pages dâ€™aide contiennent Ã  peu prÃ¨s tout ce que vous pourrez chercher Ã  savoir, mais elles ne sont pas toujours dâ€™une lecture aisÃ©e.\nDans RStudio, les pages dâ€™aide en ligne sâ€™ouvriront par dÃ©faut dans la zone en bas Ã  droite, sous lâ€™onglet Help. Un clic sur lâ€™icÃ´ne en forme de maison vous affichera la page dâ€™accueil de lâ€™aide.\n\n2.2.5 Regrouper ses commandes dans des scripts\nJusquâ€™ici on a utilisÃ© R de maniÃ¨re â€œinteractiveâ€, en saisissant des commandes directement dans la console. Ã‡a nâ€™est cependant pas la maniÃ¨re dont on va utiliser R au quotidien, pour une raison simpleÂ : lorsque R redÃ©marre, tout ce qui a Ã©tÃ© effectuÃ© dans la console est perdu.\nPlutÃ´t que de saisir nos commandes dans la console, on va donc les regrouper dans des scripts (de simples fichiers texte), qui vont garder une trace de toutes les opÃ©rations effectuÃ©es, et ce sont ces scripts, sauvegardÃ©s rÃ©guliÃ¨rement, qui seront le â€œcoeurâ€ de notre travail. Câ€™est en rouvrant les scripts et en rÃ©exÃ©cutant les commandes quâ€™ils contiennent quâ€™on pourra â€œreproduireâ€ les donnÃ©es, leur traitement, les analyses et leurs rÃ©sultats.\nPour crÃ©er un script, il suffit de sÃ©lectionner le menu File, puis New file et R script. Une quatriÃ¨me zone apparaÃ®t alors en haut Ã  gauche de lâ€™interface de RStudio. On peut enregistrer notre script Ã  tout moment dans un fichier avec lâ€™extension .R, en cliquant sur lâ€™icÃ´ne de disquette ou en choissant File puis Save.\nUn script est un fichier texte brut, qui sâ€™Ã©dite de la maniÃ¨re habituelle. Ã€ la diffÃ©rence de la console, quand on appuie sur EntrÃ©e, cela nâ€™exÃ©cute pas la commande en cours mais insÃ¨re un saut de ligne (comme on pouvait sâ€™y attendre).\nPour exÃ©cuter une commande saisie dans un script, il suffit de positionner le curseur sur la ligne de la commande en question, et de cliquer sur le bouton Run dans la barre dâ€™outils juste au-dessus de la zone dâ€™Ã©dition du script. On peut aussi utiliser le raccourci clavier Ctrl + EntrÃ©e (Cmd + EntrÃ©e sous Mac). On peut enfin sÃ©lectionner plusieurs lignes avec la souris ou le clavier et cliquer sur Run (ou utiliser le raccourci clavier), et lâ€™ensemble des lignes est exÃ©cutÃ© dâ€™un coup.\nAu final, un script pourra ressembler Ã  quelque chose comme Ã§aÂ :\n\ntailles &lt;- c(156, 164, 197, 147, 173)\npoids &lt;- c(45, 59, 110, 44, 88)\n\nmean(tailles)\nmean(poids)\n\nimc &lt;- poids / (tailles / 100) ^ 2\nmin(imc)\nmax(imc)\n\n\n2.2.5.1 Commentaires\nLes commentaires sont un Ã©lÃ©ment trÃ¨s important dâ€™un script. Il sâ€™agit de texte libre, ignorÃ© par R, et qui permet de dÃ©crire les Ã©tapes du script, sa logique, les raisons pour lesquelles on a procÃ©dÃ© de telle ou telle maniÃ¨reâ€¦ Il est primordial de documenter ses scripts Ã  lâ€™aide de commentaires, car il est trÃ¨s facile de ne plus se retrouver dans un programme quâ€™on a produit soi-mÃªme, mÃªme aprÃ¨s une courte interruption.\nPour ajouter un commentaire, il suffit de le faire prÃ©cÃ©der dâ€™un ou plusieurs symboles #. En effet, dÃ¨s que R rencontre ce caractÃ¨re, il ignore tout ce qui se trouve derriÃ¨re, jussquâ€™Ã  la fin de la ligne.\nOn peut donc documenter le script prÃ©cÃ©dentÂ :\n\n# Saisie des tailles et poids des enquÃªtÃ©s\ntailles &lt;- c(156, 164, 197, 147, 173)\npoids &lt;- c(45, 59, 110, 44, 88)\n\n# Calcul des tailles et poids moyens\nmean(tailles)\nmean(poids)\n\n# Calcul de l'IMC (poids en kilo divisÃ© par les tailles en mÃ¨tre au carrÃ©)\nimc &lt;- poids / (tailles / 100) ^ 2\n# Valeurs extrÃªmes de l'IMC\nmin(imc)\nmax(imc)\n\n\n2.2.6 Installer et charger des extensions (packages)\nR Ã©tant un logiciel libre, il bÃ©nÃ©ficie dâ€™un dÃ©veloppement communautaire riche et dynamique. Lâ€™installation de base de R permet de faire Ã©normÃ©ment de choses, mais le langage dispose en plus dâ€™un systÃ¨me dâ€™extensions permettant dâ€™ajouter facilement de nouvelles fonctionnalitÃ©s. La plupart des extensions sont dÃ©veloppÃ©es et maintenues par la communautÃ© des utilisateurs de R, et diffusÃ©es via un rÃ©seau de serveurs nommÃ© CRAN (Comprehensive R Archive Network).\nPour installer une extension, si on dispose dâ€™une connexion Internet, on peut utiliser le bouton Install de lâ€™onglet Packages de RStudio.\n\n\n\n\n\nInstaller une extension\n\n\n\nIl suffit alors dâ€™indiquer le nom de lâ€™extension dans le champ Package et de cliquer sur Install.\n\n\n\n\n\nInstallation une extension\n\n\n\nimages/screenshots/rstudio_package_install.png On peut aussi installer des extensions en utilisant la fonction install.packages() directement dans la console. Par exemple, pour installer le package questionr on peut exÃ©cuter la commandeÂ :\n\ninstall.packages(\"questionr\")\n\nInstaller une extension via lâ€™une des deux mÃ©thodes prÃ©cÃ©dentes va tÃ©lÃ©charger lâ€™ensemble des fichiers nÃ©cessaires depuis lâ€™une des machines du CRAN, puis installer tout Ã§a sur le disque dur de votre ordinateur. Vous nâ€™avez besoin de le faire quâ€™une fois, comme vous le faites pour installer un programme sur votre Mac ou PC.\nUne fois lâ€™extension installÃ©e, il faut la â€œchargerâ€ avant de pouvoir utiliser les fonctions quâ€™elle propose. Ceci se fait avec la fonction library. Par exemple, pour pouvoir utiliser les fonctions de questionr, vous devrez exÃ©cuter la commande suivanteÂ :\n\nlibrary(questionr)\n\nAinsi, bien souvent, on regroupe en dÃ©but de script toute une sÃ©rie dâ€™appels Ã  library qui permettent de charger tous les packages utilisÃ©s dans le script. Quelque chose commeÂ :\n\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(questionr)\n\nSi vous essayez dâ€™exÃ©cuter une fonction dâ€™une extension et que vous obtenez le message dâ€™erreur impossible de trouver la fonction, câ€™est certainement parce que vous nâ€™avez pas exÃ©cutÃ© la commande library correspondante.\n\n2.2.7 Exercices\n\n2.2.7.1 Exercice 1\nConstruire le vecteur x suivantÂ :\n\n\n[1] 120 134 256  12\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nx &lt;- c(120, 134, 256, 12)\n\n\n\n\nUtiliser ce vecteur x pour gÃ©nÃ©rer les deux vecteurs suivantsÂ :\n\n\n[1] 220 234 356 112\n\n\n[1] 240 268 512  24\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nx + 100\nx * 2\n\n\n\n\n\n2.2.7.2 Exercice 2\nOn a demandÃ© Ã  4 mÃ©nages le revenu des deux conjoints, et le nombre de personnes du mÃ©nageÂ :\n\nconjoint1 &lt;- c(1200, 1180, 1750, 2100)\nconjoint2 &lt;- c(1450, 1870, 1690, 0)\nnb_personnes &lt;- c(4, 2, 3, 2)\n\nCalculer le revenu total de chaque mÃ©nage, puis diviser par le nombre de personnes pour obtenir le revenu par personne de chaque mÃ©nage.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nrevenu_total &lt;- conjoint1 + conjoint2\nrevenu_total / nb_personnes\n\n\n\n\n\n2.2.7.3 Exercice 3\nDans lâ€™exercice prÃ©cÃ©dent, calculer le revenu minimum et maximum parmi ceux du premier conjoint.\n\nconjoint1 &lt;- c(1200, 1180, 1750, 2100)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nrange(conjoint1)\n\n\n\n\nRecommencer avec les revenus suivants, parmi lesquels lâ€™un des enquetÃ©s nâ€™a pas voulu rÃ©pondreÂ :\n\nconjoint1 &lt;- c(1200, 1180, 1750, NA)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nrange(conjoint1, na.rm = TRUE)\n\n\n\n\n\n2.2.7.4 Exercice 4\nLes deux vecteurs suivants reprÃ©sentent les prÃ©cipitations (en mm) et la tempÃ©rature (en Â°C) moyennes sur la ville de Lyon, pour chaque mois de lâ€™annÃ©e, entre 1981 et 2010Â :\n\ntemperature &lt;- c(3.4, 4.8, 8.4, 11.4, 15.8, 19.4, 22.2, 21.6, 17.6, 13.4, 7.6, 4.4)\nprecipitations &lt;- c(47.2, 44.1, 50.4, 74.9, 90.8, 75.6, 63.7, 62, 87.5, 98.6, 81.9, 55.2)\n\nCalculer la tempÃ©rature moyenne sur lâ€™annÃ©e.\nCalculer la quantitÃ© totale de prÃ©cipitations sur lâ€™annÃ©e.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmean(temperature)\nsum(precipitations)\n\n\n\n\nÃ€ quoi correspond et comment peut-on interprÃ©ter le rÃ©sultat de la fonction suivanteÂ ? Vous pouvez vous aider de la page dâ€™aide de la fonction si nÃ©cessaire.\n\ncumsum(precipitations)\n\n [1]  47.2  91.3 141.7 216.6 307.4 383.0 446.7 508.7 596.2 694.8 776.7 831.9\n\n\nMÃªme question pour :\n\ndiff(temperature)\n\n [1]  1.4  3.6  3.0  4.4  3.6  2.8 -0.6 -4.0 -4.2 -5.8 -3.2\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ncumsum(precipitations) correspond Ã  la somme cumulÃ©e des prÃ©cipitations sur lâ€™annÃ©e. Par exemple, la 6e valeur du vecteur rÃ©sultat correspond au total de prÃ©cipitations de janvier Ã  juin.\ndiff(temperature) correspond Ã  la diffÃ©rence de tempÃ©rature dâ€™un mois sur lâ€™autre. Par exemple, la 2e valeur de ce vecteur correspond Ã  lâ€™Ã©cart de tempÃ©rature entre le mois de fÃ©vrier et le mois de janvier.\n\n\n\n\n2.2.7.5 Exercice 5\nOn a relevÃ© les notes en maths, anglais et sport dâ€™une classe de 6 Ã©lÃ¨ves et on a stockÃ© ces donnÃ©es dans trois vecteurs :\n\nmaths &lt;- c(12, 16, 8, 18, 6, 10)\nanglais &lt;- c(14, 9, 13, 15, 17, 11)\nsport &lt;- c(18, 11, 14, 10, 8, 12)\n\nCalculer la moyenne des Ã©lÃ¨ves de la classe en anglais.\nCalculer la moyenne gÃ©nÃ©rale de chaque Ã©lÃ¨ve.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmean(anglais)\n(maths + anglais + sport) / 3\n\n\n\n\nEssayez de comprendre le rÃ©sultat des deux fonctions suivantes (vous pouvez vous aider de la page dâ€™aide de ces fonctions) :\n\npmin(maths, anglais, sport)\n\n[1] 12  9  8 10  6 10\n\n\n\npmax(maths, anglais, sport)\n\n[1] 18 16 14 18 17 12\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npmin et pmax renvoient les minimum et maximum â€œparallÃ¨lesâ€ des trois vecteurs passÃ©s en argument. Ainsi, pmin renvoie pour chaque Ã©lÃ¨ve la note minimale dans les trois matiÃ¨res, et pmax la note maximale.",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Introduction Ã  R</span>"
    ]
  },
  {
    "objectID": "02-introR.html#premier-travail-avec-des-donnÃ©es",
    "href": "02-introR.html#premier-travail-avec-des-donnÃ©es",
    "title": "\n2Â  Introduction Ã  R\n",
    "section": "\n2.3 Premier travail avec des donnÃ©es",
    "text": "2.3 Premier travail avec des donnÃ©es\n\n2.3.1 Jeu de donnÃ©es dâ€™exemple\nDans cette partie nous allons (enfin) travailler sur des â€œvraiesâ€ donnÃ©es, et utiliser un jeu de donnÃ©es prÃ©sent dans lâ€™extension questionr. Nous devons donc avant toute chose installer cette extension.\nPour installer ce package, deux possibilitÃ©sÂ :\n\nDans lâ€™onglet Packages de la zone de lâ€™Ã©cran en bas Ã  droite, cliquez sur le bouton Install. Dans le dialogue qui sâ€™ouvre, entrez â€œquestionrâ€ dans le champ Packages puis cliquez sur Install.\nSaisissez directement la commande suivante dans la consoleÂ : install.packages(\"questionr\")\n\n\nDans les deux cas, tout un tas de messages devraient sâ€™afficher dans la console. Attendez que lâ€™invite de commandes &gt; apparaisse Ã  nouveau.\nPour plus dâ€™informations sur les extensions et leur installation, voir la section @ref(packages).\nLe jeu de donnÃ©es que nous allons utiliser est un extrait de lâ€™enquÃªte Histoire de vie rÃ©alisÃ©e par lâ€™INSEE en 2003. Il contient 2000 individus et 20 variables.\nPour pouvoir utiliser ces donnÃ©es, il faut dâ€™abord charger lâ€™extension questionr (aprÃ¨s lâ€™avoir installÃ©e, bien entendu)Â :\n\nlibrary(questionr)\n\nLâ€™utilisation de library permet de rendre â€œdisponiblesâ€, dans notre session R, les fonctions et jeux de donnÃ©es inclus dans lâ€™extension.\nNous devons ensuite indiquer Ã  R que nous souhaitons accÃ©der au jeu de donnÃ©es Ã  lâ€™aide de la commande dataÂ :\n\ndata(hdv2003)\n\nCette commande ne renvoie aucun rÃ©sultat particulier (sauf en cas dâ€™erreur), mais vous devriez voir apparaÃ®tre dans lâ€™onglet Environment de RStudio un nouvel objet nommÃ© hdv2003Â :\n\n\n\n\n\nOnglet Environment\n\n\n\nCet objet est dâ€™un type nouveauÂ : il sâ€™agit dâ€™un tableau de donnÃ©es.\n\n2.3.2 Tableau de donnÃ©es (data frame)\nUn data frame (ou tableau de donnÃ©es, ou table) est un type dâ€™objet R qui contient des donnÃ©es au format tabulaire, avec les observations en ligne et les variables en colonnes, comme dans une feuille de tableur de type LibreOffice ou Excel.\nSi on se contente dâ€™exÃ©cuter le nom de notre tableau de donnÃ©esÂ :\n\nhdv2003\n\nR va, comme Ã  son habitude, nous lâ€™afficher dans la console, ce qui est tout sauf utile.\nUne autre maniÃ¨re dâ€™afficher le contenu du tableau est de cliquer sur lâ€™icÃ´ne en forme de tableau Ã  droite du nom de lâ€™objet dans lâ€™onglet EnvironmentÂ :\n\n\n\n\n\nIcone view\n\n\n\nOu dâ€™utiliser la fonction ViewÂ :\n\nView(hdv2003)\n\nDans les deux cas votre tableau devrait sâ€™afficher dans RStudio avec une interface de type tableurÂ :\n\n\n\n\n\nInterface View\n\n\n\nIl est important de comprendre que lâ€™objet hdv2003 contient lâ€™intÃ©gralitÃ© des donnÃ©es du tableau. On voit donc quâ€™un objet peut contenir des donnÃ©es de types trÃ¨s diffÃ©rents (simple nombre, texte, vecteur, tableau de donnÃ©es entier), et Ãªtre potentiellement de trÃ¨s grande taille3.\n\n\n\n\n\n\nNote\n\n\n\nSous R, on peut importer ou crÃ©er autant de tableaux de donnÃ©es quâ€™on le souhaite, dans les limites des capacitÃ©s de sa machine.\n\n\nUn data frame peut Ãªtre manipulÃ© comme les autres objets vus prÃ©cÃ©demment. On peut par exemple faireÂ :\n\nd &lt;- hdv2003\n\nce qui va entraÃ®ner la copie de lâ€™ensemble de nos donnÃ©es dans un nouvel objet nommÃ© d. Ceci peut paraÃ®tre parfaitement inutile mais a en fait lâ€™avantage de fournir un objet avec un nom beaucoup plus court, ce qui diminuera la quantitÃ© de texte Ã  saisir par la suite.\nPour rÃ©sumer, comme nous avons dÃ©sormais dÃ©cidÃ© de saisir nos commandes dans un script et non plus directement dans la console, les premiÃ¨res lignes de notre fichier de travail sur les donnÃ©es de lâ€™enquÃªte Histoire de vie pourraient donc ressembler Ã  ceciÂ :\n\n## Chargement des extensions nÃ©cessaires\nlibrary(questionr)\n\n## Jeu de donnÃ©es hdv2003\ndata(hdv2003)\nd &lt;- hdv2003\n\n\n2.3.2.1 Structure du tableau\nUn tableau Ã©tant un objet comme un autre, on peut lui appliquer des fonctions. Par exemple, nrow et ncol retournent le nombre de lignes et de colonnes du tableauÂ :\n\nnrow(d)\n\n[1] 2000\n\n\n\nncol(d)\n\n[1] 20\n\n\nLa fonction dim renvoie ses dimensions, donc les deux nombres prÃ©cÃ©dentsÂ :\n\ndim(d)\n\n[1] 2000   20\n\n\nLa fonction names retourne les noms des colonnes du tableau, câ€™est-Ã -dire la liste de nos variablesÂ :\n\nnames(d)\n\n [1] \"id\"            \"age\"           \"sexe\"          \"nivetud\"      \n [5] \"poids\"         \"occup\"         \"qualif\"        \"freres.soeurs\"\n [9] \"clso\"          \"relig\"         \"trav.imp\"      \"trav.satisf\"  \n[13] \"hard.rock\"     \"lecture.bd\"    \"peche.chasse\"  \"cuisine\"      \n[17] \"bricol\"        \"cinema\"        \"sport\"         \"heures.tv\"    \n\n\nEnfin, la fonction str renvoie un descriptif plus dÃ©taillÃ© de la structure du tableau. Elle liste les diffÃ©rentes variables, indique leur type 4 et affiche les premiÃ¨res valeursÂ :\n\nstr(d)\n\n'data.frame':   2000 obs. of  20 variables:\n $ id           : int  1 2 3 4 5 6 7 8 9 10 ...\n $ age          : int  28 23 59 34 71 35 60 47 20 28 ...\n $ sexe         : Factor w/ 2 levels \"Homme\",\"Femme\": 2 2 1 1 2 2 2 1 2 1 ...\n $ nivetud      : Factor w/ 8 levels \"N'a jamais fait d'etudes\",..: 8 NA 3 8 3 6 3 6 NA 7 ...\n $ poids        : num  2634 9738 3994 5732 4329 ...\n $ occup        : Factor w/ 7 levels \"Exerce une profession\",..: 1 3 1 1 4 1 6 1 3 1 ...\n $ qualif       : Factor w/ 7 levels \"Ouvrier specialise\",..: 6 NA 3 3 6 6 2 2 NA 7 ...\n $ freres.soeurs: int  8 2 2 1 0 5 1 5 4 2 ...\n $ clso         : Factor w/ 3 levels \"Oui\",\"Non\",\"Ne sait pas\": 1 1 2 2 1 2 1 2 1 2 ...\n $ relig        : Factor w/ 6 levels \"Pratiquant regulier\",..: 4 4 4 3 1 4 3 4 3 2 ...\n $ trav.imp     : Factor w/ 4 levels \"Le plus important\",..: 4 NA 2 3 NA 1 NA 4 NA 3 ...\n $ trav.satisf  : Factor w/ 3 levels \"Satisfaction\",..: 2 NA 3 1 NA 3 NA 2 NA 1 ...\n $ hard.rock    : Factor w/ 2 levels \"Non\",\"Oui\": 1 1 1 1 1 1 1 1 1 1 ...\n $ lecture.bd   : Factor w/ 2 levels \"Non\",\"Oui\": 1 1 1 1 1 1 1 1 1 1 ...\n $ peche.chasse : Factor w/ 2 levels \"Non\",\"Oui\": 1 1 1 1 1 1 2 2 1 1 ...\n $ cuisine      : Factor w/ 2 levels \"Non\",\"Oui\": 2 1 1 2 1 1 2 2 1 1 ...\n $ bricol       : Factor w/ 2 levels \"Non\",\"Oui\": 1 1 1 2 1 1 1 2 1 1 ...\n $ cinema       : Factor w/ 2 levels \"Non\",\"Oui\": 1 2 1 2 1 2 1 1 2 2 ...\n $ sport        : Factor w/ 2 levels \"Non\",\"Oui\": 1 2 2 2 1 2 1 1 1 2 ...\n $ heures.tv    : num  0 1 0 2 3 2 2.9 1 2 2 ...\n\n\nSous RStudio, on peut afficher Ã  tout moment la structure dâ€™un objet en cliquant sur lâ€™icÃ´ne de triangle sur fond bleu Ã  gauche du nom de lâ€™objet dans lâ€™onglet EnvironmentÂ :\n\n\n\n\n\nStructure dâ€™un objet\n\n\n\n\n2.3.2.2 AccÃ©der aux variables dâ€™un tableau\nUne opÃ©ration trÃ¨s importante est lâ€™accÃ¨s aux variables du tableau (Ã  ses colonnes) pour pouvoir les manipuler, effectuer des calculs, etc. On utilise pour cela lâ€™opÃ©rateur $, qui permet dâ€™accÃ©der aux colonnes du tableau. Ainsi, si lâ€™on tapeÂ :\n\nd$sexe\n\n  [1] Femme Femme Homme Homme Femme Femme Femme Homme Femme Homme Femme Homme\n [13] Femme Femme Femme Femme Homme Femme Homme Femme Femme Homme Femme Femme\n [25] Femme Homme Femme Homme Homme Homme Homme Homme Homme Homme Femme Femme\n [37] Homme Femme Femme Homme Femme Homme Homme Femme Femme Homme Femme Femme\n [49] Femme Femme Homme Femme Homme Femme Homme Femme Femme Femme Homme Femme\n [61] Femme Homme Homme Homme Homme Femme Homme Homme Femme Femme Homme Homme\n [73] Femme Femme Femme Femme Homme Femme Femme Femme Femme Femme Femme Homme\n [85] Homme Femme Homme Homme Homme Homme Homme Femme Homme Femme Femme Femme\n [97] Homme Homme Femme Femme Femme Homme Femme Homme Homme Femme Femme Femme\n[109] Femme Homme Homme Homme Homme Homme Femme Homme Homme Femme Homme Homme\n[121] Femme Femme Femme Homme Femme Femme Homme Femme Femme Homme Femme Homme\n[133] Femme Femme Femme Homme Homme Homme Homme Homme Homme Homme Homme Femme\n[145] Homme Homme Homme Femme Femme Femme Homme Femme Femme Femme Femme Homme\n[157] Femme Homme Homme Homme Femme Homme Femme Homme Femme Homme Homme Femme\n[169] Femme Femme Homme Femme Homme Femme Femme Femme Homme Homme Homme Femme\n[181] Homme Femme Femme Homme Homme Femme Femme Femme Femme Femme Homme Homme\n[193] Femme Homme Homme Femme Homme Femme Homme Femme\n [ reached getOption(\"max.print\") -- omitted 1800 entries ]\nLevels: Homme Femme\n\n\nR va nous afficher lâ€™ensemble des valeurs de notre variable sexe dans la console, ce qui est Ã  nouveau fort peu utile. Mais cela nous permet de constater que d$sexe est un vecteur de chaÃ®nes de caractÃ¨res tels quâ€™on en a dÃ©jÃ  rencontrÃ© prÃ©cÃ©demment.\nLa fonction table$colonne renvoie donc la colonne nommÃ©e colonne du tableau table, câ€™est-Ã -dire un vecteur, en gÃ©nÃ©ral de nombres ou de chaÃ®nes de caractÃ¨res.\nSi on souhaite afficher seulement les premiÃ¨res ou derniÃ¨res valeurs dâ€™une variable, on peut utiliser les fonctions head et tailÂ :\n\nhead(d$age)\n\n[1] 28 23 59 34 71 35\n\n\n\ntail(d$age, 10)\n\n [1] 52 42 50 41 46 45 46 24 24 66\n\n\nLe deuxiÃ¨me argument numÃ©rique permet dâ€™indiquer le nombre de valeurs Ã  afficher.\n\n2.3.2.3 CrÃ©er une nouvelle variable\nOn peut aussi utiliser lâ€™opÃ©rateur $ pour crÃ©er une nouvelle variable dans notre tableauÂ : pour cela, il suffit de lui assigner une valeur.\nPar exemple, la variable heures.tv contient le nombre dâ€™heures passÃ©es quotidiennement devant la tÃ©lÃ©Â :\n\nhead(d$heures.tv, 10)\n\n [1] 0.0 1.0 0.0 2.0 3.0 2.0 2.9 1.0 2.0 2.0\n\n\nOn peut vouloir crÃ©er une nouvelle variable dans notre tableau qui contienne la mÃªme durÃ©e mais en minutes. On va donc crÃ©er une nouvelle variables minutes.tv de la maniÃ¨re suivanteÂ :\n\nd$minutes.tv &lt;- d$heures.tv * 60\n\nOn peut alors constater, soit visuellement soit dans la console, quâ€™une nouvelle variable (une nouvelle colonne) a bien Ã©tÃ© ajoutÃ©e au tableauÂ :\n\nhead(d$minutes.tv)\n\n[1]   0  60   0 120 180 120\n\n\n\n2.3.3 Analyse univariÃ©e\nOn a donc dÃ©sormais accÃ¨s Ã  un tableau de donnÃ©es d, dont les lignes sont des observations (des individus enquÃªtÃ©s), et les colonnes des variables (des caractÃ©ristiques de chacun de ces individus), et on sait accÃ©der Ã  ces variables grÃ¢ce Ã  lâ€™opÃ©rateur $.\nSi on souhaite analyser ces variables, les mÃ©thodes et fonctions utilisÃ©es seront diffÃ©rentes selon quâ€™il sâ€™agit dâ€™une variable quantitative (variable numÃ©rique pouvant prendre un grand nombre de valeursÂ : lâ€™Ã¢ge, le revenu, un pourcentageâ€¦) ou dâ€™une variable qualitative (variable pouvant prendre un nombre limitÃ© de valeurs appelÃ©es modalitÃ©sÂ : le sexe, la profession, le dernier diplÃ´me obtenu, etc.).\n\n2.3.3.1 Analyser une variable quantitative\nUne variable quantitative est une variable de type numÃ©rique (un nombre) qui peut prendre un grand nombre de valeurs. On en a plusieurs dans notre jeu de donnÃ©es, notamment lâ€™Ã¢ge (variable age) ou le nombre dâ€™heures passÃ©es devant la tÃ©lÃ© (heures.tv).\n\n2.3.3.1.1 Indicateurs de centralitÃ©\nCaractÃ©riser une variable quantitative, câ€™est essayer de dÃ©crire la maniÃ¨re dont ses valeurs se rÃ©partissent, ou se distribuent.\nPour cela on peut commencer par regarder les valeurs extrÃªmes, avec les fonctions min, max ou rangeÂ :\n\nmin(d$age)\n\n[1] 18\n\nmax(d$age)\n\n[1] 97\n\nrange(d$age)\n\n[1] 18 97\n\n\nOn peut aussi calculer des indicateurs de centralitÃ©Â : ceux-ci indiquent autour de quel nombre se rÃ©partissent les valeurs de la variable. Il y en a plusieurs, le plus connu Ã©tant la moyenne, quâ€™on peut calculer avec la fonction meanÂ :\n\nmean(d$age)\n\n[1] 48.157\n\n\nIl existe aussi la mÃ©diane, qui est la valeur qui sÃ©pare notre population en deuxÂ : on a la moitiÃ© de nos observations en-dessous, et la moitiÃ© au-dessus. Elle se calcule avec la fonction medianÂ :\n\nmedian(d$age)\n\n[1] 48\n\n\nUne diffÃ©rence entre les deux indicateurs est que la mÃ©diane est beaucoup moins sensible aux valeurs â€œextrÃªmesâ€Â : on dit quâ€™elle est plus robuste. Ainsi, en 2013, le salaire net moyen des salariÃ©s Ã  temps plein en France Ã©tait de 2202 euros, tandis que le salaire net mÃ©dian nâ€™Ã©tait que de 1772 euros. La diffÃ©rence Ã©tant due Ã  des trÃ¨s hauts salaires qui â€œtirentâ€ la moyenne vers le haut.\n\n2.3.3.1.2 Indicateurs de dispersion\nLes indicateurs de dispersion permettent de mesurer si les valeurs sont plutÃ´t regroupÃ©es ou au contraire plutÃ´t dispersÃ©es.\nLâ€™indicateur le plus simple est lâ€™Ã©tendue de la distribution, qui dÃ©crit lâ€™Ã©cart maximal observÃ© entre les observationsÂ :\n\nmax(d$age) - min(d$age)\n\n[1] 79\n\n\nLes indicateurs de dispersion les plus utilisÃ©s sont la variance ou, de maniÃ¨re Ã©quivalente, lâ€™Ã©cart-type (qui est Ã©gal Ã  la racine carrÃ©e de la variance). On obtient la premiÃ¨re avec la fonction var, et le second avec sd (abbrÃ©viation de standard deviation)Â :\n\nvar(d$age)\n\n[1] 287.0249\n\n\n\nsd(d$age)\n\n[1] 16.94181\n\n\nPlus la variance ou lâ€™Ã©cart-type sont Ã©levÃ©s, plus les valeurs sont dispersÃ©es autour de la moyenne. Ã€ lâ€™inverse, plus ils sont faibles et plus les valeurs sont regroupÃ©es.\nUne autre maniÃ¨re de mesurer la dispersion est de calculer les quartilesÂ :\n\nle premier quartile est la valeur pour laquelle on a 25% des observations en dessous et 75% au dessus\nle deuxiÃ¨me quartile est la valeur pour laquelle on a 50% des observations en dessous et 50% au dessus (câ€™est donc la mÃ©diane)\nle troisiÃ¨me quartile est la valeur pour laquelle on a 75% des observations en dessous et 25% au dessus\n\nOn peut les calculer avec la fonction quantileÂ :\n\n### Premier quartile\nquantile(d$age, prob = 0.25)\n\n25% \n 35 \n\n\n\n## TroisiÃ¨me quartile\nquantile(d$age, prob = 0.75)\n\n75% \n 60 \n\n\nquantile prend deux arguments principauxÂ : le vecteur dont on veut calculer le quantile, et un argument prob qui indique quel quantile on souhaite obtenir. prob prend une valeur entre 0 et 1Â : 0.5 est la mÃ©diane, 0.25 le premier quartile, 0.1 le premier dÃ©cile, etc.\nNotons enfin que la fonction summary permet dâ€™obtenir dâ€™un coup plusieurs indicateurs classiquesÂ :\n\nsummary(d$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.00   35.00   48.00   48.16   60.00   97.00 \n\n\n\n2.3.3.1.3 ReprÃ©sentation graphique\nLâ€™outil le plus utile pour Ã©tudier la distribution des valeurs dâ€™une variable quantitative reste la reprÃ©sentation graphique.\nLa reprÃ©sentation la plus courante est sans doute lâ€™histogramme. On peut lâ€™obtenir avec la fonction histÂ :\n\nhist(d$age)\n\n\n\nHistogramme de lâ€™age par dÃ©faut\n\n\n\nCette fonction nâ€™a pas pour effet direct dâ€™effectuer un calcul ou de nous renvoyer un rÃ©sultatÂ : elle gÃ©nÃ¨re un graphique qui va sâ€™afficher dans lâ€™onglet Plots de RStudio.\nOn peut personnaliser lâ€™apparence de lâ€™histogramme en ajoutant des arguments supplÃ©mentaires Ã  la fonction hist. Lâ€™argument le plus important est breaks, qui permet dâ€™indiquer le nombre de classes que lâ€™on souhaite.\n\nhist(d$age, breaks = 10, main = \"\")\n\n\n\nHistogramme de lâ€™age avec 10 classes\n\n\n\n\nhist(d$age, breaks = 70, main = \"\")\n\n\n\nHistogramme de lâ€™age avec 70 classes\n\n\n\nLe choix dâ€™un â€œbonâ€ nombre de classes pour un histogramme nâ€™est pas un problÃ¨me simpleÂ : si on a trop peu de classes, on risque dâ€™effacer quasiment toutes les variations, et si on en a trop on risque dâ€™avoir trop de dÃ©tails et de masquer les grandes tendances.\nLes arguments de hist permettent Ã©galement de modifier la prÃ©sentation du graphique. On peut ainsi changer la couleur des barres avec col5, le titre avec main, les Ã©tiquettes des axes avec xlab et ylab, etc.Â :\n\nhist(d$age,\n  col = \"skyblue\",\n  main = \"RÃ©partition des Ã¢ges des enquÃªtÃ©s\",\n  xlab = \"Ã‚ge\",\n  ylab = \"Effectif\"\n)\n\n\n\nHistogramme modifiÃ©\n\n\n\nLa fonction hist fait partie des fonctions graphique de base de R. On verra plus en dÃ©tail dâ€™autres fonctions graphiques  avec lâ€™extension ggplot2 qui permet la production et la personnalisation de graphiques complexes.\n\n2.3.3.2 Analyser une variable qualitative\nUne variable qualitative est une variable qui ne peut prendre quâ€™un nombre limitÃ© de valeurs, appelÃ©es modalitÃ©s. Dans notre jeu de donnÃ©es on trouvera par exemple le sexe (sexe), le niveau dâ€™Ã©tudes (nivetud), la catÃ©gorie socio-professionnelle (qualif)â€¦\nÃ€ noter quâ€™une variable qualitative peut tout-Ã -fait Ãªtre numÃ©rique, et que certaines variables peuvent Ãªtre traitÃ©es soit comme quantitatives, soit comme qualitativesÂ : câ€™est le cas par exemple du nombre dâ€™enfants ou du nombre de frÃ¨res et soeurs.\n\n2.3.3.2.1 Tri Ã  plat\nLâ€™outil le plus utilisÃ© pour reprÃ©senter la rÃ©partition des valeurs dâ€™une variable qualitative est le tri Ã  platÂ : il sâ€™agit simplement de compter, pour chacune des valeurs possibles de la variable (pour chacune des modalitÃ©s), le nombre dâ€™observations ayant cette valeur. Un tri Ã  plat sâ€™obtient sous R Ã  lâ€™aide de la fonction tableÂ :\n\ntable(d$sexe)\n\n\nHomme Femme \n  899  1101 \n\n\nCe tableau nous indique donc que parmi nos enquÃªtÃ©s on trouve 899 hommes et 1101 femmes.\n\ntable(d$qualif)\n\n\n      Ouvrier specialise         Ouvrier qualifie               Technicien \n                     203                      292                       86 \nProfession intermediaire                    Cadre                  Employe \n                     160                      260                      594 \n                   Autre \n                      58 \n\n\nUn tableau de ce type peut Ãªtre affichÃ© ou stockÃ© dans un objet, et on peut Ã  son tour lui appliquer des fonctions. Par exemple, la fonction sort permet de trier le tableau selon la valeur de lâ€™effectif. On peut donc faireÂ :\n\ntab &lt;- table(d$qualif)\nsort(tab)\n\n\n                   Autre               Technicien Profession intermediaire \n                      58                       86                      160 \n      Ouvrier specialise                    Cadre         Ouvrier qualifie \n                     203                      260                      292 \n                 Employe \n                     594 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nAttention, par dÃ©faut la fonction table nâ€™affiche pas les valeurs manquantes (NA). Si on souhaite les inclure il faut utiliser lâ€™argument useNA = \"always\", soitÂ : table(d$qualif, useNA = \"always\").\n\n\nÃ€ noter quâ€™on peut aussi appliquer summary Ã  une variable qualitative. Le rÃ©sultat est Ã©galement le tri Ã  plat de la variable, avec en plus le nombre de valeurs manquantes Ã©ventuellesÂ :\n\nsummary(d$qualif)\n\n      Ouvrier specialise         Ouvrier qualifie               Technicien \n                     203                      292                       86 \nProfession intermediaire                    Cadre                  Employe \n                     160                      260                      594 \n                   Autre                     NA's \n                      58                      347 \n\n\nPar dÃ©faut ces tris Ã  plat sont en effectifs et ne sont donc pas toujours trÃ¨s lisibles, notamment quand on a des effectifs importants. On leur rajoute donc en gÃ©nÃ©ral la rÃ©partition en pourcentages. Pour cela, nous allons utiliser la fonction freq de lâ€™extension questionr, qui devra donc avoir prÃ©cÃ©demment Ã©tÃ© chargÃ©e avec library(questionr)Â :\n\n## Ã€ rajouter en haut de script et Ã  exÃ©cuter\nlibrary(questionr)\n\nOn peut alors utiliser la fonctionÂ :\n\nfreq(d$qualif)\n\n\n\n                           n    % val%\nOuvrier specialise       203 10.2 12.3\nOuvrier qualifie         292 14.6 17.7\nTechnicien                86  4.3  5.2\nProfession intermediaire 160  8.0  9.7\nCadre                    260 13.0 15.7\nEmploye                  594 29.7 35.9\nAutre                     58  2.9  3.5\nNA                       347 17.3   NA\n\n\nLa colonne n reprÃ©sente les effectifs de chaque catÃ©gorie, la colonne % le pourcentage, et la colonne val% le pourcentage calculÃ© sur les valeurs valides, donc en excluant les NA. Une ligne a Ã©galement Ã©tÃ© rajoutÃ©e pour indiquer le nombre et la proportion de NA.\nfreq accepte un certain nombre dâ€™arguments pour personnaliser son affichage. Par exempleÂ :\n\n\nvalid indique si on souhaite ou non afficher les pourcentages sur les valeurs valides\n\ncum indique si on souhaite ou non afficher les pourcentages cumulÃ©s\n\ntotal permet dâ€™ajouter une ligne avec les effectifs totaux\n\nsort permet de trier le tableau par frÃ©quence croissante (sort=\"inc\") ou dÃ©croissante (sort=\"dec\").\n\n\nfreq(d$qualif, valid = FALSE, total = TRUE, sort = \"dec\")\n\n\n\n                            n     %\nEmploye                   594  29.7\nOuvrier qualifie          292  14.6\nCadre                     260  13.0\nOuvrier specialise        203  10.2\nProfession intermediaire  160   8.0\nTechnicien                 86   4.3\nAutre                      58   2.9\nNA                        347  17.3\nTotal                    2000 100.0\n\n\n\n2.3.3.2.2 ReprÃ©sentations graphiques\nOn peut reprÃ©senter graphiquement le tri Ã  plat dâ€™une variable qualitative avec un diagramme en barres, obtenu avec la fonction barplot. Attention, contrairement Ã  hist cette fonction ne sâ€™applique pas directement Ã  la variable mais au rÃ©sultat du tri Ã  plat de cette variable, calculÃ© avec table. Il faut donc procÃ©der en deux Ã©tapesÂ :\n\ntab &lt;- table(d$clso)\nbarplot(tab)\n\n\n\nGraphique en barre\n\n\n\nOn peut aussi trier le tri Ã  plat avec la fonction sort avant de le reprÃ©senter graphiquement, ce qui peut faciliter la lecture du graphiqueÂ :\n\nbarplot(sort(tab))\n\n\n\nGraphique en barre triÃ©\n\n\n\nUne alternative au graphique en barres est le diagramme de Cleveland, quâ€™on peut obtenir avec la fonction dotchart. Celle-ci sâ€™applique elle aussi au tri Ã  plat de la variable calculÃ© avec table.\n\ndotchart(table(d$qualif))\n\n\n\nGraphique de Cleveland\n\n\n\nLÃ  aussi, pour amÃ©liorer la lisibilitÃ© du graphique il est prÃ©fÃ©rable de trier le tri Ã  plat de la variable avant de le reprÃ©senterÂ :\n\ndotchart(sort(table(d$qualif)))\n\n\n\nGraphique de Cleveland triÃ©\n\n\n\n\n2.3.4 Exercices\nExercice 1\nCrÃ©er un nouveau script qui effectue les actions suivantesÂ :\n\ncharger lâ€™extension questionr\n\ncharger le jeu de donnÃ©es nommÃ© hdv2003\n\ncopier le jeu de donnÃ©es dans un nouvel objet nommÃ© df\n\nafficher les dimensions et la liste des variables de df\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(questionr)\n\ndata(hdv2003)\ndf &lt;- hdv2003\n\ndim(df)\nnames(df)\n\n\n\n\nExercice 2\nOn souhaite Ã©tudier la rÃ©partition du temps passÃ© devant la tÃ©lÃ©vision par les enquÃªtÃ©s (variable heures.tv). Pour cela, affichez les principaux indicateurs de cette variableÂ : valeur minimale, maximale, moyenne, mÃ©diane et Ã©cart-type. ReprÃ©sentez ensuite sa distribution par un histogramme en 10 classes.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsummary(df$heures.tv)\nsd(df$heures.tv)\n\nhist(df$heures.tv, breaks = 10)\n\n\n\n\nExercice 3\nOn sâ€™intÃ©resse maintenant Ã  lâ€™importance accordÃ©e par les enquÃªtÃ©s Ã  leur travail (variable trav.imp). Faites un tri Ã  plat des effectifs des modalitÃ©s de cette variable avec la commande table.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ntable(df$trav.imp)\n\n\n\n\nFaites un tri Ã  plat affichant Ã  la fois les effectifs et les pourcentages de chaque modalitÃ©. Yâ€™a-t-il des valeurs manquantes ?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nfreq(df$trav.imp)\n\n\n\n\nReprÃ©sentez graphiquement les effectifs des modalitÃ©s Ã  lâ€™aide dâ€™un graphique en barres.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ntab &lt;- sort(table(df$trav.imp))\nbarplot(tab)\n\n\n\n\nUtilisez lâ€™argument col de la fonction barplot pour modifier la couleur du graphique en tomato.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nbarplot(tab, col = \"tomato\")\n\n\n\n\nTapez colors() dans la console pour afficher lâ€™ensemble des noms de couleurs disponibles dans R. Testez chaque couleur une Ã  une pour trouver votre couleur prÃ©fÃ©rÃ©e.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCâ€™est une blague, heinÂ ! Cela dit moccasin ou palevioletred sont pas mal, si vous voulez essayer :-)",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Introduction Ã  R</span>"
    ]
  },
  {
    "objectID": "02-introR.html#analyse-de-2-variables",
    "href": "02-introR.html#analyse-de-2-variables",
    "title": "\n2Â  Introduction Ã  R\n",
    "section": "\n2.4 Analyse de 2 variables",
    "text": "2.4 Analyse de 2 variables\nFaire une analyse bivariÃ©e, câ€™est Ã©tudier la relation entre deux variablesÂ : sont-elles liÃ©es ? les valeurs de lâ€™une influencent-elles les valeurs de lâ€™autre ? ou sont-elles au contraire indÃ©pendantes ?\nÃ€ noter quâ€™on va parler ici dâ€™influence ou de lien, mais pas de relation de cause Ã  effetÂ : les outils prÃ©sentÃ©s permettent de visualiser ou de dÃ©terminer une relation, mais des liens de causalitÃ© proprement dit sont plus difficiles Ã  mettre en Ã©vidence. Il faut en effet vÃ©rifier que câ€™est bien telle variable qui influence telle autre et pas lâ€™inverse, quâ€™il nâ€™y a pas de â€œvariable cachÃ©eâ€, etc.\nLÃ  encore, le type dâ€™analyse ou de visualisation est dÃ©terminÃ© par la nature qualitative ou quantitative des deux variables.\n\n2.4.1 Croisement de deux variables qualitatives\n\n2.4.1.1 Tableaux croisÃ©s\nOn va continuer Ã  travailler avec le jeu de donnÃ©es tirÃ© de lâ€™enquÃªte Histoire de vie inclus dans lâ€™extension questionr. On commence donc par charger lâ€™extension, le jeu de donnÃ©es, et Ã  le renommer en un nom plus court pour gagner un peu de temps de saisie au clavierÂ :\n\nlibrary(questionr)\ndata(hdv2003)\nd &lt;- hdv2003\n\nQuand on veut croiser deux variables qualitatives, on fait un tableau croisÃ©. Comme pour un tri Ã  plat ceci sâ€™obtient avec la fonction table de R, mais Ã  laquelle on passe cette fois deux variables en argument. Par exemple, si on veut croiser la catÃ©gorie socio-professionnelle et le sexe des enquÃªtÃ©sÂ :\n\ntable(d$qualif, d$sexe)\n\n                          \n                           Homme Femme\n  Ouvrier specialise          96   107\n  Ouvrier qualifie           229    63\n  Technicien                  66    20\n  Profession intermediaire    88    72\n  Cadre                      145   115\n  Employe                     96   498\n  Autre                       21    37\n\n\nPour pouvoir interprÃ©ter ce tableau on doit passer du tableau en effectifs au tableau en pourcentages ligne ou colonne. Pour cela, on peut utiliser les fonctions lprop et cprop de lâ€™extension questionr, quâ€™on applique au tableau croisÃ© prÃ©cÃ©dent.\nPour calculer les pourcentages ligneÂ :\n\ntab &lt;- table(d$qualif, d$sexe)\nlprop(tab)\n\n                          \n                           Homme Femme Total\n  Ouvrier specialise        47.3  52.7 100.0\n  Ouvrier qualifie          78.4  21.6 100.0\n  Technicien                76.7  23.3 100.0\n  Profession intermediaire  55.0  45.0 100.0\n  Cadre                     55.8  44.2 100.0\n  Employe                   16.2  83.8 100.0\n  Autre                     36.2  63.8 100.0\n  All                       44.8  55.2 100.0\n\n\nEt pour les pourcentages colonneÂ :\n\ncprop(tab)\n\n                          \n                           Homme Femme All  \n  Ouvrier specialise        13.0  11.7  12.3\n  Ouvrier qualifie          30.9   6.9  17.7\n  Technicien                 8.9   2.2   5.2\n  Profession intermediaire  11.9   7.9   9.7\n  Cadre                     19.6  12.6  15.7\n  Employe                   13.0  54.6  35.9\n  Autre                      2.8   4.1   3.5\n  Total                    100.0 100.0 100.0\n\n\n\n\n\n\n\n\nNote\n\n\n\nPour savoir si on doit faire des pourcentages ligne ou colonne, on pourra se rÃ©fÃ©rer Ã  lâ€™article suivantÂ :\nhttp://alain-leger.lescigales.org/textes/lignecolonne.pdf\nEn rÃ©sumÃ©, quand on fait un tableau croisÃ©, celui-ci est parfaitement symÃ©triqueÂ : on peut inverser les lignes et les colonnes, Ã§a ne change pas son interprÃ©tation. Par contre, on a toujours en tÃªte un â€œsensâ€ de lecture dans le sens oÃ¹ on considÃ¨re que lâ€™une des variables dÃ©pend de lâ€™autre. Par exemple, si on croise sexe et type de profession, on dira que le type de profession dÃ©pend du sexe, et non lâ€™inverseÂ : le type de profession est alors la variable dÃ©pendante (Ã  expliquer), et le sexe la variable indÃ©pendante (explicative).\nPour faciliter la lecture dâ€™un tableau croisÃ©, il est recommandÃ© de faire les pourcentages sur la variable indÃ©pendante. Dans notre exemple, la variable indÃ©pendante est le sexe, elle est en colonne, on calcule donc les pourcentages colonnes qui permettent de comparer directement, pour chaque sexe, la rÃ©partition des catÃ©gories socio-professionnelles.\n\n\n\n\n2.4.1.2 ReprÃ©sentation graphique\nIl est possible de faire une reprÃ©sentation graphique dâ€™un tableau croisÃ©, par exemple avec la fonction mosaicplotÂ :\n\nmosaicplot(tab)\n\n\n\nGraphique mosaique\n\n\n\nOn peut amÃ©liorer ce graphique en colorant les cases selon les rÃ©sidus du test du Ï‡Â² (argument shade = TRUE) et en orientant verticalement les labels de colonnes (argument las = 3)Â :\n\nmosaicplot(tab, las = 3, shade = TRUE)\n\n\n\nGraphique mosaique modifiÃ©\n\n\n\nChaque rectangle de ce graphique reprÃ©sente une case de tableau. Sa largeur correspond au pourcentage des modalitÃ©s en colonnes (il yâ€™a beaucoup dâ€™employÃ©s et dâ€™ouvriers et trÃ¨s peu dâ€™â€œautresâ€). Sa hauteur correspond aux pourcentages colonnesÂ : la proportion dâ€™hommes chez les cadres est plus Ã©levÃ©e que chez les employÃ©s. Enfin, la couleur de la case correspond au rÃ©sidu du test du Ï‡Â² correspondantÂ : les cases en rouge sont sous-reprÃ©sentÃ©es, les cases en bleu sur-reprÃ©sentÃ©es, et les cases blanches sont proches des effectifs attendus sous lâ€™hypothÃ¨se dâ€™indÃ©pendance.\n\n2.4.2 Croisement dâ€™une variable quantitative et dâ€™une variable qualitative\n\n2.4.2.1 ReprÃ©sentation graphique\nCroiser une variable quantitative et une variable qualitative, câ€™est essayer de voir si les valeurs de la variable quantitative se rÃ©partissent diffÃ©remment selon la catÃ©gorie dâ€™appartenance de la variable qualitative.\nPour cela, lâ€™idÃ©al est de commencer par une reprÃ©sentation graphique de type â€œboÃ®te Ã  moustacheâ€ Ã  lâ€™aide de la fonction boxplot. Par exemple, si on veut visualiser la rÃ©partition des Ã¢ges selon la pratique ou non dâ€™un sport, on va utiliser la syntaxe suivanteÂ :\n\nboxplot(age ~ sport, data = d)\n\n\n\n\n\n\n\nNote\n\n\n\nCette syntaxe de boxplot utilise une nouvelle notation de type â€œformuleâ€. Celle-ci est utilisÃ©e notamment pour la spÃ©cification des modÃ¨les de rÃ©gression. Ici le ~ peut se lire comme â€œen fonction deâ€Â : on veut reprÃ©senter le boxplot de lâ€™Ã¢ge en fonction du sport.\n\n\nCe qui va nous donner le rÃ©sultat suivantÂ :\n\n\n\n\nGraphique en boites Ã  moustaches\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nLâ€™interprÃ©tation dâ€™un boxplot est la suivanteÂ : Les bords infÃ©rieurs et supÃ©rieurs du carrÃ© central reprÃ©sentent le premier et le troisiÃ¨me quartile de la variable reprÃ©sentÃ©e sur lâ€™axe vertical. On a donc 50% de nos observations dans cet intervalle. Le trait horizontal dans le carrÃ© reprÃ©sente la mÃ©diane. Enfin, des â€œmoustachesâ€ sâ€™Ã©tendent de chaque cÃ´tÃ© du carrÃ©, jusquâ€™aux valeurs minimales et maximales, avec une exceptionÂ : si des valeurs sont Ã©loignÃ©es du carrÃ© de plus de 1,5 fois lâ€™Ã©cart interquartile (la hauteur du carrÃ©), alors on les reprÃ©sente sous forme de points (symbolisant des valeurs considÃ©rÃ©es comme â€œextrÃªmesâ€).\n\n\nDans le graphique ci-dessus, on voit que ceux qui ont pratiquÃ© un sport au cours des douze derniers mois ont lâ€™air dâ€™Ãªtre sensiblement plus jeunes que les autres.\n\n2.4.2.2 Calculs dâ€™indicateurs\nOn peut aussi vouloir comparer certains indicateurs (moyenne, mÃ©diane) dâ€™une variable quantitative selon les modalitÃ©s dâ€™une variable qualitative. Si on reprend lâ€™exemple prÃ©cÃ©dent, on peut calculer la moyenne dâ€™Ã¢ge pour ceux qui pratiquent un sport et pour ceux qui nâ€™en pratiquent pas.\nUne premiÃ¨re mÃ©thode pour cela est dâ€™extraire de notre population autant de sous-populations quâ€™il y a de modalitÃ©s dans la variable qualitative. On peut le faire notamment avec la fonction subset.\n\nOn applique subset pour crÃ©er deux sous-populations, stockÃ©es dans deux nouveaux tableaux de donnÃ©esÂ :\n\nd_sport &lt;- subset(d, sport == \"Oui\")\nd_nonsport &lt;- subset(d, sport == \"Non\")\n\nOn peut ensuite utiliser ces deux nouveaux tableaux de donnÃ©es comme on en a lâ€™habitude, et calculer les deux moyennes dâ€™Ã¢geÂ :\n\nmean(d_sport$age)\n\n[1] 40.92531\n\n\n\nmean(d_nonsport$age)\n\n[1] 52.25137\n\n\nUne autre possibilitÃ© est dâ€™utiliser la fonction tapply, qui prend en paramÃ¨tre une variable quantitative, une variable qualitative et une fonction, puis applique automatiquement la fonction aux valeurs de la variables quantitative pour chaque niveau de la variable qualitativeÂ :\n\ntapply(d$age, d$sport, mean)\n\n     Non      Oui \n52.25137 40.92531 \n\n\n\n\n2.4.3 Croisement de deux variables quantitatives\nLe jeu de donnÃ©es hdv2003 comportant assez peu de variables quantitatives, on va sâ€™intÃ©resser maintenant Ã  un autre jeu de donnÃ©es comportant des informations du recensement de la population de 2012. On le charge avecÂ :\n\ndata(rp2012)\n\nUn nouveau tableau de donnÃ©es rp2012 devrait apparaÃ®tre dans votre environnement. Celui-ci comprend les 5170 communes de France mÃ©tropolitaine de plus de 2000 habitants, et une soixantaine de variables telles que le dÃ©partement, la population, le taux de chÃ´mage, etc. Pour une description plus complÃ¨te et une liste des variables, voir section @ref(rp2012).\n\n2.4.3.1 ReprÃ©sentation graphique\nQuand on croise deux variables quantitatives, lâ€™idÃ©al est de faire une reprÃ©sentation graphique sous forme de nuage de points Ã  lâ€™aide de la fonction plot. On va reprÃ©senter le croisement entre le pourcentage de cadres et le pourcentage de propriÃ©taires dans la communeÂ :\n\nplot(rp2012$cadres, rp2012$proprio)\n\n\n\nGraphique du pourcentage de propriÃ©taire en fonction du pourcentage de cadre\n\n\n\nUne reprÃ©sentation graphique est lâ€™idÃ©al pour visualiser lâ€™existence dâ€™un lien entre les deux variables. Voici quelques exemples dâ€™interprÃ©tationÂ :\n\n\n\n\nIllustration des relations bivariÃ©es\n\n\n\nDans ce premier graphique gÃ©nÃ©rÃ© sur nos donnÃ©es, il semble difficile de mettre en Ã©vidence une relation de dÃ©pendance. Si par contre on croise le pourcentage de cadres et celui de diplÃ´mÃ©s du supÃ©rieur, on obtient une belle relation de dÃ©pendance linÃ©aire.\n\nplot(dipl_sup ~ cadres, data = rp2012)\n\n\n\nRelation entre le nombre de personnes diplomÃ©es Ã  lâ€™universitÃ© et le nombre de cadre\n\n\n\n\n\n2.4.4 Exercices\nExercice 1\nDans le jeu de donnÃ©es hdv2003, faire le tableau croisÃ© entre la catÃ©gorie socio-professionnelle (variable qualif) et le fait de croire ou non en lâ€™existence des classes sociales (variable clso). Identifier la variable indÃ©pendante et la variable dÃ©pendante, et calculer les pourcentages ligne ou colonne. InterprÃ©ter le rÃ©sultat.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(questionr)\ndata(hdv2003)\ntab &lt;- table(hdv2003$qualif, hdv2003$clso)\n\n## Ici la variable indÃ©pendante est `qualif`, on calcule donc\n## les pourcentages lignes\nlprop(tab)\n\n\n\n\n\nReprÃ©senter ce tableau croisÃ© sous la forme dâ€™un mosaicplot en colorant les cases selon les rÃ©sidus du test du Ï‡Â².\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmosaicplot(tab, shade = TRUE)\n\n\n\n\nExercice 2\nToujours sur le jeu de donnÃ©es hdv2003, faire le boxplot qui croise le nombre dâ€™heures passÃ©es devant la tÃ©lÃ©vision (variable heures.tv) avec le statut dâ€™occupation (variable occup).\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nboxplot(hdv2003$heures.tv ~ hdv2003$occup)\n\n\n\n\nCalculer la durÃ©e moyenne devant la tÃ©lÃ©vision en fonction du statut dâ€™occupation Ã  lâ€™aide de tapply.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ntapply(hdv2003$heures.tv, hdv2003$occup, mean, na.rm = TRUE)\n\n\n\n\nExercice 3\nSur le jeu de donnÃ©es rp2012, reprÃ©senter le nuage de points croisant le pourcentage de personnes sans diplÃ´me (variable dipl_aucun) et le pourcentage de propriÃ©taires (variable proprio).\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(questionr)\ndata(rp2012)\nplot(rp2012$dipl_aucun, rp2012$proprio)\n## ou\nplot(proprio ~ dipl_aucun, data = rp2012)",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Introduction Ã  R</span>"
    ]
  },
  {
    "objectID": "02-introR.html#gÃ©rer-les-donnÃ©es",
    "href": "02-introR.html#gÃ©rer-les-donnÃ©es",
    "title": "\n2Â  Introduction Ã  R\n",
    "section": "\n2.5 GÃ©rer les donnÃ©es",
    "text": "2.5 GÃ©rer les donnÃ©es\n\n2.5.1 Importer et exporter des donnÃ©es\nIl existe de multiple format four sauvegarder les donnÃ©es, les 2 plus utiles sont .csv et .Rdata. Les fichiers .csv sont utilisÃ©s pour stocker des donnÃ©es. Ils sont ouvrables par les Ã©diteurs de texte (e.g.Â Word, Writer, atom, â€¦) et les tableurs (e.g.Â MS Excel, LO Calc). Ils sont lus avec la fonction read.csv et crÃ©Ã©s avec write.csv. Les fichiers .Rdata sont utilisÃ©s pour stocker nâ€™importe quel objet R pas uniquement des donnÃ©es. Cependant, ces fichiers ne peuvent Ãªtre lus et utilisÃ©s que par R. Ces fichiers sont lus avec la fonction load et crÃ©Ã©s avec la fonction save.\nLes donnÃ©es pour les exercices de laboratoire et pour les devoirs vous sont fournies en format .csv.\n\n2.5.1.1 RÃ©pertoire de travail\n\n\n\n\n\n\nAvertissement\n\n\n\nUne des erreurs les plus communes lorsque lâ€™on dÃ©bute avec R est liÃ© au chargement des donnÃ©es et la lecture de fichier externe Ã  R.\n\n\nUn message dâ€™erreur typique est:\nError in file(file, \"rt\") : cannot open the connection\nIn addition: Warning message:\nIn file(file, \"rt\") :\n  cannot open file 'ou_est_mon_fichier.csv': No such file or directory\nLâ€™erreur est du au fait que R ne sache pas oÃ¹ trouver le fichier. Par dÃ©faut lorsquâ€™on ouvre R, R utilise le dossier utilisateur sur lâ€™ordinateur comme dossier de travail. Cela signifie que R va cherhcer Ã  lire les fichiers dans ce dossier et Ã©crire les nouveaux fichiers dans ce dossier. Ceci nâ€™est pas toujours pratique surtout lorsque lâ€™on dÃ©bute avec R. Pour lire/Ã©crire un fichier dans un endroit particulier sur lâ€™ordinateur, il faut spÃ©cifier Ã  R le chemin de cet endroit. Cela peut ce faire de 3 maniÃ¨res diffÃ©rentes:\n\navec la fonction file.choose(). La fonction ouvrira une boÃ®te de dialogue vous permettant dâ€™aller choisir un fichier sur votre ordinateur. Si cette option semble trÃ¨s attirante de part sa simplicitÃ©, je ne recommande pas de sâ€™en servir car elle ne permet pas de reproduire lâ€™analyse facilement. En effet, elle nÃ©cessite de choisir le document chaque fois que lâ€™on souhaite lâ€™utiliser.\nen spÃ©cifiant le chemin complet du fichier dans la commande. Par example \"/home/julien/Documents/cours/BIO4558/labo/data/monfichier.csv\". Câ€™est assez long Ã  taper et surtout cela ne permet pas de facilement utliser le code sur un autre ordinateur.\nen spÃ©cifiant un rÃ©pertoire de travail avec la fonction setwd(). Ceci indique Ã  R de chercher et dâ€™Ã©crire les fichiers dans un dossier en particulier. Le chemin des fichiers est toujours interprÃ©tÃ© de maniÃ¨re relative au rÃ©pertoire de travail. Cela Ã  lâ€™avantage de pouvoir facilement utiliser le mÃªme code sur plusieurs ordinateur ssi la structure du dossier est la mÃªme.\n\nPOur connaitre le rÃ©pertoire de travail de R il faut utiliser la fonction getwd(). La fonction setwd() permet de spÃ©cifier le chemin du dossier Ã  utiliser comme rÃ©pertoire de travail.\n\n\n\n\n\n\nNote\n\n\n\nSi vous ouvrez RStudio en double-cliquant sur un fichier .R alors Rstudio utlisera le dossier oÃ¹ ce fichier est prÃ©sent comme rÃ©pertoire de travail. PlutÃ´t pratique car cela Ã©vite dâ€™avoir Ã  utiliser la fonction setwd().\n\n\n\n\n\n\n\n\nImportant\n\n\n\nPour lâ€™ensemble des laboratoire du cours, je suggÃ¨re de crÃ©er un dossier dans lequel seront sauvegardÃ©s tous les scripts dâ€™analyses et de sauvegardÃ©s tous les fichiers de donnÃ©es dans un sous dossier data. Le code du labo est structurÃ© de cette maniÃ¨re. Câ€™est pourquoi tous les codes de chargement ou dâ€™Ã©criture de donnÃ©es seront du type data/mon_fichier.xxx.\n\n\n\n2.5.1.2 Ouvrir un fichier de donnÃ©es en format .Rdata\n\nPour ouvrir ces fichiers, vous pouvez cliquer dessus et laisser votre systÃ¨me dâ€™exploitation dÃ©marrer une nouvelle session de R ou encore, Ã  partir de la console de R, utliser la fonction load avec le nom et le chemin du fichier de donnÃ©es. Par example, pour ouvrir le fichier ErablesGatineau.Rdata qui se situe dans le dossier data du dossier de travail, il faut taper:\n\nload(\"data/ErablesGatineau.Rdata\")\n\n\n2.5.1.3 Ouvrir un fichier de donnÃ©es en format .csv\n\nPour importer ces donnÃ©es en format .csv dans R, il faut utiliser la commande read.csv(). Par exemple, pour crÃ©er un objet R erables qui contient les donnÃ©es du fichier ErablesGatineau.csv, il faut utiliser la commande suivant.\n\nerables &lt;- read.csv(\"data/ErablesGatineau.csv\")\n\n\n\n\n\n\n\nAvertissement\n\n\n\nAttention si vous travaillez dans une langue utilisant la virgule au lieu du point dÃ©cimal. Par dÃ©faut, R utilise le point dÃ©cimal et vous nâ€™obtiendrez pas le rÃ©sultat escomptÃ©. Il existe une version modifiÃ©e de read.csv() appelÃ©e read.csv2() qui rÃ¨gle ce problÃ¨me. Googlez-la si vous en avez besoin.\n\n\nPour vÃ©rifier si les donnÃ©es ont bel et bien Ã©tÃ© lues, vous pouvez lister les objets en mÃ©moire avec la fonction ls() ou en obtenir une liste avec une description plus dÃ©taillÃ©e avec ls.str().\n\n\n\n\n\n\nNote\n\n\n\nJe vous dÃ©conseille cependant, la fonction ls.str() car elle peut produire des sorties extrÃ¨mementn longue si vous avez beaucoup dâ€™objet dans lâ€™environnement R. Je vous suggÃ¨re donc dâ€™utliser ls() et ensuite str() sur lâ€™objet qui vous intÃ©resse.\n\n\n\nls()\n\n [1] \"anglais\"        \"chien\"          \"d\"              \"d_nonsport\"    \n [5] \"d_sport\"        \"diplome\"        \"erables\"        \"hdv2003\"       \n [9] \"imc\"            \"maths\"          \"p\"              \"poids\"         \n[13] \"precipitations\" \"reg\"            \"resultat\"       \"rp2012\"        \n[17] \"s\"              \"sport\"          \"tab\"            \"taille1\"       \n[21] \"taille2\"        \"taille3\"        \"taille4\"        \"taille5\"       \n[25] \"tailles\"        \"tailles_m\"      \"temperature\"    \"title\"         \n[29] \"x\"              \"y\"             \n\nstr(erables)\n\n'data.frame':   100 obs. of  3 variables:\n $ station: chr  \"A\" \"A\" \"A\" \"A\" ...\n $ diam   : num  22.4 36.1 44.4 24.6 17.7 ...\n $ biom   : num  732 1171 673 1552 504 ...\n\n\nR confirme avoir en mÃ©moire lâ€™objet erables. erables est un tableau de donnÃ©es rectangulaire (data.frame) contenant 100 observations (lignes) de 3 variables (colonnes): station, une variable de type Facteur avec 2 niveaux, et diam et biom qui sont 2 variables numÃ©riques.\n\n2.5.1.4 Entrer des donnÃ©es\nR nâ€™est pas un environnement idÃ©al pour entrer des donnÃ©es. Câ€™est possible, mais la syntaxe est lourde et peut inciter Ã  sâ€™arracher les cheveux. Utilisez votre chiffrier prÃ©fÃ©rÃ© pour faire lâ€™entrÃ©e de donnÃ©es. Ce sera plus efficace et moins frustrant.\n\n2.5.1.5 Nettoyer/corriger des donnÃ©es\nUne autre opÃ©ration qui peut Ãªtre frustrante en R. Mon conseil : ne le faites pas lÃ . Retournez au fichier original, faites la correction, puis re-exportez les donnÃ©es vers R. Il est finalement plus simple de refaire exÃ©cuter les quelques lignes de code par la machine. Vous aurez Ã  la fin une seule version (corrigÃ©e) de vos donnÃ©es et un code qui vous permet de refaire votre analyse.\n\n2.5.1.6 Exporter des donnÃ©es Ã  partir de R.\nVous pouvez utiliser la fonction,\n\nwrite.csv(mydata, file = \"outfilename.csv\", row.names = FALSE)\n\noÃ¹ mydata est le nom du base de donnÃ©es Ã  exporter et outfilename.csv est le nom du fichier Ã  produire. Notez que ce fichier sera crÃ©Ã© dans le rÃ©pertoire de travail (qui peut Ãªtre changÃ© par le menu Ã  File&gt;Change dir, ou par la commande setwd())\n\n2.5.2 Examen prÃ©liminaire des donnÃ©es\nLa premiÃ¨re Ã©tape de toute analyse est lâ€™examen des donnÃ©es. Elle nous permet de dÃ©couvrir si on a bien importÃ© les donnÃ©es, si les nombres enregistrÃ©s sont possibles, si toutes les donnÃ©es ont bien Ã©tÃ© lues, etc. Lâ€™examen prÃ©liminaire des donnÃ©es permet souvent aussi dâ€™identifier des observations suspectes, possiblement dÃ»es Ã  des erreurs dâ€™entrÃ©e de donnÃ©e. Finalement, lâ€™examen graphique prÃ©liminaire permet en gÃ©nÃ©ral de visualiser les tendances principales qui seront confirmÃ©es par lâ€™analyse statistique en tant que telle. Le fichier sturgeon.csv contient les donnÃ©es dâ€™une Ã©tude effectuÃ©e sur les esturgeons de la riviÃ¨re Saskatchewan. Ces donnÃ©es ont Ã©tÃ© rÃ©coltÃ©es, entre autres, pour examiner comment la taille des esturgeons varie entre les sexes (sex), les sites (location), et les annÃ©es (year).\n\n\nChargez les donnÃ©es du fichier sturgeon.csv dans un objet sturgeon.\nPour obtenir un aperÃ§u des Ã©lÃ©ments du fichier qui ont Ã©tÃ© chargÃ©s en mÃ©moire, taper la commande str(sturgeon).\n\n\nsturgeon &lt;- read.csv(\"data/sturgeon.csv\")\nstr(sturgeon)\n\n'data.frame':   186 obs. of  9 variables:\n $ fklngth : num  37 50.2 28.9 50.2 45.6 ...\n $ totlngth: num  40.7 54.1 31.3 53.1 49.5 ...\n $ drlngth : num  23.6 31.5 17.3 32.3 32.1 ...\n $ rdwght  : num  15.95 NA 6.49 NA 29.92 ...\n $ age     : int  11 24 7 23 20 23 20 7 23 19 ...\n $ girth   : num  40.5 53.5 31 52.5 50 54.2 48 28.5 44 39 ...\n $ sex     : chr  \"MALE\" \"FEMALE\" \"MALE\" \"FEMALE\" ...\n $ location: chr  \"THE_PAS\" \"THE_PAS\" \"THE_PAS\" \"THE_PAS\" ...\n $ year    : int  1978 1978 1978 1978 1978 1978 1978 1978 1978 1978 ...\n\n\n\n2.5.2.1 Sommaire statistique\nPour un sommaire du contenu du base de donnÃ©es appelÃ© sturgeon qui est en mÃ©moire, taper la commande\n\nsummary(sturgeon)\n\n    fklngth         totlngth        drlngth          rdwght     \n Min.   :24.96   Min.   :28.15   Min.   :14.33   Min.   : 4.73  \n 1st Qu.:41.00   1st Qu.:43.66   1st Qu.:25.00   1st Qu.:18.09  \n Median :44.06   Median :47.32   Median :27.00   Median :23.10  \n Mean   :44.15   Mean   :47.45   Mean   :27.29   Mean   :24.87  \n 3rd Qu.:48.00   3rd Qu.:51.97   3rd Qu.:29.72   3rd Qu.:30.27  \n Max.   :66.85   Max.   :72.05   Max.   :41.93   Max.   :93.72  \n                 NA's   :85      NA's   :13      NA's   :4      \n      age            girth           sex              location        \n Min.   : 7.00   Min.   :11.50   Length:186         Length:186        \n 1st Qu.:17.00   1st Qu.:40.00   Class :character   Class :character  \n Median :20.00   Median :44.00   Mode  :character   Mode  :character  \n Mean   :20.24   Mean   :44.33                                        \n 3rd Qu.:23.50   3rd Qu.:48.80                                        \n Max.   :55.00   Max.   :73.70                                        \n NA's   :11      NA's   :85                                           \n      year     \n Min.   :1978  \n 1st Qu.:1979  \n Median :1979  \n Mean   :1979  \n 3rd Qu.:1980  \n Max.   :1980  \n               \n\n\nPour chaque variable, R donne le minimum, le maximum, la mÃ©diane qui est la valeur au milieu de la liste des observations ordonnÃ©es (appelÃ©e le 50 iÃ¨me percentile), ici, la 93 iÃ¨me valeur des 186 observations, les valeurs au premier (25%) et troisiÃ¨me quartile (75%), et si il y a des valeurs manquantes dans la colonne. Notez que plusieurs des variables ont des observations manquantes (NA). Donc, seules les variables fklngth (longueur Ã  la fourche), sex, location et year ont 186 observations.\n\n\n\n\n\n\nAvertissement\n\n\n\nAttention aux valeurs manquantes Plusieurs fonctions de R y rÃ©agissent mal et on doit souvent faire les analyses sur des sous- ensembles sans valeur manquante, par des commandes ou des options dans les commandes. On y reviendra, mais prenez lâ€™habitude de noter mentalement si il y a des donnÃ©es manquantes et de vous en rappeler en faisant lâ€™analyse.\n\n\n\n2.5.2.2 Histogramme, densitÃ© de probabilitÃ© empirique, boxplot et examen visuel de la normalitÃ©\nExaminons maintenant de plus prÃ¨s la distribution de fklngth. La commande hist() permet de tracer un histogramme de la variable fklngth dans le base de donnÃ©es sturgeon.\n\nhist(sturgeon$fklngth)\n\n\n\n\n\n\n\nLes donnÃ©es semblent suivre approximativement une distribution normale.\n\n\n\n\n\n\nNote\n\n\n\nCette syntaxe peut paraÃ®tre un peu lourde puisquâ€™on doit ajouter le prÃ©fixe sturgeon$ devant chaque nom de variable. On pourrait se faciliter la tÃ¢che en utilisant la commande attach() mais cela est fortement dÃ©conseillÃ© et jamais utilisÃ© dans ce document.\n\n\nCet histogramme est la reprÃ©sentation classique. Mais les histogrammes ne sont pas parfaits. Leur forme dÃ©pend en partie du nombre de catÃ©gories utilisÃ©es, surtout pour les petits Ã©chantillons. On peut faire mieux, particuliÃ¨rement si on est intÃ©ressÃ© Ã  comparer visuellement la distribution des observations Ã  une distribution normale. Mais il faut programmer un peu (ou savoir copier-collerâ€¦). Le code suivant est un histogramme fait avec lâ€™extension ggplot2.\n\n\n\n\n\n\nExercice\n\n\n\nCopiez-collez le code suivant dans une nouvelle fenÃªtre script (File-&gt;New script, ou Ctrl-n dans Windows), puis exÃ©cutez le.\n\n\n\n## Chargez l'extension ggplot si besoin\nlibrary(ggplot2)\n##  crÃ©er un graphique `mygraph` utilisant les donnÃ©es de \"sturgeon\"\n## et dÃ©finir l'axe des X comme la longueur `fklngth`\nmygraph &lt;- ggplot(data = sturgeon, aes(x = fklngth))\n\n## ajouter diffÃ©rentes parties au graphique\nmygraph &lt;- mygraph +\n  ## histogramme semi-transparent\n  geom_histogram(aes(y = ..density..), bins = 30, color = \"black\", alpha = 0.3) +\n  ##  line de densitÃ©\n  geom_density() +\n  ##  localisation des observations\n  geom_rug() +\n  ##  courbe de distribution normale approximÃ© au donnÃ©es\n  stat_function(\n    fun = dnorm,\n    args = list(\n      mean = mean(sturgeon$fklngth),\n      sd = sd(sturgeon$fklngth)\n    ),\n    color = \"red\"\n  )\n\n## montrer le graphique\nmygraph\n\n\n\n\n\n\n\nChaque observation est reprÃ©sentÃ©e par une barre sous lâ€™axe des x (rug). En rouge est la distribution normale de donnÃ©es avec la mÃªme moyenne et Ã©cart-type que les observations. Et lâ€™autre ligne est la densitÃ© de probabilitÃ© empirique, Â« lissÃ©e Â» Ã  partir des observations. Si vous Ãªtes plus aventureux, vous pouvez examiner la distribution des observations de fklngth par sous-groupes (par exemple sex et year) avec :\n\nmygraph + facet_grid(year ~ sex)\n\n\n\n\n\n\n\nChaque panneau illustre la distribution pour un sexe cette annÃ©e-lÃ , et la courbe en rouge rÃ©currente reprÃ©sente la distribution normale pour lâ€™ensemble des donnÃ©es. Cette courbe peut servir Ã  mieux Ã©valuer visuellement les diffÃ©rences entre les panneaux. Une autre faÃ§on dâ€™Ã©valuer la normalitÃ© de donnÃ©es visuellement est de faire un QQ plot avec la paire de commandes qqnorm() et qqline().\n\nqqnorm(sturgeon$fklngth)\nqqline(sturgeon$fklngth)\n\n\n\n\n\n\n\nDes donnÃ©es parfaitement normales suivraient la ligne droite diagonale. Ici, il y a des dÃ©viations dans les queues de la distribution, et un peu Ã  droite du centre. Comparez cette reprÃ©sentation Ã  celle des deux graphiques prÃ©cÃ©dents. Vous conviendrez sans doute avec moi quâ€™il est plus facile de visualiser comment la distribution dÃ©vie de la normalitÃ© sur les histogrammes et les graphiques de la densitÃ© empirique de probabilitÃ© que sur les QQ plots. Ceci dit, les QQ plots sont souvent utilisÃ©s et vous devriez Ãªtre capable de les interprÃ©ter. De plus, on peut facilement Ã©prouver statistiquement lâ€™hypothÃ¨se que les donnÃ©es sont distribuÃ©es normalement avec R par la commande shapiro.test() qui calcule une statistique (W) qui est une mesure de la tendance des points dâ€™un QQ plot Ã  former une ligne parfaite. Si oui, alors W=1. Si W sâ€™Ã©loigne de 1 (vers 0), alors les donnÃ©es sâ€™Ã©loignent de la normalitÃ©. Ici,\n\nshapiro.test(sturgeon$fklngth)\n\n\n    Shapiro-Wilk normality test\n\ndata:  sturgeon$fklngth\nW = 0.97225, p-value = 0.0009285\n\n\nW nâ€™est pas trÃ¨s loin de 1, mais suffisamment pour que la diffÃ©rence soit significative. Lâ€™examen visuel des grands Ã©chantillons est souvent compliquÃ© par le fait que plusieurs points se superposent et quâ€™il devient plus difficile de bien visualiser la tendance centrale. Les boxplots avec â€œmoustachesâ€ (box and whiskers plots) offrent une alternative intÃ©ressante. La commande boxplot() peut produire un boxplot de fklngth pour chaque niveau de sex, et ajoute les coches.\n\nboxplot(fklngth ~ sex, data = sturgeon, notch = TRUE)\n\n\n\n\n\n\n\nLa ligne un peu plus Ã©paisse dans la boÃ®te de la Figure indique la mÃ©diane. La coche est proportionnelle Ã  lâ€™incertitude quant Ã  la position de la mÃ©diane. On peut visuellement interprÃ©ter approximativement les diffÃ©rences entre mÃ©dianes en examinant si il y a chevauchement entre les coches (ici, il nâ€™y a pas chevauchement, et on conclurait provisoirement que la mÃ©diane de fklngth pour les femelles est supÃ©rieure Ã  celle des mÃ¢les). Les boÃ®tes sâ€™Ã©tendent du premier au troisiÃ¨me quartile (du 25iÃ¨me au 75iÃ¨me percentile si vous prÃ©fÃ©rez), Les barres (moustaches ou whiskers) au-dessus et en dessous des boÃ®tes sâ€™Ã©tendent soit de la valeur minimum Ã  la valeur maximum, ou, si il y a des valeurs extrÃªmes, de la plus petite Ã  la plus grande valeur Ã  lâ€™intÃ©rieur de 1.5x la largeur de lâ€™Ã©tendue interquartile . Enfin, les observations qui excÃ¨dent les limites des moustaches (donc Ã  plus de 1.5x lâ€™Ã©tendue interquartile de chaque cÃ´tÃ© de la mÃ©diane) sont indiquÃ©es par des symboles.Ce sont des valeurs qui pourraient Ãªtre considÃ©rÃ©es comme extrÃªmes et possiblement aberrantes.\n\n2.5.2.3 Diagrammes de dispersion bivariÃ©s\nEn plus des graphiques pour chacune des variables sÃ©parÃ©ment, il est trÃ¨s souvent intÃ©ressant de jeter un coup dâ€™oeil aux diagrammes de dispersion . La commande plot(y~x) permet de faire le graphique de y sur lâ€™axe vertical (lâ€™ordonnÃ©e) en fonction de x sur lâ€™axe horizontal (lâ€™abscisse).\n\n\n\n\n\n\nExercice\n\n\n\nFaites un graphique de fklngth en fonction de age avec la commande plot.\n\n\nVous devriez obtenir:\n\nplot(fklngth ~ age, data = sturgeon)\n\n\n\n\n\n\n\nR a une fonction qui permet la crÃ©ation des graphiques de dispersion de toutes les paires de variables (pairs()). Une des option de Â¬ est lâ€™ajout dâ€™une trace lowess qui indique la tendance de la relation entre les variables. Pour obtenir la matrice de ces graphiques avec la trace lowess pour toutes les variable dans sturgeon, entrer la commande pairs(sturgeon[,1:6], panel=panel.smooth) et vous devriez obtenir\n\npairs(sturgeon[, 1:6], panel = panel.smooth)\n\n\n\n\n\n\n\n\n2.5.3 CrÃ©er des sous-ensembles de cas\nIl arrive frÃ©quemment quâ€™une analyse se concentre sur un sous-ensemble des observations contenues dans un fichier de donnÃ©es. Les cas sont dâ€™habitude sÃ©lectionnÃ©s selon un critÃ¨re en particulier. Pour utiliser un sous-ensemble de vos donnÃ©es en crÃ©ant un graphique ou en performant une analyse, on peut utiliser la commande subset(). Par exemple, pour crÃ©er un sous ensemble des donnÃ©es du tableau sturgeon qui ne contient que les femelles capturÃ©es en 1978, on peut Ã©crire :\n\nsturgeon_female_1978 &lt;- subset(sturgeon, sex == \"FEMALE\" & year == \"1978\")\nsturgeon_female_1978\n\n     fklngth totlngth  drlngth rdwght age girth    sex   location year\n2   50.19685 54.13386 31.49606     NA  24  53.5 FEMALE    THE_PAS 1978\n4   50.19685 53.14961 32.28346     NA  23  52.5 FEMALE    THE_PAS 1978\n6   49.60630 53.93701 31.10236  35.86  23  54.2 FEMALE    THE_PAS 1978\n7   47.71654 51.37795 33.97638  33.88  20  48.0 FEMALE    THE_PAS 1978\n15  48.89764 53.93701 29.92126  35.86  23  52.5 FEMALE    THE_PAS 1978\n105 46.85039       NA 28.34646  23.90  24    NA FEMALE CUMBERLAND 1978\n106 40.74803       NA 24.80315  17.50  18    NA FEMALE CUMBERLAND 1978\n107 40.35433       NA 25.59055  20.90  21    NA FEMALE CUMBERLAND 1978\n109 43.30709       NA 27.95276  24.10  19    NA FEMALE CUMBERLAND 1978\n113 53.54331       NA 33.85827  48.90  20    NA FEMALE CUMBERLAND 1978\n114 51.77165       NA 31.49606  35.30  26    NA FEMALE CUMBERLAND 1978\n116 45.27559       NA 26.57480  23.70  24    NA FEMALE CUMBERLAND 1978\n118 53.14961       NA 32.67717  45.30  25    NA FEMALE CUMBERLAND 1978\n119 50.19685       NA 32.08661  33.90  26    NA FEMALE CUMBERLAND 1978\n123 49.01575       NA 29.13386  37.50  22    NA FEMALE CUMBERLAND 1978\n\n\n\n\n\n\n\n\nAvertissement\n\n\n\nDans ces comparaisons, il faut toujours utiliser == pour Ã©gal Ã . Dans ce contexte, si vous utilisez = seulement, vous nâ€™obtiendrez pas ce que vous dÃ©sirez. Dans le tableau qui suit se trouve une liste de commandes communes que vous allez probablement utiliser pour crÃ©er des expressions en R.\n\n\n\n\nOperateur\nExplication\nOperateur\nExplication\n\n\n\n==\nÃ‰gal Ã \n!=\nPas Ã©gal Ã \n\n\n&gt;\nPlus que\n&lt;\nMoins que\n\n\n&gt;=\nPlus que ou Ã©gal Ã \n&lt;=\nMoins que ou Ã©gal Ã \n\n\n&\nEt vectorisÃ©\n|\nOu vectorisÃ©\n\n\n&&\nEt contrÃ´le\n||\nOu contrÃ´le\n\n\n!\nPas\n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nEn utilisant les commandes subset() et hist(), essayez de faire un histogramme pour le sous-ensemble de cas correspondant aux femelles capturÃ©es en 1979 et 1980 (donc sex == \"FEMALE\" & (year == \"1979\" | year == \"1980\"))\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsub_female_7980 &lt;- subset(sturgeon, sex == \"FEMALE\" & (year == \"1979\" | year == \"1980\"))\nhist(sub_female_7980$fklngth)\n\n\n\n\n\n\n\n\n\n\n\n2.5.4 Transformations de donnÃ©es\nIl est trÃ¨s frÃ©quemment nÃ©cessaire dâ€™effectuer des transformations mathÃ©matiques sur les donnÃ©es brutes pour mieux satisfaire aux conditions dâ€™application de tests statistiques. R Ã©tant aussi un langage de programmation complet, il peut donc effectuer les transformations dÃ©sirÃ©es. Les fonctions les plus frÃ©quemment utilisÃ©es sont:\n\nlog()\nsqrt()\nifelse()\n\nOn peut employer ces fonctions directement dans les lignes de commandes, ou encore crÃ©er de nouvelles variables orphelines ou faisant partie dâ€™un data.frame. Par exemple, pour faire un graphique du logarithme dÃ©cimal de fklngth en fonction de lâ€™Ã¢ge, on peut Ã©crire\n\nplot(log(fklngth) ~ age, data = sturgeon)\n\nPour crÃ©er une variable orpheline (i.e.Â non incluse dans le data.frame) appelÃ©e logfklngth et contenant le logarithme dÃ©cimal de fklngth, on peut Ã©crire\n::: {.cell}\nlogfklngth &lt;- log10(sturgeon$fklngth)\n:::\nSi on veut ajouter cette variable transformÃ©e Ã  un tableau de donnÃ©es (data.frame), alors, on doit prÃ©fixer le nom de la variable par le nom du base de donnÃ©es et du symbole $, par exemple, pour ajouter une variable nommÃ©e lfkl contenant le log10 de fklngth au tableau sturgeon, on peut Ã©crire:\n\nsturgeon$logfkl &lt;- log10(sturgeon$fklngth)\n\nNâ€™oubliez pas de sauvegarder ce tableau modifiÃ© si vous voulez avoir accÃ¨s Ã  cette nouvelle variable dans le futur. Pour les transformations conditionnelles, on peut utiliser la fonction ifelse(). Par exemple, pour crÃ©er une nouvelle variable appelÃ©e dummy qui sera Ã©gale Ã  1 pour les mÃ¢les et 0 pour les femelles, on peut Ã©crire:\n\nsturgeon$dummy &lt;- ifelse(sturgeon$sex == \"MALE\", 1, 0)\n\n\n2.5.5 Exercice sur R\nVous trouverez dans le fichier salmonella.csv, des valeurs numÃ©riques du ratio dâ€™infection des cellules par la salmonelle dans deux milieux (IN VITRO et IN VIVO) et pour trois souches diffÃ©rentes de salmonelles. Examinez les donnÃ©es pour le ratio et faites des graphiques pour Ã©valuer la normalitÃ© de la distribution des ratios pour la souche SAUVAGE dans les 2 milieux combinÃ©s et produire un graphique.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n## Charger les donnÃ©es\nsalmonella &lt;- read.csv(\"data/salmonella.csv\")\n\n## creer le graph en utilisant juste la souche sauvage et dÃ©finir x\nmygraph &lt;- ggplot(subset(salmonella, souche == \"SAUVAGE\"), aes(x = ratio))\n## ajouter des composants graphiques\nmygraph &lt;- mygraph +\n  # line densitÃ©\n  geom_density() +\n  # position des observations\n  geom_rug() +\n  # histogramme\n  geom_histogram(aes(y = ..density..),\n    bins = 30,\n    color = \"black\",\n    alpha = 0.3\n  ) +\n  # distribution normal ajustÃ©e\n  stat_function(\n    fun = dnorm,\n    args = list(\n      mean = mean(subset(salmonella, souche == \"SAUVAGE\")$ratio),\n      sd = sd(subset(salmonella, souche == \"SAUVAGE\")$ratio)\n    ),\n    color = \"red\"\n  )\n## faire le graphique\nmygraph\n\n\n\nDistibution des ratios dâ€™infections par la souche sauvage de salmonelle",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Introduction Ã  R</span>"
    ]
  },
  {
    "objectID": "02-introR.html#footnotes",
    "href": "02-introR.html#footnotes",
    "title": "\n2Â  Introduction Ã  R\n",
    "section": "",
    "text": "On peut ignorer pour le moment la prÃ©sence du [1] en dÃ©but de ligne.â†©ï¸\nc est lâ€™abbrÃ©viation de combine, son nom est trÃ¨s court car on lâ€™utilise trÃ¨s souventâ†©ï¸\nLa seule limite pour la taille dâ€™un objet Ã©tant la mÃ©moire vive (RAM) de la machine sur laquelle tourne la session R.â†©ï¸\nLes diffÃ©rents types de variables seront dÃ©crits plus en dÃ©tail dans le chapitre @ref(vectorfactor) sur les recodages.â†©ï¸\nLes diffÃ©rentes maniÃ¨res de spÃ©cifier des couleurs sont indiquÃ©es dans lâ€™encadrÃ© de la section @ref(scalecolor).â†©ï¸",
    "crumbs": [
      "DonnÃ©es",
      "Utiliser R",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Introduction Ã  R</span>"
    ]
  },
  {
    "objectID": "25-power.html",
    "href": "25-power.html",
    "title": "\n3Â  Analyse de puissance avec R et G*Power\n",
    "section": "",
    "text": "3.1 La thÃ©orie",
    "crumbs": [
      "DonnÃ©es",
      "Fundamentals of stats",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Analyse de puissance avec R et G\\*Power</span>"
    ]
  },
  {
    "objectID": "25-power.html#la-thÃ©orie",
    "href": "25-power.html#la-thÃ©orie",
    "title": "\n3Â  Analyse de puissance avec R et G*Power\n",
    "section": "",
    "text": "3.1.1 Quâ€™est-ce que la puissance?\nLa puissance est la probabilitÃ© de rejeter lâ€™hypothÃ¨se nulle quand elle est fausse.\n\n3.1.2 Pourquoi faire une analyse de puissance?\nÃ‰valuer lâ€™Ã©vidence\nLâ€™analyse de puissance effectuÃ©e aprÃ¨s avoir acceptÃ© une hypothÃ¨se nulle permet de calculer la probabilitÃ© que lâ€™hypothÃ¨se nulle soit rejetÃ©e si elle Ã©tait fausse et que la taille de lâ€™effet Ã©tait dâ€™une valeur donnÃ©e. Ce type dâ€™analyse a posteriori est trÃ¨s commun.\nPlanifier de meilleures expÃ©riences\nLâ€™analyse de puissance effectuÃ©e avant de rÃ©aliser une expÃ©rience (le plus souvent aprÃ¨s une expÃ©rience prÃ©liminaire cependant), permet de dÃ©terminer le nombre dâ€™observations nÃ©cessaires pour dÃ©tecter un effet dâ€™une taille donnÃ©e Ã  un niveau fixe de probabilitÃ© (la puissance). Ce type dâ€™analyse a priori devrait Ãªtre rÃ©alisÃ© plus souvent.\nEstimer la â€œlimite de dÃ©tectionâ€ statistique\nLâ€™effort dâ€™Ã©chantillonnage est souvent dÃ©terminÃ© Ã  lâ€™avance (par exemple lorsque vous hÃ©ritez de donnÃ©es rÃ©coltÃ©es par quelquâ€™un dâ€™autre), ou trÃ¨s sÃ©vÃ¨rement limitÃ© (lorsque les contraintes logistiques prÃ©valent). Que ce soit a priori ou a posteriori lâ€™analyse de puissance vous permet dâ€™estimer, pour un effort dâ€™Ã©chantillonnage donnÃ© et un niveau de puissance fixe, quelle est la taille minimale de lâ€™effet qui peut Ãªtre dÃ©tectÃ© (comme Ã©tant statistiquement significatif).\n\n3.1.3 Facteurs qui affectent la puissance\nIl y a 3 facteurs qui affectent la puissance dâ€™un test statistique.\nLe critÃ¨re de dÃ©cision\nLa puissance dÃ©pend de \\(\\alpha\\), le seuil de probabilitÃ© auquel on rejette lâ€™hypothÃ¨se nulle. Si ce seuil est trÃ¨s strict (i.e. si \\(\\alpha\\) est fixÃ© Ã  une valeur trÃ¨s basse, comme 0.1% ou p = 0.001), alors la puissance sera plus faible que si le seuil Ã©tait moins strict.\nLa taille de lâ€™Ã©chantillon\nPlus lâ€™Ã©chantillon est grand, plus la puissance est Ã©levÃ©e. La capacitÃ© dâ€™un test Ã  dÃ©tecter de petites diffÃ©rences comme Ã©tant statistiquement significatives augmente avec une augmentation du nombre dâ€™observations.\nLa taille de lâ€™effet\nPlus la taille de lâ€™effet est grande, plus un test a de puissance. Pour un Ã©chantillon de taille fixe, la capacitÃ© dâ€™un test Ã  dÃ©tecter un effet comme Ã©tant statistiquement significatif est plus Ã©levÃ©e si lâ€™effet est grand que sâ€™il est petit. La taille de lâ€™effet est en fait une mesure du degrÃ© de faussetÃ© de lâ€™hypothÃ¨se nulle.",
    "crumbs": [
      "DonnÃ©es",
      "Fundamentals of stats",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Analyse de puissance avec R et G\\*Power</span>"
    ]
  },
  {
    "objectID": "25-power.html#quest-ce-que-gpower",
    "href": "25-power.html#quest-ce-que-gpower",
    "title": "\n3Â  Analyse de puissance avec R et G*Power\n",
    "section": "\n3.2 Quâ€™est ce que G*Power?",
    "text": "3.2 Quâ€™est ce que G*Power?\nG*Power est un programme gratuit, dÃ©veloppÃ© par des psychologues de lâ€™UniversitÃ© de Dusseldorf en Allemagne. Le programme existe en version Mac et Windows. Il peut cependant Ãªtre utilisÃ© sous linux via Wine. G*Power vous permettra dâ€™effectuer une analyse de puissance pour la majoritÃ© des tests que nous verrons au cours de la session sans avoir Ã  effectuer des calculs complexes ou farfouiller dans des tableaux ou des figures dÃ©crivant des distributions ou des courbes de puissance. Il est possible de faire tous les analyses de G*power avec R, mais cela est nettement plus complexes, car il faut tous coder Ã  la main. Dans les cas les plus simple le code R est aussi fourni. G*power est vraiment un outil trÃ¨s utile que vous devrez maÃ®triser.\n\n\n\n\n\n\nExercice\n\n\n\nTÃ©lÃ©chargez le programme ici et installez-le sur votre ordi et votre station de travail au laboratoire (si ce nâ€™est dÃ©jÃ  fait).",
    "crumbs": [
      "DonnÃ©es",
      "Fundamentals of stats",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Analyse de puissance avec R et G\\*Power</span>"
    ]
  },
  {
    "objectID": "25-power.html#comment-utiliser-gpower",
    "href": "25-power.html#comment-utiliser-gpower",
    "title": "\n3Â  Analyse de puissance avec R et G*Power\n",
    "section": "\n3.3 Comment utiliser G*Power",
    "text": "3.3 Comment utiliser G*Power\n\n3.3.1 Principe gÃ©nÃ©ral\nLâ€™utilisation de G*Power implique gÃ©nÃ©ralement en trois Ã©tapes:\n\nChoisir le test appropriÃ©\nChoisir lâ€™un des 5 types dâ€™analyses de puissance disponibles\nInscrire les valeurs des paramÃ¨tres requis et cliquer sur Calculate\n\n3.3.2 Types dâ€™analyses de puissance disponibles\nA priori\nCalcule lâ€™effectif requis pour une valeur de \\(\\alpha\\), \\(\\beta\\) et de taille dâ€™effet donnÃ©e. Ce type dâ€™analyse est utile Ã  lâ€™Ã©tape de planification des expÃ©riences.\nCompromis\nCalcule \\(\\alpha\\) et \\(\\beta\\) pour un rapport \\(\\beta / \\alpha\\) donnÃ©, un effectif fixe, et une taille dâ€™effet donnÃ©e. Ce type dâ€™analyse est plus rarement utilisÃ© (je ne lâ€™ai jamais fait), mais peut Ãªtre utile lorsque le rapport \\(\\beta / \\alpha\\) est dâ€™intÃ©rÃªt, par exemple lorsque le coÃ»t dâ€™une erreur de type I et de type II peut Ãªtre quantifiÃ©.\nCritÃ¨re\nCalcule \\(\\alpha\\) pour \\(\\beta\\), effectif et taille dâ€™effet donnÃ©. En pratique, je vois peu dâ€™utilitÃ© pour ce type de calcul. Contactez-moi si vous en voyez une!\nPost-hoc\nCalcule la puissance (1 - \\(\\beta\\)) pour \\(\\alpha\\), une taille dâ€™effet et un effectif donnÃ©. TrÃ¨s utilisÃ©e pour interprÃ©ter les rÃ©sultats dâ€™une analyse statistique non-significative, mais seulement si lâ€™on utilise une taille dâ€™effet biologiquement significative (et non la taille dâ€™effet observÃ©e). Peu pertinente lorsque le test est significatif.\nSensitivitÃ©\nCalcule la taille dâ€™effet dÃ©tectable pour une valeur dâ€™\\(\\alpha\\), \\(\\beta\\) et un effectif donnÃ©. TrÃ¨s utile Ã©galement au stade de planification des expÃ©riences.\n\n3.3.3 Comment calculer la taille de lâ€™effet G*Power permet de faire une analyse de puissance pour de nombreux tests statistiques\nLâ€™indice de la taille de lâ€™effet qui est utilisÃ© par G*Power pour les calculs dÃ©pend du test. Notez que dâ€™autres logiciels peuvent utiliser des indices diffÃ©rents et il est important de vÃ©rifier que lâ€™indice que lâ€™on utilise est celui qui convient. G*Power vous facilite la tÃ¢che et permet de calculer la taille de lâ€™effet en inscrivant seulement les valeurs pertinentes dans la fenÃªtre de calcul. Le tableau suivant donne les indices utilisÃ©s par G*Power pour les diffÃ©rents tests.\n\n\n\n\n\n\n\nTest\nTaille dâ€™effet\nFormule\n\n\n\ntest de t sur des moyennes\nd\n\\(d = \\frac{|\\mu_1 - \\mu_2|}{\\sqrt{({s_1}^2 + {s_2}^2)/2}}\\)\n\n\ntest de t pour des corrÃ©lations\nr\n\n\n\nautres tests de t\nd\n\\(d = \\frac{\\mu}{\\sigma}\\)\n\n\ntest F (ANOVA)\nf\n\\(f = \\frac{\\frac{\\sqrt{\\sum_{i=1}^k (\\mu_i - \\mu)^2}}{k}}{\\sigma}\\)\n\n\nautres test F\n\\(f^2\\)\n\\(f^2 = \\frac{{R_p}^2}{1-{R_p}^2}\\)\n\n\n\n\n\n\\({R_p}\\) est le coefficient de corrÃ©lation partiel\n\n\ntest Chi-carrÃ©\nw\n\\(w = \\sqrt{ \\sum_{i=1}^m \\frac{(p_{0i} - p_{1i})^2 }{ p_{0i}} }\\)\n\n\n\n\n\n\\(p_{0i}\\) \\(p_{1i}\\) sont les proportions de la catÃ©gorie i prÃ©dites par lâ€™hypothÃ¨se nulle et alternative respectivement",
    "crumbs": [
      "DonnÃ©es",
      "Fundamentals of stats",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Analyse de puissance avec R et G\\*Power</span>"
    ]
  },
  {
    "objectID": "25-power.html#puissance-pour-un-test-de-t-comparant-deux-moyennes",
    "href": "25-power.html#puissance-pour-un-test-de-t-comparant-deux-moyennes",
    "title": "\n3Â  Analyse de puissance avec R et G*Power\n",
    "section": "\n3.4 Puissance pour un test de t comparant deux moyennes",
    "text": "3.4 Puissance pour un test de t comparant deux moyennes\n\n\n\n\n\n\nImportant\n\n\n\nLâ€™ensemble des analyses de puissance dÃ©crites aprÃ¨s peuvent Ãªtre rÃ©alisÃ© avec 2 fonctions dans R.\n\n\npwr.t.test(): lorsque les tailles dâ€™Ã©chantillons sont identiques\n\npwr.t2n.test(): lorsque les Ã©chantillons ont des tailles diffÃ©rentes\n\n\n\nLâ€™objectif de cette sÃ©ance de laboratoire est de vous familiariser avec G*Power et de vous aider Ã  comprendre comment les quatre paramÃ¨tres des analyses de puissance (\\(\\alpha\\), \\(\\beta\\), effectif et taille de lâ€™effet) sont reliÃ©s entre eux. On examinera seulement un des nombreux tests, le test de t permettant de comparer deux moyennes indÃ©pendantes. Câ€™est le test le plus communÃ©ment utilisÃ© par les biologistes, vous lâ€™avez tous dÃ©jÃ  utilisÃ©, et il conviendra trÃ¨s bien pour les besoins de la cause. Ce que vous apprendrez aujourdâ€™hui sâ€™appliquera Ã  toutes les autres analyses de puissance que vous effectuerez Ã  lâ€™avenir.\nJaynie Stephenson a Ã©tudiÃ© la productivitÃ© des ruisseaux de la rÃ©gion dâ€™Ottawa. Elle a, entre autres, quantifiÃ© la biomasse des poissons dans 18 ruisseaux sur le Bouclier Canadien dâ€™une part, et dans 18 autres ruisseaux de la vallÃ©e de la riviÃ¨re des Outaouais et de la riviÃ¨re Rideau dâ€™autre part. Elle a observÃ© une biomasse plus faible dans les ruisseaux de la vallÃ©e (2.64 \\(g/m^2\\), Ã©cart-type=3.28) que dans ceux du Bouclier (3.31 \\(g/m^2\\), Ã©cart-type=2.79). En faisant un test de t pour Ã©prouver lâ€™hypothÃ¨se nulle que la biomasse des poissons est la mÃªme dans les deux rÃ©gions, elle obtient:\nPooled-Variance Two-Sample t-Test\nt = -0.5746, df = 34, p-value = 0.5693\nElle accepte lâ€™hypothÃ¨se nulle (puisque p est plus Ã©levÃ© que 0.05) conclue donc que la biomasse moyenne des poissons est la mÃªme dans ces deux rÃ©gions.\n\n3.4.1 Analyse post-hoc\nCompte tenu des valeurs des moyennes observÃ©es et de leur Ã©cart- type, on peut utiliser G*Power pour calculer la puissance du test de t bilatÃ©ral pour deux moyennes indÃ©pendantes et pour la taille dâ€™effet (i.e.Â la diffÃ©rence entre la biomasse entre les deux rÃ©gions, pondÃ©rÃ©e par les Ã©carts-type) Ã  \\(\\alpha\\) = 0.05.\nDÃ©marrer G*Power.\n\nÃ€ Test family, choisir: t tests\nÃ€ Statistical test, choisir: Means: Difference between two inde- pendent means (two groups)\nÃ€ Type of power analysis, choisir: Post hoc: Compute achieved power - given \\(\\alpha\\), sample size, and effect size\nDans Input Parameters,\n\n\nÃ  la boÃ®te Tail(s), choisir: Two,\nvÃ©rifier que \\(\\alpha\\) err prob est Ã©gal Ã  0.05\ninscrire 18 pour Sample size group 1 et 2\npour calculer la taille dâ€™effet (Effect size d), cliquer sur le bouton Determine =&gt;\n\n\n\nDans la fenÃªtre qui sâ€™ouvre Ã  droite, sÃ©lectionner n1 = n2\n\n\n\nentrer les moyennes (Mean group 1 et 2)\nentrer les Ã©carts types (SDs group 1 et 2)\ncliquer sur le bouton Calculate and transfer to main window\n\n\n\nCliquer sur le bouton Calculate dans la fenÃªtre principale et vous devriez obtenir ceci:\n\n\n\n\n\nAnalyse post-hoc avec la taille dâ€™effet estimÃ©e\n\n\n\nLa mÃªme analyse peut Ãªtre faites en utlisant R. Pour lâ€™analyse avec R, il faut dÃ©finir dâ€™abord calculer la taille dâ€™effet d pour un test de t comparant deux moyennes, puis utiliser la fonction pwr.t.test de lâ€™extension pwr. Le plus simple comme nous allons estimer la taille dâ€™effet d plusieurs fois et de crÃ©er une petite fonction qui estime d basÃ© sur les paramÃ¨tres nÃ©cessaires.\n\n# charger l'extension pwr\nlibrary(pwr)\n# dÃ©finir une fonction pour d\nd &lt;- function(u1, u2, sd1, sd2) {\n  abs(u1 - u2) / sqrt((sd1^2 + sd2^2) / 2)\n}\n\n# analyse de puissance\npwr.t.test(n = 18, d = d(u1 = 2.64, sd1 = 3.28, u2 = 3.31, sd2 = 2.79), sig.level = 0.05, type = \"two.sample\")\n\n\n     Two-sample t test power calculation \n\n              n = 18\n              d = 0.220042\n      sig.level = 0.05\n          power = 0.09833902\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n# graphique comme g*Power\nx &lt;- seq(-4, 4, length = 200)\nplot(x, dnorm(x), type = \"l\", col = \"red\", lwd = 2)\nqc &lt;- qt(0.025, 16)\nabline(v = qc, col = \"green\")\nabline(v = -qc, col = \"green\")\nlines(x, dnorm(x, mean = (3.31 - 2.64)), type = \"l\", col = \"blue\", lwd = 2)\n\n# power corresponds to the shaded area\ny &lt;- dnorm(x, mean = (3.31 - 2.64))\npolygon(c(x[x &lt;= -qc], -qc), c(y[x &lt;= -qc], 0), col = rgb(red = 0, green = 0.2, blue = 1, alpha = 0.5))\n\n\n\nGraphique de lâ€™analyse de puissance dans R\n\n\n\nÃ‰tudions un peu la figure @ref(fig:gpower-1).\n\nLa courbe de gauche, en rouge, correspond Ã  la distribution de la statistique t si \\(H_0\\) est vraie (i.e si les deux moyennes Ã©taient Ã©gales) compte tenu de lâ€™effectif (18 dans chaque rÃ©gion) et des Ã©carts- types observÃ©s.\nLes lignes verticales vertes correspondent aux valeurs critiques de t pour une valeur \\(\\alpha = 0.05\\) et un effectif total de 36 (2x18).\nLes rÃ©gions ombrÃ©es en rose correspondent aux zones de rejet de \\(H_0\\). Si Jaynie avait obtenu une valeur de t en dehors de lâ€™intervalle dÃ©limitÃ© par les valeurs critiques allant de -2.03224 Ã  2.03224, alors elle aurait rejetÃ© \\(H_0\\), lâ€™hypothÃ¨se nulle dâ€™Ã©galitÃ© des deux moyennes. En fait, elle a obtenu une valeur de t Ã©gale Ã  -0.5746 et conclu que la biomasse est la mÃªme dans les deux rÃ©gions.\nLa courbe de droite, en bleu, correspond Ã  la distribution de la sta- tistique t si \\(H_1\\) est vraie (ici \\(H_1\\) correspond Ã  une diffÃ©rence de biomasse entre les deux rÃ©gions de \\(3.33-2.64=0.69g/m^2\\), compte tenu des Ã©carts-types observÃ©s). Cette distribution correspond Ã  ce quâ€™on devrait sâ€™attendre Ã  observer si \\(H_1\\) Ã©tait vraie et que lâ€™on rÃ©pÃ©tait un grand nombre de fois les mesures dans des Ã©chantillons alÃ©atoires de 18 ruisseaux des deux rÃ©gions en calculant la statistique t Ã  chaque fois. En moyenne, on observerait une valeur de t dâ€™environ 0.6.\nNotez que la distribution de droite chevauche considÃ©rablement celle de gauche, et une bonne partie de la surface sous la courbe de droite se retrouve Ã  lâ€™intÃ©rieur de lâ€™intervalle dâ€™acceptation de \\(H_0\\), dÃ©limitÃ© par les deux lignes vertes et allant de -2.03224 Ã  2.03224. Cette proportion, correspondant Ã  la partie ombrÃ©e en bleu sous la courbe de droite et dÃ©notÃ© par \\(\\beta\\) correspond au risque dâ€™erreur de type II qui est dâ€™accepter \\(H_0\\) quand \\(H_1\\) est vraie.\nLa puissance est simplement \\(1-\\beta\\), et est ici de 0.098339. Donc, si la biomasse diffÃ©rait de 0.69\\(g/m^2\\) entre les deux rÃ©gions, Jaynie nâ€™avait que 9.8% des chances dâ€™Ãªtre capable de dÃ©tecter une diffÃ©rence statistiquement significative Ã  \\(\\alpha=5%\\) en Ã©chantillonnant 18 ruisseaux de chaque rÃ©gion.\n\nRÃ©capitulons: La diffÃ©rence de biomasse entre les deux rÃ©gions nâ€™est pas statistiquement significative dâ€™aprÃ¨s le test de t. Câ€™est donc que cette diffÃ©rence est relativement petite compte tenu de la prÃ©cision des mesures. Il nâ€™est donc pas trÃ¨s surprenant que la puissance, i.e.Â la probabilitÃ© de dÃ©tecter une diffÃ©rence significative, soit faible. Toute cette analyse ne nous informe pas beaucoup.\nUne analyse de puissance post hoc avec la taille de lâ€™effet observÃ© nâ€™est pas trÃ¨s utile. On la fera plutÃ´t pour une taille dâ€™effet autre que celle observÃ©e quand H 0 est acceptÃ©e. Quelle taille dâ€™effet utiliser? Câ€™est la biologie du systÃ¨me Ã©tudiÃ© qui peut nous guider. Par exemple, en ce qui concerne la biomasse des poissons, on pourrait sâ€™attendre Ã  ce quâ€™une diffÃ©rence de biomasse du simple au double (disons de 2.64 Ã  5.28 \\(g/m^2\\)) ait des consÃ©quences Ã©cologiques. On voudrait sâ€™assurer que Jaynie avait de bonnes chances de dÃ©tecter une diffÃ©rence aussi grande que celle-lÃ  avant dâ€™accepter ses conclusions que la biomasse est la mÃªme entre les deux rÃ©gions. Quelles Ã©taient les chances de Jaynie de dÃ©tecter une diffÃ©rence de 2.64 \\(g/m^2\\) entre les deux rÃ©gions? G*Power peut nous le dire.\n\n\n\n\n\n\nExercice\n\n\n\nChanger la moyenne du groupe 2 Ã  5.28, recalculer la taille dâ€™effet, et cliquer sur Calculate pour obtenir (@ref(fig:gpower-2)).\n\n\n\n\n\n\nAnalyse post-hoc avec une taille dâ€™effet diffÃ©rente\n\n\n\n\npwr.t.test(n = 18, d = d(u1 = 2.64, sd1 = 3.28, u2 = 5.28, sd2 = 2.79), sig.level = 0.05, type = \"two.sample\")\n\n\n     Two-sample t test power calculation \n\n              n = 18\n              d = 0.8670313\n      sig.level = 0.05\n          power = 0.7146763\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nLa puissance est de 0.71, donc Jaynie avait une chance raisonnable de dÃ©tecter une diffÃ©rence du simple au double avec 18 ruisseaux dans chaque rÃ©gion.\nNotez que cette analyse de puissance post hoc pour une taille dâ€™effet jugÃ©e biologiquement significative est bien plus informative que lâ€™analyse prÃ©cÃ©dente pour la taille dâ€™effet observÃ©e (qui est celle effectuÃ©e par dÃ©faut par bien des nÃ©ophytes et de trop nombreux logiciels qui essaient de penser pour nous). En effet, Jaynie nâ€™a pu dÃ©tecter de diffÃ©rences significatives entre les deux rÃ©gions. Cela pourrait Ãªtre pour deux raisons: soit quâ€™il nâ€™y a pas de diffÃ©rences entre les rÃ©gions, ou soit parce que la prÃ©cision des mesures est si faible et lâ€™effort dâ€™Ã©chantillonnage Ã©tait si limitÃ© quâ€™il Ã©tait trÃ¨s peu probable de dÃ©tecter mÃªme dâ€™Ã©normes diffÃ©rences. La deuxiÃ¨me analyse de puissance permet dâ€™Ã©liminer cette seconde possibilitÃ© puisque Jaynie avait 71% des chances de dÃ©tecter une diffÃ©rence du simple au double.\n\n3.4.2 Analyse Ã  priori\nSupposons quâ€™on puisse dÃ©fendre la position quâ€™une diffÃ©rence de biomasse observÃ©e par Jaynie entre les deux rÃ©gions, \\(3.31- 2.64=0.67g/m^2\\), soit Ã©cologiquement signifiante. On devrait donc planifier la prochaine saison dâ€™Ã©chantillonnage de maniÃ¨re Ã  avoir de bonnes chances de dÃ©tecter une diffÃ©rence de cette taille. Combien de ruisseaux Jaynie devrait-elle Ã©chantillonner pour avoir 80% des chances de la dÃ©tecter (compte tenu de la variabilitÃ© observÃ©e)?\n\n\n\n\n\n\nExercice\n\n\n\nChanger le type dâ€™analyse de puissance dans G*Power Ã  A priori: Compute sample size - given \\(\\alpha\\), power, and effect size. Assurez-vous que les valeurs pour les moyennes et les Ã©carts-type soient celles quâ€™a obtenu Jaynie, recalculez la taille de lâ€™effet, et inscrivez 0.8 pour la puissance.\n\n\n\n\n\n\nAnalyse Ã  priori\n\n\n\n\npwr.t.test(power = 0.8, d = d(u1 = 2.64, sd1 = 3.28, u2 = 3.31, sd2 = 2.79), sig.level = 0.05, type = \"two.sample\")\n\n\n     Two-sample t test power calculation \n\n              n = 325.1723\n              d = 0.220042\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nOuch! Il faudrait Ã©chantillonner 326 ruisseaux dans chaque rÃ©gion! Cela coÃ»terait une fortune et exigerait de nombreuses Ã©quipes de travail. Sans cela, on ne pourrait Ã©chantillonner que quelques dizaines de ruisseaux, et il serait peu probable que lâ€™on puisse dÃ©tecter une si faible diffÃ©rence de biomasse entre les deux rÃ©gions. Ce serait vraisemblablement en vain et pourrait Ãªtre considÃ©rÃ© comme une perte de temps: pourquoi tant dâ€™efforts et de dÃ©penses si les chances de succÃ¨s sont si faibles.\nSi on refait le mÃªme calcul pour une puissance de 95%, on obtient 538 ruisseaux par rÃ©gion. Augmenter la puissance Ã§a demande plus dâ€™effort.\n\npwr.t.test(power = 0.95, d = d(u1 = 2.64, sd1 = 3.28, u2 = 3.31, sd2 = 2.79), sig.level = 0.05, type = \"two.sample\")\n\n\n     Two-sample t test power calculation \n\n              n = 537.7286\n              d = 0.220042\n      sig.level = 0.05\n          power = 0.95\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\n\n3.4.3 Analyse de sensitivitÃ© - Calculer la taille dâ€™effet dÃ©tectable\nCompte tenu de la variabilitÃ© observÃ©e, dâ€™un effort dâ€™Ã©chantillonnage de 18 ruisseaux par rÃ©gion, et en conservant \\(\\alpha=0.05\\), quelle est la taille dâ€™effet que Jaynie pouvait dÃ©tecter avec 80% de chances \\(\\beta=0.2\\))?\n\n\n\n\n\n\nExercice\n\n\n\nChangez le type dâ€™analyse dans G*Power Ã  Sensitivity: Compute required effect size - given \\(\\alpha\\), power, and sample size et assurez-vous que la taille des Ã©chantillons est de 18 dans chaque rÃ©gion.\n\n\n\n\n\n\nAnalyse de sensitivitÃ©\n\n\n\n\npwr.t.test(power = 0.8, n = 18, sig.level = 0.05, type = \"two.sample\")\n\n\n     Two-sample t test power calculation \n\n              n = 18\n              d = 0.9612854\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nLa taille dâ€™effet dÃ©tectable pour cette taille dâ€™Ã©chantillon, \\(\\alpha=0.05\\) et \\(\\beta=0.2\\) (ou une puissance de 80%) est de 0.961296.\n\n\n\n\n\n\nAvertissement\n\n\n\ncette valeur est lâ€™indice d de la taille de lâ€™effet et est pondÃ©rÃ©e par la variabilitÃ© des mesures.\n\n\nDans ce cas ci, d est approximativement Ã©gal Ã  \\[ d = \\frac{| \\bar{X_1} \\bar{X_2} |} {\\sqrt{\\frac{{s_1}^2 +{s_2}^2}{2}}}\\] Pour convertir cette valeur de d sans unitÃ©s en une valeur de diffÃ©rence de biomasse dÃ©tectable (i.e \\(| \\bar{X_1} \\bar{X_2} |\\)), il suffit de multiplier d par le dÃ©nominateur de lâ€™Ã©quation. \\[\n| \\bar{X_1} \\bar{X_2} | = d * \\sqrt{\\frac{{s_1}^2 +{s_2}^2}{2}}\n\\] Dans R, on peut estimer cela avec:\n\npwr.t.test(power = 0.8, n = 18, sig.level = 0.05, type = \"two.sample\")$d * sqrt((3.28^2 + 2.79^2) / 2)\n\n[1] 2.926992\n\n\nDonc, avec 18 ruisseaux dans chaque rÃ©gion, pour \\(\\alpha=0.05\\) et \\(\\beta=0.2\\) (une puissance de 80%), Jaynie pouvait dÃ©tecter une diffÃ©rence de biomasse de 2.93\\(g/m^2\\) entre les rÃ©gions, un peu plus que du simple au double.",
    "crumbs": [
      "DonnÃ©es",
      "Fundamentals of stats",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Analyse de puissance avec R et G\\*Power</span>"
    ]
  },
  {
    "objectID": "25-power.html#points-Ã -retenir",
    "href": "25-power.html#points-Ã -retenir",
    "title": "\n3Â  Analyse de puissance avec R et G*Power\n",
    "section": "\n3.5 Points Ã  retenir",
    "text": "3.5 Points Ã  retenir\n\nLâ€™analyse de puissance post hoc nâ€™est pertinente que lorsque lâ€™on a acceptÃ© lâ€™hypothÃ¨se nulle. Il est en effet impossible de faire une erreur de type II quand on rejette \\(H_0\\).\nAvec de trÃ¨s grands Ã©chantillons, on a une puissance quasi infinie et on peut dÃ©tecter statistiquement de trÃ¨s petites diffÃ©rences qui ne sont pas nÃ©cessairement biologiquement significatives.\nEn utilisant un critÃ¨re de signification plus strict (\\(\\alpha\\)&lt;0.05) on diminue notre puissance.\nEn voulant maximiser la puissance, on augmente lâ€™effort requis, Ã  moins dâ€™utiliser une valeur critique plus libÃ©rale (\\(\\alpha&gt;0.05\\))\nLe choix de \\(\\beta\\) est quelque peu arbitraire. On considÃ¨re que \\(\\beta=0.2\\) (puissance de 80%) est relativement Ã©levÃ©.",
    "crumbs": [
      "DonnÃ©es",
      "Fundamentals of stats",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Analyse de puissance avec R et G\\*Power</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html",
    "href": "31-reg_lin.html",
    "title": "\n4Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "",
    "text": "4.1 Extensions R et donnÃ©es requises pour le labo\nCe laboratoire nÃ©cessite:\nIl ne faut pas oublier de charge les extensions avec library() et de les installer au besoin avec install.packages() Pour les donnÃ©es, il faut les lire et les assigner Ã  un objet R.\nlibrary(car)\nlibrary(lmtest)\nlibrary(boot)\nlibrary(ggplot2)\nlibrary(pwr)\nlibrary(performance)\n\nsturgeon &lt;- read.csv(\"data/sturgeon.csv\")",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#set-lm",
    "href": "31-reg_lin.html#set-lm",
    "title": "\n4Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "",
    "text": "les paquets R:\n\ncar\nlmtest\nboot\npwr\nggplot\n\n\nles fichiers de donnÃ©es\n\nsturgeon.csv\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotez que la ligne de code pour lire les donnÃ©es considÃ¨re que le fichier de donnÃ©es se trouve dans un dossier data au sein de votre rÃ©pertoire de travail. Si ce nâ€™est pas le cas veuillez ajuster la ligne de commande.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#diagrammes-de-dispersion",
    "href": "31-reg_lin.html#diagrammes-de-dispersion",
    "title": "\n4Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n4.2 Diagrammes de dispersion",
    "text": "4.2 Diagrammes de dispersion\nLes analyses de corrÃ©lation et de rÃ©gression devraient toujours commencer par un examen des donnÃ©es.Câ€™est une Ã©tape critique qui sert Ã  Ã©valuer si ce type dâ€™analyse est appropriÃ© pour un ensemble de donnÃ©es. Supposons que nous sommes intÃ©ressÃ©s Ã  Ã©valuer si la longueur dâ€™esturgeons mÃ¢les dans la rÃ©gion de The Pas covarie avec leur poids. Pour rÃ©pondre Ã  cette question, regardons dâ€™abord la corrÃ©lation entre la longueur et le poids. Souvenez-vous quâ€™une des conditions dâ€™application de lâ€™analyse de corrÃ©lation est que la relation entre les deux variables est linÃ©aire. Pour Ã©valuer cela, commenÃ§ons par faire un diagramme de dispersion.\n\nLes donnÃ©es sur les esturgeons son disponibles dans le fichier sturgeon.csv. AprÃ¨s avoir chargÃ© les donnÃ©es dnas un objet sturgeon, faites un diagramme de dispersion avec une droite de rÃ©gression et une courbe LOWESS de la longueur en fonction du poids.\n\n\nsturgeon &lt;- read.csv(\"data/sturgeon.csv\")\nstr(sturgeon)\n\n'data.frame':   186 obs. of  9 variables:\n $ fklngth : num  37 50.2 28.9 50.2 45.6 ...\n $ totlngth: num  40.7 54.1 31.3 53.1 49.5 ...\n $ drlngth : num  23.6 31.5 17.3 32.3 32.1 ...\n $ rdwght  : num  15.95 NA 6.49 NA 29.92 ...\n $ age     : int  11 24 7 23 20 23 20 7 23 19 ...\n $ girth   : num  40.5 53.5 31 52.5 50 54.2 48 28.5 44 39 ...\n $ sex     : chr  \"MALE\" \"FEMALE\" \"MALE\" \"FEMALE\" ...\n $ location: chr  \"THE_PAS\" \"THE_PAS\" \"THE_PAS\" \"THE_PAS\" ...\n $ year    : int  1978 1978 1978 1978 1978 1978 1978 1978 1978 1978 ...\n\n\n\nmygraph &lt;- ggplot(\n  data = sturgeon[!is.na(sturgeon$rdwght), ], # source of data\n  aes(x = fklngth, y = rdwght)\n)\n# plot data points, regression, loess trace\nmygraph &lt;- mygraph +\n  stat_smooth(method = lm, se = FALSE, color = \"green\") + # add linear regression, but no SE shading\n  stat_smooth(color = \"red\", se = FALSE) + # add loess\n  geom_point() # add data points\n\nmygraph # display graph\n\n\n\nGraphique du poids en fonction de la longueur des esturgeons\n\n\n\n\n\nEst-ce que la dispersion des points suggÃ¨re une bonne corrÃ©lation entre les deux variables? Est-ce que la relation semble linÃ©aire?\n\nCe graphique suggÃ¨re une tendance plus curvilinÃ©aire que linÃ©aire. MalgrÃ© tout, il semble y avoir une forte corrÃ©lation entre les deux variables.\n\nRefaites le diagramme de dispersion avec des axes logarithmiques.\n\n\n# apply log transformation on defined graph\nmygraph + scale_x_log10() + scale_y_log10()\n\n\n\nGraphique poids-longueur avec une Ã©chelle log\n\n\n\nComparez les diagrammes de dispersion avant et aprÃ¨s transformation (Figures @ref(fig:stur-2) et @ref(fig:stur-log)). Comme lâ€™analyse de corrÃ©lation prÃ©suppose une relation linÃ©aire entre les variables, on devrait donc privilÃ©gier lâ€™analyse sur les donnÃ©es log-transformÃ©es.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#transformations-et-le-coefficient-de-corrÃ©lation",
    "href": "31-reg_lin.html#transformations-et-le-coefficient-de-corrÃ©lation",
    "title": "\n4Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n4.3 Transformations et le coefficient de corrÃ©lation",
    "text": "4.3 Transformations et le coefficient de corrÃ©lation\nUne autre condition prÃ©alable Ã  lâ€™analyse de corrÃ©lation est que les deux variables concernÃ©es suivent une distribution normale bidimensionnelle. On peut aisÃ©ment vÃ©rifier la normalitÃ© de chacune des 2 variables sÃ©parÃ©ment tel que dÃ©crit dans le laboratoire prÃ©cÃ©dent. Si les deux variables sont normalement distribuÃ©es, on prÃ©sume gÃ©nÃ©ralement quâ€™elles suivent une distribution normale bidimensionnelle lorsquâ€™analysÃ©es simultanÃ©ment (notez que ce nâ€™est pas toujours le cas cependant).\n\nExaminez la distribution des quatre variables (les deux variables originales et les variables transformÃ©es). Que concluez-vous de lâ€™inspection visuelle de ces graphiques ?\n\nLes figures ci-dessous sont les diagrammes de probabilitÃ© (qqplot()). Le code pour produire des graphiques multiples sur une page, comme on voit ci-dessous, est:\n\npar(mfrow = c(2, 2)) # divise le graphique en 4 sections\nqqnorm(sturgeon$fklngth, ylab = \"fklngth\")\nqqline(sturgeon$fklngth)\nqqnorm(log10(sturgeon$fklngth), ylab = \"log10(fklngth)\")\nqqline(log10(sturgeon$fklngth))\nqqnorm(sturgeon$rdwght, ylab = \"rdwght\")\nqqline(sturgeon$rdwght)\nqqnorm(log10(sturgeon$rdwght), ylab = \"log10(rdwgth)\")\nqqline(log10(sturgeon$rdwght))\n\n\n\n\n\n\npar(mfrow = c(1, 1)) # redÃ©finie la zone de graphique par dÃ©faut\n\nIl nâ€™y a pas grand-chose Ã  redire: aucune des distributions nâ€™est parfaitement normale, mais les dÃ©viations semblent mineures.\n\nGÃ©nÃ©rez une matrice de graphiques de dispersion amÃ©liorÃ©s en utilisant la commande scatterplotMatrix de la librairie car.\n\n\nscatterplotMatrix(\n  ~ fklngth + log10(fklngth) + rdwght + log10(rdwght),\n  data = sturgeon,\n  smooth = TRUE, diagonal = \"density\"\n)\n\nWarning in applyDefaults(diagonal, defaults = list(method = \"adaptiveDensity\"),\n: unnamed diag arguments, will be ignored\n\n\n\n\n\n\n\n\n\nEnsuite, calculez le coefficient de corrÃ©lation de Pearson entre chaque paire (variables originales et logtransformÃ©es) en utilisant la commande cor(). Avant de commencer, on va cependant ajouter les variables transformÃ©es au tableau de donnÃ©es sturgeon:\n\n\nsturgeon$lfklngth &lt;- with(sturgeon, log10(fklngth))\nsturgeon$lrdwght &lt;- log10(sturgeon$rdwght)\n\nVous pouvez ensuite obtenir la matrice de corrÃ©lation par:\n\ncor(sturgeon[, c(\"fklngth\", \"lfklngth\", \"lrdwght\", \"rdwght\")], use = \"complete.obs\")\n\nFrÃ©quemment, il y a des donnÃ©es manquantes dans un Ã©chantillon. En choisissant use=\"complete.obs\", toutes les lignes du fichier pour lesquelles les variables ne sont pas toutes mesurÃ©es sont Ã©liminÃ©es. Dans ce cas, toutes les corrÃ©lations seront calculÃ©es avec le mÃªme nombre de cas. Par contre, en utilisant use=\"pairwise.complete.obs\", R Ã©limine une observation que lorsquâ€™un des deux membres de la paire a une valeur manquante. Dans ce cas, si les donnÃ©es manquantes pour diffÃ©rentes variables se retrouvent dans un groupe diffÃ©rent dâ€™observation, les corrÃ©lations ne seront pas nÃ©cessairement calculÃ©es sur le mÃªme nombre de cas ni sur le mÃªme sous-ensemble de cas. En gÃ©nÃ©ral, vous devriez utiliser lâ€™option use=\"complete.obs\" Ã  moins que vous ayez un trÃ¨s grand nombre de donnÃ©es manquantes et que cette faÃ§on de procÃ©der Ã©limine la plus grande partie de vos observations.\nPourquoi la corrÃ©lation entre les variables originales est-elle la plus faible des trois ?\n\ncor(sturgeon[, c(\"fklngth\", \"lfklngth\", \"lrdwght\", \"rdwght\")], use = \"complete.obs\")\n\n           fklngth  lfklngth   lrdwght    rdwght\nfklngth  1.0000000 0.9921435 0.9645108 0.9175435\nlfklngth 0.9921435 1.0000000 0.9670139 0.8756203\nlrdwght  0.9645108 0.9670139 1.0000000 0.9265513\nrdwght   0.9175435 0.8756203 0.9265513 1.0000000\n\n\nIl y a plusieurs choses Ã  noter ici.\n\nPremiÃ¨rement, la corrÃ©lation entre la longueur Ã  la fourche et le poids rond est Ã©levÃ©e, peu importe la transformation: les poissons lourds ont tendance Ã  Ãªtre longs.\nDeuxiÃ¨mement, la corrÃ©lation est plus forte pour les donnÃ©es transformÃ©es que pour les donnÃ©es brutes.\n\nPourquoi? Parce que le coefficient de corrÃ©lation est inversement proportionnel au bruit autour de la relation linÃ©aire. Si la relation est curvilinÃ©aire (comme dans le cas des donnÃ©es non transformÃ©es), le bruit est plus grand que si la relation est parfaitement linÃ©aire. Par consÃ©quent, la corrÃ©lation est plus faible.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#matrices-de-corrÃ©lations-et-correction-de-bonferroni",
    "href": "31-reg_lin.html#matrices-de-corrÃ©lations-et-correction-de-bonferroni",
    "title": "\n4Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n4.4 Matrices de corrÃ©lations et correction de Bonferroni",
    "text": "4.4 Matrices de corrÃ©lations et correction de Bonferroni\nUne pratique courante est dâ€™examiner une matrice de corrÃ©lation Ã  la recherche des associations significatives. Comme exemple, essayons de tester si la corrÃ©lation entre lfklngth et rdwght est significative (câ€™est le plus faible coefficient de corrÃ©lation de cette matrice).\n\nEstimer la correlation entre la longueur (fklngth) et le poids (rdwght) des esturgeons:\n\n\ncor.test(\n  sturgeon$lfklngth, sturgeon$rdwght,\n  alternative = \"two.sided\",\n  method = \"pearson\"\n)\n\n\n    Pearson's product-moment correlation\n\ndata:  sturgeon$lfklngth and sturgeon$rdwght\nt = 24.322, df = 180, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8367345 0.9057199\nsample estimates:\n      cor \n0.8756203 \n\n\nOn voit ici que la corrÃ©lation est hautement significative (\\(p &lt; 2.2e-16\\)),ce qui nâ€™est pas surprenant Ã©tant donnÃ© la valeur du coefficient de corrÃ©lation (0.8756). Il est important de rÃ©aliser que si une matrice contient un grand nombre de corrÃ©lations, il nâ€™est pas surprenant dâ€™en trouver au moins une qui soit â€œsignificativeâ€. En effet, on sâ€™attend Ã  en trouver 5% en moyenne lorsquâ€™il nâ€™y a en fait aucune corrÃ©lation entre les paires de moyennes. Une faÃ§on de corriger pour cette tendance est dâ€™ajuster le niveau \\(\\alpha\\) critique auquel on attribue une signification statistique en divisant \\(\\alpha\\) par le nombre \\(k\\) de corrÃ©lations qui sont examinÃ©es : \\(\\alpha' =\n\\alpha / k\\) (ajustement de Bonferroni). Si initialement \\(\\alpha = 0.05\\) et quâ€™il y a 10 corrÃ©lations qui sont examinÃ©es, alors \\(\\alpha'= 0.005\\). Donc, afin de rejeter lâ€™hypothÃ¨se nulle, la valeur de p devra Ãªtre plus petite que \\(\\alpha'\\), en lâ€™occurrence 0.005. Dans lâ€™exemple qui prÃ©cÃ¨de, on devrait donc ajuster \\(\\alpha\\) critique en divisant par le nombre total de corrÃ©lations dans la matrice (6 dans ce cas, donc \\(\\alpha'=0.00833\\)). Cette correction modifie-t-elle votre conclusion quant Ã  la corrÃ©lation entre lkfl et rdwght?",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#corrÃ©lations-non-paramÃ©triques-r-de-spearman-et-tau-de-kendall",
    "href": "31-reg_lin.html#corrÃ©lations-non-paramÃ©triques-r-de-spearman-et-tau-de-kendall",
    "title": "\n4Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n4.5 CorrÃ©lations non paramÃ©triques: r de Spearman et \\(\\tau\\) de Kendall",
    "text": "4.5 CorrÃ©lations non paramÃ©triques: r de Spearman et \\(\\tau\\) de Kendall\nLâ€™analyse faite Ã  la section prÃ©cÃ©dente avec les esturgeons suggÃ¨re que lâ€™une des conditions prÃ©alables Ã  lâ€™analyse de corrÃ©lation, soit la distribution normale bidimensionnelle de donnÃ©es, pourrait ne pas Ãªtre remplie pour fklngth et rdwght, ni pour les paires de variables transformÃ©es. La recherche dâ€™une transformation appropriÃ©e peut parfois Ãªtre difficile. Pire encore, pour certaines distributions il nâ€™existe pas de transformation qui va normaliser les donnÃ©es. Dans ces cas-lÃ , la meilleure option est de faire une analyse non paramÃ©trique qui ne prÃ©sume ni de la normalitÃ© ni de la linÃ©aritÃ©. Ces analyses sont basÃ©es sur les rangs. Les deux plus communes sont le coefficient de rang de Spearman et le \\(\\tau\\) (tau) de Kendall.\n\nDans R, testez la corrÃ©lation entre fklngth et rdwght en utilisant Spearman et Kendallâ€™s .\n\n\ncor.test(\n  sturgeon$lfklngth, sturgeon$rdwght,\n  alternative = \"two.sided\",\n  method = \"spearman\"\n)\n\nWarning in cor.test.default(sturgeon$lfklngth, sturgeon$rdwght, alternative =\n\"two.sided\", : Cannot compute exact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  sturgeon$lfklngth and sturgeon$rdwght\nS = 47971, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.9522546 \n\n\n\ncor.test(\n  sturgeon$lfklngth, sturgeon$rdwght,\n  alternative = \"two.sided\",\n  method = \"kendall\"\n)\n\n\n    Kendall's rank correlation tau\n\ndata:  sturgeon$lfklngth and sturgeon$rdwght\nz = 16.358, p-value &lt; 2.2e-16\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.8208065 \n\n\nComparer les rÃ©sultats de cette analyse Ã  lâ€™analyse paramÃ©trique. Pourquoi y-a-tâ€™il une diffÃ©rence ?\nCalculez les corrÃ©lations non paramÃ©triques sur les paires de variables transformÃ©es. Vous devriez voir tout de suite que les corrÃ©lations des donnÃ©es transformÃ©es et non transformÃ©es sont identiques puisque dans les deux cas la corrÃ©lation est calculÃ©e Ã  partir des rangs qui ne sont pas affectÃ©s par la transformation.\nNotez que les corrÃ©lations obtenues avec le tau de Kendall (0.820) sont plus faibles que celles du coefficient de Spearman (0.952). Le tau de Kendall pondÃ¨re un peu plus les grandes diffÃ©rences entre les rangs alors que le coefficient de Spearman donne le mÃªme poids Ã  chaque paire dâ€™observations. En gÃ©nÃ©ral, on prÃ©fÃ¨re le tau de Kendall lorsquâ€™il y a plus dâ€™incertitude quant aux rangs qui sont prÃ¨s les uns des autres.\nLes esturgeons de cet Ã©chantillon ont Ã©tÃ© capturÃ©s Ã  lâ€™aide de filets et dâ€™hameÃ§ons dâ€™une taille fixe. Quel impact cette mÃ©thode de capture peut-elle avoir eu sur la forme de la distribution de fklngth et rdwght? Compte tenu de ces circonstances, lâ€™analyse de corrÃ©lation est-elle appropriÃ©e ?\nRappelez-vous que lâ€™analyse de corrÃ©lation prÃ©sume aussi que chaque variable est Ã©chantillonnÃ©e alÃ©atoirement. Dans le cas de nos esturgeons, ce nâ€™est pas le cas: les hameÃ§ons appÃ¢tÃ©s et les filets ne capturent pas de petits esturgeons (et câ€™est pourquoi il nâ€™y en a pas dans lâ€™Ã©chantillon). Il faut donc rÃ©aliser que les coefficients de corrÃ©lation obtenus dans cette analyse ne reflÃ¨tent pas nÃ©cessairement ceux de la population totale des esturgeons.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#rÃ©gression-linÃ©aire-simple",
    "href": "31-reg_lin.html#rÃ©gression-linÃ©aire-simple",
    "title": "\n4Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n4.6 RÃ©gression linÃ©aire simple",
    "text": "4.6 RÃ©gression linÃ©aire simple\nLâ€™analyse de corrÃ©lation vise Ã  dÃ©crire comment deux variables covarient. Lâ€™analyse de rÃ©gression vise plutÃ´t Ã  produire un modÃ¨le permettant de prÃ©dire une variable (la variable dÃ©pendante) par lâ€™autre (la variable indÃ©pendante).\nComme pour lâ€™analyse de corrÃ©lation, on devrait commencer en examinant des graphiques. Puisque lâ€™on est intÃ©ressÃ© Ã  quantifier la relation entre deux variables, un graphique de la variable dÃ©pendante (Y) en fonction de la variable indÃ©pendante (X) est tout Ã  fait appropriÃ©.\n\nLe fichier sturgeon.csv contient des donnÃ©es dâ€™un inventaire des esturgeons rÃ©coltÃ©s en 1978-1980 Ã  Cumberland House en Saskatchewan et Ã  The Pas au Manitoba. Faites un diagramme de dispersion de fklngth (la variable dÃ©pendante) en fonction de age (la variable indÃ©pendante) pour les esturgeons mÃ¢les unqiuement et ajoutez-y une rÃ©gression linÃ©aire et une trace lowess. Que concluez-vous de ce diagramme de dispersion ?\n\n\nsturgeon.male &lt;- subset(sturgeon, subset = sex == \"MALE\")\nmygraph &lt;- ggplot(\n  data = sturgeon.male, # source of data\n  aes(x = age, y = fklngth)\n) # aesthetics: y=fklngth, x=rdwght\n# plot data points, regression, loess trace\nmygraph &lt;- mygraph +\n  stat_smooth(method = lm, se = FALSE, color = \"green\") + # add linear regression, but no SE shading\n  stat_smooth(color = \"red\") + # add loess\n  geom_point() # add data points\nmygraph # display graph\n\n\n\n\n\n\n\nCe graphique suggÃ¨re que la relation nâ€™est pas linÃ©aire.\nSupposons que nous dÃ©sirions estimer le taux de croissance des esturgeons mÃ¢les. Un estimÃ© (peut-Ãªtre pas terribleâ€¦) du taux de croissance peut Ãªtre obtenu en calculant la pente de la rÃ©gression de la longueur Ã  la fourche sur lâ€™Ã¢ge.\nAjustons dâ€™abord une rÃ©gression avec la commande lm() et sauvons ces rÃ©sultats dans un objet appelÃ© RegModel.1.\n\nRegModel.1 &lt;- lm(fklngth ~ age, data = sturgeon.male)\n\nRien nâ€™apparait Ã  lâ€™Ã©cran, câ€™est normal ne vous inquiÃ©tez pas, tout a Ã©tÃ© sauvegardÃ© en mÃ©moire. Pour voir les rÃ©sultats, tapez:\n\nsummary(RegModel.1)\n\n\nCall:\nlm(formula = fklngth ~ age, data = sturgeon.male)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.4936 -2.2263  0.1849  1.7526 10.8234 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 28.50359    1.16873   24.39   &lt;2e-16 ***\nage          0.70724    0.05888   12.01   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.307 on 73 degrees of freedom\n  (5 observations deleted due to missingness)\nMultiple R-squared:  0.664, Adjusted R-squared:  0.6594 \nF-statistic: 144.3 on 1 and 73 DF,  p-value: &lt; 2.2e-16\n\n\nla sortie R donne:\n\n\nCall: Le modÃ¨le qui a Ã©tÃ© ajustÃ© et les donnÃ©es utilisÃ©es.\n\nResiduals: Un sommaire statistique des rÃ©sidus autour du modÃ¨le estimÃ©.\n\nCoefficients: Valeurs estimÃ©es des paramÃ¨tres du modÃ¨le, erreurs-types, statistiques t et probabilitÃ©s associÃ©es.\n\nResidual standard error: Racine carrÃ©e de la variance rÃ©siduelle.\n\nMultiple R-squared: Coefficient de dÃ©termination. Il correspond Ã  la proportion de la variabilitÃ© de la variable dÃ©pendante qui peut Ãªtre expliquÃ©e par la rÃ©gression.\n\nAdjusted R-squared: Le R-carrÃ© ajustÃ© tient compte du nombre de paramÃ¨tres du modÃ¨le. Si vous voulez comparer diffÃ©rents modÃ¨les qui nâ€™ont pas le mÃªme nombre de paramÃ¨tres, câ€™est ce quâ€™il faut utiliser.\n\nF-statistic: Câ€™est le test de signification omnibus du modÃ¨le. Dans le cas de la rÃ©gression simple, il est Ã©quivalent au test sur la pente de la rÃ©gression.\n\nLa rÃ©gression estimÃ©e est donc:\n\\[ Fklngth = 28.50359 + 0.70724 * age\\]\nÃ‰tant donnÃ© la valeur significative du test de F ainsi que pour le test de t pour la pente de la droite, on rejette lâ€™hypothÃ¨se nulle quâ€™il nâ€™y a pas de relation entre la taille et lâ€™Ã¢ge.\n\n4.6.1 VÃ©rifier les conditions dâ€™application de la rÃ©gression\nLa rÃ©gression simple de type I a quatre conditions prÃ©alables :\n\nil nâ€™y a pas dâ€™erreur de mesure sur la variable indÃ©pendante (X)\nla relation entre Y et X est linÃ©aire\nles rÃ©sidus sont normalement distribuÃ©s\nla variance des rÃ©sidus est constante pour toutes les valeurs de la variable indÃ©pendante\n\nProcÃ©dons maintenant Ã  lâ€™examen post-mortem. La premiÃ¨re condition est rarement remplie avec des donnÃ©es biologiques ; il y presque toujours de lâ€™erreur sur X et sur Y. Cela veut dire quâ€™en gÃ©nÃ©ral les pentes estimÃ©es sont biaisÃ©es, mais que les valeurs prÃ©dites ne le sont pas. Toutefois, si lâ€™erreur de mesure sur X est petite par rapport Ã  lâ€™Ã©tendue des valeurs de X, le rÃ©sultat de lâ€™analyse nâ€™est pas dramatiquement influencÃ©. Par contre, si lâ€™erreur de mesure est relativement grande (toujours par rapport Ã  lâ€™Ã©tendue des valeurs de X), la droite de rÃ©gression obtenue par la rÃ©gression de modÃ¨le I est un piÃ¨tre estimÃ© de la relation fonctionnelle entre X et Y. Dans ce cas, il est prÃ©fÃ©rable de passer Ã  la rÃ©gression de modÃ¨le II, malheureusement au-delÃ  du contenu de ce cours. Les autres conditions prÃ©alables Ã  lâ€™analyse de rÃ©gression de modÃ¨le I peuvent cependant Ãªtre vÃ©rifiÃ©es, ou du moins Ã©valuÃ©es visuellement. La commande plot() permet de visualiser des graphiques diagnostiques pour des modÃ¨les linÃ©aires.\n\npar(mfrow = c(2, 2), las = 1)\nplot(RegModel.1)\n\nLa commande par() est utilisÃ©e pour dire Ã  R de tracer 2 rangÃ©es et 2 colonnes de graphiques par page (il y a quatre graphiques diagnostiques qui sont gÃ©nÃ©rÃ©s automatiquement pour les modÃ¨les linÃ©aires), et la commande las indique Ã  R dâ€™effectuer une rotation des lÃ©gendes de lâ€™axe des Y pour quâ€™elles soient perpendiculaires Ã  lâ€™axe (oui. Je sais. Rien de tout Ã§a nâ€™est Ã©vident.)\nVous obtiendrez:\n\n\n\n\n\n\n\n\n\nEn haut Ã  gauche, permet dâ€™Ã©valuer la linÃ©aritÃ©, la normalitÃ©, et lâ€™homoscÃ©dasticitÃ© des rÃ©sidus. Il illustre les dÃ©viations autour de la rÃ©gression en fonction des valeurs prÃ©dites. Rappllez-vous que le graphique de fklngth vs age suggÃ¨re que la relation entre la longueur Ã  la fourche et lâ€™Ã¢ge nâ€™est pas linÃ©aire. Les trÃ¨s jeunes et trÃ¨s vieux esturgeons sont sous la droite en gÃ©nÃ©ral, alors que les esturgeons dâ€™Ã¢ge moyen sont retrouvÃ©s gÃ©nÃ©ralement au-dessus de la droite de rÃ©gression. Câ€™est exactement ce que le graphique des rÃ©sidus en fonction des valeurs prÃ©dites illustre. La ligne en rouge est une trace lowess au travers de ce nuage de points. Si la relation Ã©tait linÃ©aire, la trace lowess serait presque plate et prÃ¨s de 0. La dispersion des rÃ©sidus permet dâ€™Ã©valuer visuellement leur normalitÃ© et hÃ©tÃ©roscÃ©dasticitÃ©; mais ce graphique nâ€™est pas optimal pour Ã©valuer ces propriÃ©tÃ©s. Les deux graphiques suivants sont supÃ©rieurs au premier pour cela.\nEn haut Ã  droite permet dâ€™Ã©valuer la normalitÃ© des rÃ©sidus. Câ€™est un graphique QQ des rÃ©sidus (QQ plot). Des rÃ©sidus distribuÃ©s normalement tomberaient exactement sur la diagonale. Ici, on voit que câ€™est presque le cas, sauf dans les queues de la distribution.\nEn bas Ã  gauche, intitulÃ© Scale-Location, permet dâ€™Ã©valuer lâ€™homoscedasticitÃ©. On y retrouve sur lâ€™ordonnÃ©e (lâ€™axe des y) la racine carrÃ©e de la valeur absolue des rÃ©sidus standardisÃ©s (rÃ©sidus divisÃ©s par lâ€™Ã©cart-type des rÃ©sidus) en fonction des valeurs prÃ©dites. Le graphique aide Ã  dÃ©terminer si la variation des rÃ©sidus est constante ou non. Si les rÃ©sidus sont homoscÃ©dastiques, la valeur moyenne sur lâ€™axe des y ne va pas changer en fonction de la valeur prÃ©dite. Ici, il y a une certaine tendance, mais pas une tendance monotone puisquâ€™ il y a dâ€™abord une baisse puis une hausse..; bref, rien qui soit une forte Ã©vidence contre la supposition dâ€™homoscÃ©dasticitÃ©.\nEn bas Ã  droite, montre les rÃ©sidus en fonction du â€œleverageâ€ et permet de dÃ©tecter certaines valeurs extrÃªmes qui ont une grande influence sur la rÃ©gression. Le leverage dâ€™un point mesure sa distance des autres points, mais seulement en ce qui concerne les variables indÃ©pendantes. Dans le cas dâ€™une rÃ©gression simple, cela revient Ã  la distance entre le point sur lâ€™axe des x et la moyenne de tous les points sur cet axe. Vous devriez porter une attention particuliÃ¨re aux observations qui ont un leverage plus grand que \\(2(k+1)/n\\), oÃ¹ k est le nombre de variables indÃ©pendantes (ici, 1) et n est le nombre dâ€™observations. Dans cet exemple, il y a 75 observations et une variable indÃ©pendante et donc les points ayant un leverage plus grand que \\(4 / 75 =  0.053\\) devrait Ãªtre considÃ©rÃ©s avec attention. Le graphique indique Ã©galement comment la rÃ©gression changerait si on enlevait un point. Ce changement est mesurÃ© par la distance de Cook, illustrÃ©e par les bandes en rouge sur le graphique. Un point ayant une distance de Cook supÃ©rieure Ã  1 a une grande influence.\n\n\n\n\n\n\n\nAvertissement\n\n\n\nNotez que R identifie automatiquement les cas les plus extrÃ¨mes sur chacun de ces 4 graphiques. Le fait quâ€™un point soit identifiÃ© ne signifie pas nÃ©cessairement que câ€™est une valeur rÃ©ellement extrÃ¨me, ou que vous devez vous en prÃ©occuper. Dans tous les ensembles de donnÃ©es il y aura toujours un rÃ©sidu plus grand que les autresâ€¦\n\n\nIl est possible dâ€™obtenir des graphiques dâ€™Ã©valutions des conditions dâ€™applications, qui sont plus simple Ã  interprÃ©ter et plus joli (avec des couleurs). Il faut utiliser la fonction model_check() dans le ğŸ“¦ performance.\n\ncheck_model(RegModel.1)\n\n\n\n\n\n\n\nFinalement, quel est le verdict concernant la rÃ©gression linÃ©aire entre fklngth et age ? Elle viole la condition de linÃ©aritÃ©, possiblement celle de normalitÃ©, remplit la condition dâ€™homoscÃ©dasticitÃ©, et ne semble pas influencÃ©e outre mesure par des valeurs bizarres ou extrÃªmes.\n\n4.6.2 Tests formels des conditions dâ€™application pour la rÃ©gression\nPersonnellement, je nâ€™utilise jamais les tests formels des conditions dâ€™application de la rÃ©gression et me contente des graphiques des rÃ©sidus pour guider mes dÃ©cisions. Câ€™est ce que la plupart des praticiens font. Cependant, lors de mes premiÃ¨res analyses, je nâ€™Ã©tais pas toujours certain de bien interprÃ©ter les graphiques et jâ€™aurais aimÃ© un indice plus formel ou un test permettant de dÃ©tecter les violations des conditions dâ€™application de la rÃ©gression.\nLe package lmtest, qui ne fait pas partie de lâ€™installation de base, mais qui est disponible sur CRAN, permet de faire plusieurs tests de linÃ©aritÃ© et dâ€™homoscÃ©dasticitÃ©. Et on peut tester la normalitÃ© avec le test Shapiro-Wilk test vu prÃ©cÃ©demment.\nCharger le package lmtest de CRAN (et installer le si besoin).\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(lmtest)\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nExÃ©cutez les commandes suivantes\n\n\n\nbptest(RegModel.1)\n\n\n    studentized Breusch-Pagan test\n\ndata:  RegModel.1\nBP = 1.1765, df = 1, p-value = 0.2781\n\n\nLe test Breusch-Pagan test examine si la variabilitÃ© des rÃ©sidus est constantes lorsque les valeurs prÃ©dites changent. Une faible valeur de p suggÃ¨re de lâ€™hÃ©tÃ©roscÃ©dasticitÃ©. Ici, la valeur p est Ã©levÃ©e et suggÃ¨re que la condition dâ€™application dâ€™homoscÃ©dasticitÃ© est remplie avec ces donnÃ©es.\n\ndwtest(RegModel.1)\n\n\n    Durbin-Watson test\n\ndata:  RegModel.1\nDW = 2.242, p-value = 0.8489\nalternative hypothesis: true autocorrelation is greater than 0\n\n\nLe test Durbin-Watson permet de dÃ©tecter lâ€™autocorrÃ©lation sÃ©rielle des rÃ©sidus. En lâ€™absence dâ€™autocorrÃ©lation (i.e.Â dâ€™indÃ©pendance des rÃ©sidus) la valeur attendue de la statistique D est 2. Ce test permet dâ€™Ã©prouver lâ€™hypothÃ¨se dâ€™indÃ©pendance des rÃ©sidus, mais ne permet de dÃ©tecter quâ€™un type particulier de dÃ©pendance. Ici, le test ne permet pas de rejeter lâ€™hypothÃ¨se dâ€™indÃ©pendance.\n\nresettest(RegModel.1)\n\n\n    RESET test\n\ndata:  RegModel.1\nRESET = 14.544, df1 = 2, df2 = 71, p-value = 5.082e-06\n\n\nLe test RESET permet dâ€™Ã©prouver la linÃ©aritÃ©. Si la relation est linÃ©aire, alors la statistique RESET sera dâ€™environ 1. Ici, la statistique est beaucoup plus Ã©levÃ©e (14.54) et hautement significative. Le test confirme la tendance que nous avons dÃ©tectÃ©e visuellement plus haut: la relation nâ€™est pas linÃ©aire.\n\nshapiro.test(residuals(RegModel.1))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(RegModel.1)\nW = 0.98037, p-value = 0.2961\n\n\nLe test de normalitÃ© Shapiro-Wilk sur les rÃ©sidus confirme que la dÃ©viation par rapport Ã  une distribution normale des rÃ©sidus nâ€™est pas grande.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#transformation-des-donnÃ©es-en-rÃ©gression",
    "href": "31-reg_lin.html#transformation-des-donnÃ©es-en-rÃ©gression",
    "title": "\n4Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n4.7 Transformation des donnÃ©es en rÃ©gression",
    "text": "4.7 Transformation des donnÃ©es en rÃ©gression\nLa relation entre fklngth et age nâ€™Ã©tant pas linÃ©aire, on devrait donc essayer de transformer les donnÃ©es pour tenter de les linÃ©ariser :\n\nVoyons ce quâ€™une transformation log donne:\n\n\npar(mfrow = c(1, 1), las = 1)\nggplot(\n  data = sturgeon.male,\n  aes(x = log10(age), y = log10(fklngth))\n) +\n  geom_smooth(color = \"red\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"green\") +\n  geom_point()\n\n\n\n\n\n\n\nAjustons maintenant une rÃ©gression simple sur ces donnÃ©es transformÃ©es.\n\nRegModel.2 &lt;- lm(log10(fklngth) ~ log10(age), data = sturgeon.male)\nsummary(RegModel.2)\n\n\nCall:\nlm(formula = log10(fklngth) ~ log10(age), data = sturgeon.male)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.082794 -0.016837 -0.000719  0.021102  0.087446 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.19199    0.02723   43.77   &lt;2e-16 ***\nlog10(age)   0.34086    0.02168   15.72   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03015 on 73 degrees of freedom\n  (5 observations deleted due to missingness)\nMultiple R-squared:  0.772, Adjusted R-squared:  0.7688 \nF-statistic: 247.1 on 1 and 73 DF,  p-value: &lt; 2.2e-16\n\n\nExaminons maintenant les graphiques diagnostiques:\n\npar(mfrow = c(2, 2), las = 1)\nplot(RegModel.2)\n\n\n\n\n\n\n\nIl y a une certaine amÃ©lioration, mais ce nâ€™est pas encore parfait (la perfection nâ€™est pas de ce mondeâ€¦.). Le graphique des rÃ©sidus en fonction des valeurs prÃ©dites suggÃ¨re encore une certaine non linÃ©aritÃ©. Sur le graphique Q-Q les points se retrouvent plus prÃ¨s de la droite diagonale quâ€™avant, indiquant que les rÃ©sidus sont encore plus prÃ¨s de la normalitÃ© aprÃ¨s la transformation log-log. Il nâ€™y a pas dâ€™indice dâ€™hÃ©tÃ©roscÃ©dasticitÃ©. Finalement, mÃªme si il reste quelques points avec plus dâ€™influence (leverage) que les autres, aucun nâ€™a une distance de Cook au-delÃ  de 0.5. En rÃ©sumÃ©, la transformation log a amÃ©liorÃ© les choses: relation est plus linÃ©aire, les rÃ©sidus sont plus normaux, et il y a moins de points avec une influence relativement Ã©levÃ©e.Est-ce que les tests formels supportent cette Ã©valuation?\n\nbptest(RegModel.2)\n\n\n    studentized Breusch-Pagan test\n\ndata:  RegModel.2\nBP = 0.14282, df = 1, p-value = 0.7055\n\ndwtest(RegModel.2)\n\n\n    Durbin-Watson test\n\ndata:  RegModel.2\nDW = 2.1777, p-value = 0.6134\nalternative hypothesis: true autocorrelation is greater than 0\n\nresettest(RegModel.2)\n\n\n    RESET test\n\ndata:  RegModel.2\nRESET = 4.4413, df1 = 2, df2 = 71, p-value = 0.01523\n\nshapiro.test(residuals(RegModel.2))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(RegModel.2)\nW = 0.98998, p-value = 0.8246\n\n\nOui, les conclusions sont les mÃªmes: les rÃ©sidus sont encore homoscÃ©dastiques (test Breusch-Pagan), ne sont pas autocorrÃ©lÃ©s (test Durbin-Watson), sont normaux (test Shapiro-Wilk), et sont plus linÃ©aires (la valeur de P du test RESET est maintenant 0.015, au lieu de 0.000005). Donc la linÃ©aritÃ© a augmentÃ©, mais cette condition dâ€™application semble encore lÃ©gÃ¨rement violÃ©e.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#traitement-des-valeurs-extrÃ¨mes",
    "href": "31-reg_lin.html#traitement-des-valeurs-extrÃ¨mes",
    "title": "\n4Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n4.8 Traitement des valeurs extrÃ¨mes",
    "text": "4.8 Traitement des valeurs extrÃ¨mes\nDans cet exemple, il nâ€™y a pas de valeur vraiment extrÃ¨me. Oui, je sais, R a quand mÃªme identifiÃ© les observations 8, 24, et 112 dans le dernier graphique diagnostique. Mais ces valeurs sont encore dans la fourchette de valeurs que je juge â€œacceptablesâ€. Mais comment dÃ©terminer objectivement ce qui est acceptable? Ã€ quel moment juge tâ€™on quâ€™une valeur extrÃªme est vraiment trop invraisemblable pour ne pas lâ€™exclure? Il nâ€™y a malheureusement pas de rÃ¨gle absolue lÃ -dessus. Les opinions varient, mais je penche vers le conservatisme sur cette question.\nMa position est que, Ã  moins que la valeur soit biologiquement impossible ou clairement une erreur dâ€™entrÃ©e de donnÃ©es, je nâ€™Ã©limine pas les valeurs extrÃªmes et jâ€™utilise toutes mes donnÃ©es dans leur analyse. Pourquoi?\nParce que je veux que mes donnÃ©es reflÃ¨tent bien la variabilitÃ© naturelle ou rÃ©elle. Câ€™est dâ€™ailleurs parfois cette variabilitÃ© qui est intÃ©ressante.\nLâ€™approche conservatrice qui consiste Ã  conserver toutes les valeurs extrÃªmes possibles est possiblement la plus honnÃªte, mais elle peut causer certains problÃ¨mes. Ces valeurs extrÃªmes sont souvent la cause des violations des conditions dâ€™application des tests statistiques. La solution suggÃ©rÃ©e Ã  ce dilemme est de faire lâ€™analyse avec et sans les valeurs extrÃªmes et de comparer les conclusions. Dans bien des cas, les conclusions seront qualitativement les mÃªmes et les tailles dâ€™effet ne seront pas trÃ¨s diffÃ©rentes. Toutefois, dans certains cas, la prÃ©sence des valeurs extrÃªmes change complÃ¨tement les conclusions. Dans ces cas, il faut simplement accepter que les conclusions dÃ©pendent entiÃ¨rement de la prÃ©sence des valeurs extrÃªmes et sont donc peu concluantes.\nSuivant cette approche comparative, refaisons donc lâ€™analyse aprÃ¨s avoir enlevÃ© les observations 8, 24, et 112.\n\nRegModel.3 &lt;- lm(log10(fklngth) ~ log10(age), data = sturgeon.male, subset = !(rownames(sturgeon.male) %in% c(\"8\", \"24\", \"112\")))\nsummary(RegModel.3)\n\n\nCall:\nlm(formula = log10(fklngth) ~ log10(age), data = sturgeon.male, \n    subset = !(rownames(sturgeon.male) %in% c(\"8\", \"24\", \"112\")))\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.069163 -0.017390  0.000986  0.018590  0.047647 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.22676    0.02431   50.46   &lt;2e-16 ***\nlog10(age)   0.31219    0.01932   16.16   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02554 on 70 degrees of freedom\n  (5 observations deleted due to missingness)\nMultiple R-squared:  0.7885,    Adjusted R-squared:  0.7855 \nF-statistic:   261 on 1 and 70 DF,  p-value: &lt; 2.2e-16\n\n\nLâ€™ordonnÃ©e Ã  lâ€™origine (Intercept), la pente, et le R carrÃ© sont presque les mÃªmes, et la valeur de p est encore astronomiquement petite. Enlever les valeurs extrÃªmes a peu dâ€™effet dans ce cas.\nLes graphiques diagnostiques des rÃ©sidus et les tests formels des conditions dâ€™application sur ce sous-ensemble de donnÃ©es donnent:\n\npar(mfrow = c(2, 2))\nplot(RegModel.3)\n\n\n\n\n\n\nsturgeon.male.subset &lt;- subset(sturgeon, subset = !(rownames(sturgeon.male) %in% c(\"8\", \"24\", \"112\")))\nbptest(RegModel.3)\n\n\n    studentized Breusch-Pagan test\n\ndata:  RegModel.3\nBP = 0.3001, df = 1, p-value = 0.5838\n\ndwtest(RegModel.3)\n\n\n    Durbin-Watson test\n\ndata:  RegModel.3\nDW = 2.0171, p-value = 0.5074\nalternative hypothesis: true autocorrelation is greater than 0\n\nresettest(RegModel.3)\n\n\n    RESET test\n\ndata:  RegModel.3\nRESET = 3.407, df1 = 2, df2 = 68, p-value = 0.0389\n\nshapiro.test(residuals(RegModel.3))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(RegModel.3)\nW = 0.98318, p-value = 0.4502\n\n\nIl nâ€™y a pas vraiment de diffÃ©rence ici non plus avec lâ€™analyse des donnÃ©es en entier. Bref, tout pointe vers la conclusion que les valeurs les plus extrÃªmes de cet ensemble de donnÃ©e nâ€™influencent pas indÃ»ment les rÃ©sultats statistiques.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#quantifier-la-taille-deffet-et-analyse-de-puissance-en-rÃ©gression",
    "href": "31-reg_lin.html#quantifier-la-taille-deffet-et-analyse-de-puissance-en-rÃ©gression",
    "title": "\n4Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n4.9 Quantifier la taille dâ€™effet et analyse de puissance en rÃ©gression",
    "text": "4.9 Quantifier la taille dâ€™effet et analyse de puissance en rÃ©gression\nLâ€™interprÃ©tation biologique des rÃ©sultats nâ€™est pas la mÃªme chose que lâ€™interprÃ©tation statistique. Dans lâ€™analyse qui prÃ©cÃ¨de, on conclue statistiquement que la taille augmente avec lâ€™Ã¢ge (puisque la pente est positive et et p&lt;0.05). Mais cette augmentation â€œstatistiqueâ€ de la taille avec lâ€™Ã¢ge ne donne pas dâ€™information sur la diffÃ©rence de taille entre les jeunes et vieux individus. La pente et un graphique sont plus informatifs Ã  ce sujet que la valeur p.Â La pente (dans lâ€™espace log-log) est 0.34. Cela veut dire que pour chaque unitÃ© dâ€™accroissement de X (log10(age)), il y a une augmentation de 0.34 unitÃ©s de log10(fklngth). En dâ€™autres mots, quand lâ€™Ã¢ge est multipliÃ© par 10, la longueur Ã  la fourche est multipliÃ©e environ par 2 (100.34). Donc la longueur des esturgeons augmente plus lentement que leur Ã¢ge (contrairement Ã  mon tour de taille, semble-t-ilâ€¦.). La valeur de la pente (0.34) est un estimÃ© de la taille de lâ€™effet de lâ€™Ã¢ge sur la longueur.\nIl est aussi importnat dâ€™estimer lâ€™intervalle de confiance sur la pente pour pouvoir estimer si lâ€™intervalle inclus ou non que des valeurs biologiquement importantes. Cela peut Ãªtre fait simplement avec la fonction confint().\n\nconfint(RegModel.2)\n\n                2.5 %   97.5 %\n(Intercept) 1.1377151 1.246270\nlog10(age)  0.2976433 0.384068\n\n\nLâ€™intervalle de confiance Ã  95% de la pente est 0.29-0.38. L,intervalle de confiance est assez faible et Ã©loignÃ© de zÃ©ro.\n\n4.9.1 Puissance de dÃ©tecter une pente donnÃ©e\nPour les calculs de puissance avec G*Power vous devrez cependant utiliser une autre mÃ©trique de la taille de lâ€™effet, calculÃ©e Ã  partir de la pente, de son erreur-type, et de la taille de lâ€™Ã©chantillon (ce qui facilite les calculs pour G*Power, mais malheureusement pas pour vous ;-) La mÃ©trique (d) est calculÃ©e comme: \\[ d = \\frac{b}{s_b\\sqrt{n-k-1}} \\] oÃ¹ \\(b\\) est lâ€™estimÃ© de la pente, \\(s_b\\) est lâ€™erreur type de la pente, \\(n\\) est le nombre dâ€™observations, et \\(k\\) est le nombre de variables indÃ©pendantes (1 pour la rÃ©gression linÃ©aire simple).\nVous pouvez calculer approximativement la puissance avec G*Power pour une valeur de pente que vous jugez assez grande pour mÃ©riter dâ€™Ãªtre dÃ©tectÃ©e. Allez Ã  Tests: Means: One group: difference from constant, lÃ , vous devrez remplacer la valeur de \\(b\\) dans lâ€™Ã©quation pour la taille dâ€™effet (d) par la pente que vous voudriez dÃ©tecter, mais utiliser lâ€™erreur type calculÃ©e Ã  partir de vos donnÃ©es.\nPar exemple, supposons que les ichthyologues considÃ¨rent quâ€™une pente de 0.1 pour la relation entre log10(fklngth) et log10(age) est signifiante biologiquement, et quâ€™ils dÃ©sirent estimer la puissance de dÃ©tecter une telle pente Ã  partir dâ€™un Ã©chantillon de 20 esturgeons. Les rÃ©sultats de la rÃ©gression log-log nous fournissent ce dont on a besoin:\n\nsummary(RegModel.2)\n\n\nCall:\nlm(formula = log10(fklngth) ~ log10(age), data = sturgeon.male)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.082794 -0.016837 -0.000719  0.021102  0.087446 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.19199    0.02723   43.77   &lt;2e-16 ***\nlog10(age)   0.34086    0.02168   15.72   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03015 on 73 degrees of freedom\n  (5 observations deleted due to missingness)\nMultiple R-squared:  0.772, Adjusted R-squared:  0.7688 \nF-statistic: 247.1 on 1 and 73 DF,  p-value: &lt; 2.2e-16\n\n\nLâ€™erreur-type de la pente est 0.02168. Il y avait 75 poissons (n=75) dans lâ€™Ã©chantillon de dÃ©part. On peut donc calculer la mÃ©trique de taille dâ€™effet pour G*Power \\[ d = \\frac{b}{s_b\\sqrt{n-k-1}} = \\frac{0.1}{0.02168\\sqrt{74-1-1}}=0.54\\]\nArmÃ©s de cette taille dâ€™effet (une pente prÃ©sumÃ©e de 0.1 et une variabilitÃ© autour de la rÃ©gression similaire Ã  la rÃ©gression de fklngth vs age), aller Ã  Tests: Means: One group: difference from constant, et entrez la valeur calculÃ©e de d, alpha, et lâ€™effectif de lâ€™Ã©chantillon pour calculer la puissance.\n\n\n\n\nAnalyse de puissance pour N = 20 et pente = 0.1\n\n\n\nDans R, il est possible de faire cette analyse avec le code suivant:\n\nlibrary(pwr)\n\n# analyse de puissance\npwr.t.test(n = 20, d = 0.54, sig.level = 0.05, type = \"one.sample\")\n\n\n     One-sample t test power calculation \n\n              n = 20\n              d = 0.54\n      sig.level = 0.05\n          power = 0.6299804\n    alternative = two.sided\n\n\nLa puissance de dÃ©tecter une pente comme Ã©tant statistiquement significative (au niveau alpha), si la pente est 0.1, que la variabilitÃ© rÃ©siduelle autour de la rÃ©gression est semblable Ã  celle de notre Ã©chantillon (ce qui revient Ã  une taille dâ€™effet de 0.54, pour un Ã©chantillon de 20 esturgeons et alpha=0.05) est de 0.629. Seulement environ 2/3 des Ã©chantillons de cette taille dÃ©tecteraient un effet significatif de lâ€™Ã¢ge sur fklngth.\n\n4.9.2 Effectif requis pour atteindre une puissance dÃ©sirÃ©e (test A-priori)\nPour estimer la taille dâ€™Ã©chantillon (effectif) requis pour avoir une puissance de 99% de dÃ©tecter un effet de lâ€™Ã¢ge si la pente est 0.1 (sur une Ã©chelle log-log), avec alpha=0.05, on utilise la mÃªme valeur de d (0.54):\n\n\n\n\nAnalyse Ã  priori pour dÃ©terminer la taille dâ€™Ã©chantillon pour une puissance de 0.99\n\n\n\nDans R, il est possible de faire cette analyse avec le code suivant:\n\nlibrary(pwr)\n\n# analyse de puissance\npwr.t.test(n = 65, d = 0.54, sig.level = 0.05, type = \"one.sample\")\n\n\n     One-sample t test power calculation \n\n              n = 65\n              d = 0.54\n      sig.level = 0.05\n          power = 0.9900297\n    alternative = two.sided\n\n\nEn augmentant la taille de lâ€™Ã©chantillon Ã  65, selon le mÃªme scÃ©nario que prÃ©cÃ©demment, la puissance augmente Ã  99%.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "31-reg_lin.html#bootstrap-en-rÃ©gression-simple-avec-r",
    "href": "31-reg_lin.html#bootstrap-en-rÃ©gression-simple-avec-r",
    "title": "\n4Â  CorrÃ©lation et rÃ©gression linÃ©aire simple\n",
    "section": "\n4.10 Bootstrap en rÃ©gression simple avec R",
    "text": "4.10 Bootstrap en rÃ©gression simple avec R\nUn test non paramÃ©trique pour lâ€™ordonnÃ©e Ã  lâ€™origine et la pente dâ€™une rÃ©gression simple peut Ãªtre effectuÃ© par bootstrap.\n\n# charger le paquet boot\nlibrary(boot)\n# obtenir les poids de rÃ©gression\nbs &lt;- function(formula, data, indices) {\n  d &lt;- data[indices, ] # allows boot to select sample\n  fit &lt;- lm(formula, data = d)\n  return(coef(fit))\n}\n# bootstrapping with 1000 replications\nresults &lt;- boot(\n  data = sturgeon.male,\n  statistic = bs,\n  R = 1000, formula = log10(fklngth) ~ log10(age)\n)\n# view results\nresults\n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = sturgeon.male, statistic = bs, R = 1000, formula = log10(fklngth) ~ \n    log10(age))\n\n\nBootstrap Statistics :\n     original        bias    std. error\nt1* 1.1919926  0.0011567837  0.03387942\nt2* 0.3408557 -0.0007755788  0.02683725\n\n\nPour chaque paramÃ¨tre du modÃ¨le (ici lâ€™ordonnÃ©e Ã  lâ€™origine est appelÃ©e t1* et la pente de la rÃ©gression t2*), R imprime :\n\n\noriginal la valeur estimÃ©e sur tout lâ€™Ã©chantillon\n\nbias la diffÃ©rence entre la valeur moyenne des estimÃ©s par bootstrap et la valeur originale sur tout lâ€™Ã©chantillon\n\nstd. error lâ€™erreur-type de lâ€™estimÃ© bootstrap\n\n\npar(mfrow = c(2, 2))\nplot(results, index = 1) # intercept\n\n\n\n\n\n\nplot(results, index = 2) # log10(age)\n\n\n\n\n\n\n\nLa distribution des estimÃ©s obtenus par bootstrap est assez normale dans cet exemple, avec de petites dÃ©viations dans les queuee de la distribution (lÃ  oÃ¹ Ã§a compte pour les intervalles de confianceâ€¦). On pourrait utiliser lâ€™erreur-type des estimÃ©s bootstrap pour calculer un intervalle de confiance symÃ©trique (moyenne +- t ET). Cependant, comme R peut facilement calculer des intervalles de confiance qui corrigent pour le biais (BCa) ou encore des intervalle empiriques Ã  partir des distributions simulÃ©es (mÃ©thode Percentile) il peut Ãªtre aussi simple de les calculer selon les 3 mÃ©thodes:\n\n# interval de confiance pour l'ordonnÃ©e Ã  l'origine\nboot.ci(results, type = \"all\", index = 1)\n\nWarning in boot.ci(results, type = \"all\", index = 1): bootstrap variances\nneeded for studentized intervals\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results, type = \"all\", index = 1)\n\nIntervals : \nLevel      Normal              Basic         \n95%   ( 1.124,  1.257 )   ( 1.120,  1.258 )  \n\nLevel     Percentile            BCa          \n95%   ( 1.125,  1.264 )   ( 1.114,  1.251 )  \nCalculations and Intervals on Original Scale\n\n\n\n# intervalle de confiance pour la pente\nboot.ci(results, type = \"all\", index = 2)\n\nWarning in boot.ci(results, type = \"all\", index = 2): bootstrap variances\nneeded for studentized intervals\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results, type = \"all\", index = 2)\n\nIntervals : \nLevel      Normal              Basic         \n95%   ( 0.2890,  0.3942 )   ( 0.2894,  0.3968 )  \n\nLevel     Percentile            BCa          \n95%   ( 0.2849,  0.3923 )   ( 0.2937,  0.4029 )  \nCalculations and Intervals on Original Scale\n\n\nIci, les 4 types dâ€™intervalles de confiance que R a calculÃ© sont essentiellement semblables. Si les donnÃ©es avaient violÃ© plus sÃ©vÃ¨rement les conditions dâ€™application de la rÃ©gression (normalitÃ©, homoscedasticitÃ©), alors les diffÃ©rentes mÃ©thodes (Normal, Basic, Percentile, et BCa) auraient divergÃ© un peu plus. Lequel choisir alors? BCa est celui qui est prÃ©fÃ©rÃ© de la majoritÃ© des praticiens, prÃ©sentement.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>CorrÃ©lation et rÃ©gression linÃ©aire simple</span>"
    ]
  },
  {
    "objectID": "32-t_test.html",
    "href": "32-t_test.html",
    "title": "\n5Â  Comparaison de deux Ã©chantillons\n",
    "section": "",
    "text": "5.1 Paquets et donnÃ©es requises pour le labo\nCe laboratoire nÃ©cessite:\nlibrary(car)\nlibrary(lmtest)\nlibrary(boot)\nlibrary(lmPerm)\nlibrary(ggplot2)\nsturgeon &lt;- read.csv(\"data/sturgeon.csv\")\nskull &lt;- read.csv(\"data/skulldat_2020.csv\")",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Comparaison de deux Ã©chantillons</span>"
    ]
  },
  {
    "objectID": "32-t_test.html#set-t",
    "href": "32-t_test.html#set-t",
    "title": "\n5Â  Comparaison de deux Ã©chantillons\n",
    "section": "",
    "text": "les paquets R:\n\ncar\nlmtest\nboot\nlmPerm\n\n\nles fichiers de donnÃ©es\n\nsturgeon.csv\nskulldat_2020.csv",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Comparaison de deux Ã©chantillons</span>"
    ]
  },
  {
    "objectID": "32-t_test.html#examen-visuel-des-donnÃ©es",
    "href": "32-t_test.html#examen-visuel-des-donnÃ©es",
    "title": "\n5Â  Comparaison de deux Ã©chantillons\n",
    "section": "\n5.2 Examen visuel des donnÃ©es",
    "text": "5.2 Examen visuel des donnÃ©es\nUne des premiÃ¨res Ã©tapes dans toute analyse de donnÃ©es est lâ€™examen visuel des donnÃ©es par des graphiques et statistiques sommaires pour dÃ©tecter les distributions sous-jacentes, les valeurs extrÃªmes et les tendances dans vos donnÃ©es. Cela commence souvent avec des graphiques de vos donnÃ©es (histogrammes, diagrammes de probabilitÃ©, Box plots, etc.) qui vous permettent dâ€™Ã©valuer si vos donnÃ©es sont normales, si elles sont corrÃ©lÃ©es les unes aux autres, ou sâ€™il y a des valeurs suspectes dans le fichier.\nSupposons que lâ€™on veuille comparer la distribution en taille des esturgeons de The Pas et Cumberland House. La variable fklngth dans le fichier sturgeon.csv reprÃ©sente la longueur (en cm) Ã  la fourche de chaque poisson mesurÃ©e de lâ€™extrÃ©mitÃ© de la tÃªte Ã  la base de la fourche de la nageoire caudale. Pour commencer, examinons si cette variable est normalement distribuÃ©e. On ne va pas tester pour la normalitÃ© Ã  ce stade-ci; la prÃ©somption de normalitÃ© dans les analyses paramÃ©triques sâ€™applique aux rÃ©sidus et non aux donnÃ©es brutes. Cependant, si les donnÃ©es brutes ne sont pas normales, vous avez dâ€™habitude une trÃ¨s bonne raison de soupÃ§onner que les rÃ©sidus vont aussi ne pas avoir une distribution normale.\nUne excellente faÃ§on de comparer visuellement une distribution Ã  la distribution normale est de superposer un histogramme des donnÃ©es observÃ©es Ã  une courbe normale. Pour ce faire, il faut procÃ©der en deux Ã©tapes :\n\nindiquer Ã  R que nous voulons crÃ©er un histogramme superposÃ© Ã  une courbe normale\nspÃ©cifier quâ€™on veut que les graphiques soient faits pour les deux sites\n\n\nEn utilisant les donnÃ©es du fichier sturgeon.csv, gÃ©nÃ©rez les histogrammes et les approximations des distributions normales ajustÃ©es aux donnÃ©es de fklngth Ã  The Pas et Cumberland House.\n\n\n# use \"sturgeon\" dataframe to make plot called mygraph\n# and define x axis as representing fklngth\nmygraph &lt;- ggplot(\n  data = sturgeon,\n  aes(x = fklngth)\n) +\n  xlab(\"Fork length (cm)\")\n# add data to the mygraph ggplot\nmygraph &lt;- mygraph +\n  geom_density() + # add data density smooth\n  geom_rug() + # add rug (bars at the bottom of the plot)\n  geom_histogram( # add black semitransparent histogram\n    aes(y = ..density..),\n    color = \"black\", alpha = 0.3\n  ) +\n  # add normal curve in red, with mean and sd from fklength\n  stat_function(\n    fun = dnorm,\n    args = list(\n      mean = mean(sturgeon$fklngth),\n      sd = sd(sturgeon$fklngth)\n    ),\n    color = \"red\"\n  )\n# display graph, by location\nmygraph + facet_grid(. ~ location)\n\n\n\nDistribution de la longueur des esturgeons\n\n\n\nExaminez ce graphique et essayez de dÃ©terminer si ces deux Ã©chantillons sont normalement distribuÃ©s. Ã€ mon avis, cette variable est approximativement normalement distribuÃ©e dans les deux Ã©chantillons. Puisque ce qui nous intÃ©resse est de comparer la taille des poissons de deux sites diffÃ©rents, câ€™est probablement une bonne idÃ©e de crÃ©er un graphique qui compare les deux groupes de donnÃ©es. Un Box plot convient trÃ¨s bien pour cette tÃ¢che.\n\nTracez un boxplot de fklngth groupÃ© par location. Que concluez-vous quant Ã  la diffÃ©rence entre les deux sites?\n\n\nggplot(data = sturgeon, aes(\n  x = location,\n  y = fklngth\n)) +\n  geom_boxplot(notch = TRUE)\n\n\n\nBoxplot de la longueur des esturgeons\n\n\n\nIl nâ€™y a pas de grande diffÃ©rence de taille entre les deux sites, mais la taille des poissons Ã  The Pas est plus variable ayant une plus large Ã©tendue de taille et des valeurs extrÃªmes (dÃ©finies par les valeurs qui sont &gt; 1.5*lâ€™Ã©tendue interquartile) Ã  chaque bout de la distribution.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Comparaison de deux Ã©chantillons</span>"
    ]
  },
  {
    "objectID": "32-t_test.html#comparer-les-moyennes-de-deux-Ã©chantillons-indÃ©pendants",
    "href": "32-t_test.html#comparer-les-moyennes-de-deux-Ã©chantillons-indÃ©pendants",
    "title": "\n5Â  Comparaison de deux Ã©chantillons\n",
    "section": "\n5.3 Comparer les moyennes de deux Ã©chantillons indÃ©pendants",
    "text": "5.3 Comparer les moyennes de deux Ã©chantillons indÃ©pendants\nÃ‰prouvez lâ€™hypothÃ¨se nulle dâ€™Ã©galitÃ© de la longueur Ã  la fourche Ã  The Pas et Cumberland House de 3 maniÃ¨res diffÃ©rentes:\n\nparamÃ©triques supposant des variances Ã©gales\nparamÃ©triques supposant des variances diffÃ©rentes\nnon-paramÃ©trique (pas de conditions dâ€™aplications sur la distribution et la variance)\n\nQue concluez-vous?\n\n# t-test assuming equal variances\nt.test(\n  fklngth ~ location,\n  data = sturgeon,\n  alternative = \"two.sided\",\n  var.equal = TRUE\n)\n\n\n    Two Sample t-test\n\ndata:  fklngth by location\nt = 2.1359, df = 184, p-value = 0.03401\nalternative hypothesis: true difference in means between group CUMBERLAND and group THE_PAS is not equal to 0\n95 percent confidence interval:\n 0.1308307 3.2982615\nsample estimates:\nmean in group CUMBERLAND    mean in group THE_PAS \n                45.08439                 43.36984 \n\n\n\n# t-test assuming unequal variances\nt.test(\n  fklngth ~ location,\n  data = sturgeon,\n  alternative = \"two.sided\",\n  var.equal = FALSE\n)\n\n\n    Welch Two Sample t-test\n\ndata:  fklngth by location\nt = 2.2201, df = 169.8, p-value = 0.02774\nalternative hypothesis: true difference in means between group CUMBERLAND and group THE_PAS is not equal to 0\n95 percent confidence interval:\n 0.1900117 3.2390804\nsample estimates:\nmean in group CUMBERLAND    mean in group THE_PAS \n                45.08439                 43.36984 \n\n\n\n# test non paramÃ©trique\nwilcox.test(\n  fklngth ~ location,\n  data = sturgeon,\n  alternative = \"two.sided\"\n)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  fklngth by location\nW = 4973, p-value = 0.06296\nalternative hypothesis: true location shift is not equal to 0\n\n\nEn se fiant au test de t, on rejette donc lâ€™hypothÃ¨se nulle. Il y a une diffÃ©rence significative entre les deux moyennes des longueurs Ã  la fourche.\nNotez que si lâ€™on se fie au test de Wilcoxon, il faut accepter lâ€™hypothÃ¨se nulle. Les deux tests mÃ¨nent donc Ã  des conclusions contradictoires. La diffÃ©rence significative obtenue par le test de t peut provenir en partie dâ€™une violation des conditions dâ€™application du test (normalitÃ© et homoscÃ©dasticitÃ©). Dâ€™un autre cÃ´tÃ©, lâ€™absence de diffÃ©rence significative selon le test de Wilcoxon pourrait Ãªtre due au fait que, pour un effectif donnÃ©, la puissance du test non paramÃ©trique est infÃ©rieure Ã  celle du test paramÃ©trique correspondant. Compte tenu 1) des valeurs de p obtenues pour les deux tests, et 2) le fait que pour des grands Ã©chantillons (des effectifs de 84 et 101 sont considÃ©rÃ©s grands) le test de t est considÃ©rÃ© robuste, il est raisonnable de rejeter lâ€™hypothÃ¨se nulle.\nAvant dâ€™accepter les rÃ©sultats du test de t et de rejeter lâ€™hypothÃ¨se nulle quâ€™il nâ€™y a pas de diffÃ©rences de taille entre les deux sites, il est important de dÃ©terminer si les donnÃ©es remplissent les conditions de normalitÃ© des rÃ©sidus et dâ€™Ã©galitÃ© des variances. Lâ€™examen prÃ©liminaire suggÃ©rait que les donnÃ©es sont Ã  peu prÃ¨s normales mais quâ€™il y avait peut-Ãªtre des problÃ¨mes avec les variances (puisque lâ€™Ã©tendue des donnÃ©es pour The Pas Ã©tait beaucoup plus grande que celle pour Cumberland). On peut examiner ces conditions dâ€™application plus en dÃ©tail en examinant les rÃ©sidus dâ€™un modÃ¨le linÃ©aire et en utilisant les graphiques diagnostiques:\n\nm1 &lt;- lm(fklngth ~ location, data = sturgeon)\npar(mfrow = c(2, 2))\nplot(m1)\n\n\n\nCondition dâ€™application du modÃ¨le linÃ©aire\n\n\n\nLe premier graphique ci-dessus montre comment les rÃ©sidus se distribuent autour des valeurs prÃ©dites (les moyennes) pour chaque site et permette de juger si il semble y avoir un problÃ¨me de normalitÃ© ou dâ€™homoscÃ©dasticitÃ©. Si les variances Ã©taient Ã©gales dans les deux sites, lâ€™Ã©tendue verticale des rÃ©sidus tendrait Ã  Ãªtre la mÃªme. Sur le graphique, on voit que lâ€™Ã©tendue des rÃ©sidus est plus grande Ã  gauche (le site oÃ¹ la taille moyenne est la plus faible), ce qui suggÃ¨re un possible problÃ¨me dâ€™homogÃ©nÃ©itÃ© des variances. On peut tester cela plus formellement en comparant la moyenne de la valeur absolue des rÃ©sidus.(on y reviendra; câ€™est le test de Levene).\nLe second graphique est un graphique de probabilitÃ© (graphique Q-Q) des rÃ©sidus. Comme ici, les points tombent prÃ¨s de la diagonale, il ne semble pas y avoir de problÃ¨me important avec la normalitÃ©. On peut faire un test formel de la condition de normalitÃ© par le test de Shapiro- Wilk:\n\nshapiro.test(residuals(m1))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(m1)\nW = 0.97469, p-value = 0.001857\n\n\nHummm. Ce test indique que les rÃ©sidus ne sont pas normaux, ce qui contredit notre Ã©valuation visuelle. Cependant, puisque (a) la distribution des rÃ©sidus ne sâ€™Ã©loigne pas beaucoup de la normalitÃ© et (b) le nombre dâ€™observations Ã  chaque site est raisonnablement grand (i.e.Â &gt;30), on nâ€™a pas Ã  Ãªtre trop inquiet quant Ã  lâ€™impact de cette violation de normalitÃ© sur la fiabilitÃ© du test.\nQuâ€™en est-il de lâ€™Ã©galitÃ© des variances?\n\nlibrary(car)\nleveneTest(m1)\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value    Pr(&gt;F)    \ngroup   1  11.514 0.0008456 ***\n      184                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nbptest(m1)\n\n\n    studentized Breusch-Pagan test\n\ndata:  m1\nBP = 8.8015, df = 1, p-value = 0.00301\n\n\nLes rÃ©sultats qui prÃ©cÃ©dents proviennent de 3 des tests disponibles en R (dans les package car et lmtest) qui Ã©prouvent lâ€™hypothÃ¨se de lâ€™Ã©galitÃ© des variances dans des tests de t ou des modÃ¨les linÃ©aires ayant uniquement des variables indÃ©pendantes discontinues ou catÃ©goriques. Il est redondant de faire les 2 tests. Si ils sont prÃ©sentÃ©s ici, câ€™est que ces 2 tests sont usuels et quâ€™il nâ€™y a pas consensus quant au meilleur des deux. Le test de Levene est le plus connu et utilisÃ©. Il compare la moyenne des valeurs absolues des rÃ©sidus dans les deux groupes. Le test Breusch-Pagan a lâ€™avantage dâ€™Ãªtre applicable Ã  une plus large gamme de modÃ¨les linÃ©aires (il peut Ãªtre utilisÃ© Ã©galement avec des variables indÃ©pendantes continues, comme en rÃ©gression). Ici, les deux tests mÃ¨nent Ã  la mÃªme conclusion: la variance diffÃ¨re entre les deux sites.\nSur la base de ces rÃ©sultats, on peut conclure quâ€™il y a Ã©vidence (mais faible) pour rejeter lâ€™hypothÃ¨se nulle quâ€™il nâ€™y a pas de diffÃ©rence dans la taille de poissons entre les deux sites. On a utilisÃ© une modification du test de t pour tenir compte du fait que les variances ne sont pas Ã©gales et nous sommes satisfaits que la condition de normalitÃ© des rÃ©sidus a Ã©tÃ© remplie. Alors, fklngth Ã  Cumberland est plus grande que fklngth Ã  The Pas.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Comparaison de deux Ã©chantillons</span>"
    ]
  },
  {
    "objectID": "32-t_test.html#bootstrap-et-tests-de-permutation-pour-comparer-deux-moyennes",
    "href": "32-t_test.html#bootstrap-et-tests-de-permutation-pour-comparer-deux-moyennes",
    "title": "\n5Â  Comparaison de deux Ã©chantillons\n",
    "section": "\n5.4 Bootstrap et tests de permutation pour comparer deux moyennes",
    "text": "5.4 Bootstrap et tests de permutation pour comparer deux moyennes\n\n5.4.1 Bootstrap\nLe bootstrap et les tests de permutation peuvent Ãªtre utilisÃ©s pour comparer les moyennes (ou dâ€™autres statistiques). Le principe gÃ©nÃ©ral est simple et peut Ãªtre effectuÃ© de diverses faÃ§ons. Ici jâ€™utilise certains des outils disponibles et le fait quâ€™une comparaison de moyenne peut Ãªtre reprÃ©sentÃ©e par un modÃ¨le linÃ©aire. On pourra utiliser un programme similaire plus tard quand on ajustera des modÃ¨les plus complexes.\nlibrary(boot)\nLa premiÃ¨re section sert Ã  dÃ©finir une fonction (ici appelÃ©e bs) qui extraie les coefficients dâ€™un modÃ¨le ajustÃ© :\n\n# function to obtain model coefficients for each iteration\nbs &lt;- function(formula, data, indices) {\n  d &lt;- data[indices, ]\n  fit &lt;- lm(formula, data = d)\n  return(coef(fit))\n}\n\nLa deuxiÃ¨me section avec la commande boot() fait le gros du travail: on prend les donnÃ©es dans sturgeon, on les bootstrap \\(R = 1000\\) fois, et chaque fois on ajuste le modÃ¨le fklngth vs location et on garde les valeurs calculÃ©es par la fonction bs.\n\n# bootstrapping with 1000 replications\nresults &lt;- boot(\n  data = sturgeon, statistic = bs, R = 1000,\n  formula = fklngth ~ location\n)\n# view results\nresults\n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = sturgeon, statistic = bs, R = 1000, formula = fklngth ~ \n    location)\n\n\nBootstrap Statistics :\n     original       bias    std. error\nt1* 45.084391 -0.001144302   0.4317398\nt2* -1.714546  0.017195029   0.7498871\n\n\nOn obtient les estimÃ©s originaux pour les deux coefficients du modÃ¨le: la moyenne pour le premier (alphabÃ©tiquement) site soit Cumberland, et la diffÃ©rence entre les deux moyennes Ã  Cumberland et The Pas. Câ€™est ce second paramÃ¨tre, la diffÃ©rence entre les moyennes, qui nous intÃ©resse.\n\nplot(results, index = 2)\n\n\n\nNormalitÃ© des estimÃ©s de la diffÃ©rence des moyennes par bootstrap\n\n\n\n\n# get 95% confidence intervals\nboot.ci(results, type = \"bca\", index = 2)\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results, type = \"bca\", index = 2)\n\nIntervals : \nLevel       BCa          \n95%   (-3.245, -0.346 )  \nCalculations and Intervals on Original Scale\n\n\nComme lâ€™intervalle de confiance nâ€™inclue pas 0, on conclue que les moyennes ne sont pas les mÃªmes.\n\n5.4.2 Permutation\nLes tests de permutation pour les modÃ¨les linÃ©aires peuvent Ãªtre effectuÃ©s Ã  lâ€™aide du package lmPerm:\n\nm1Perm &lt;- lmp(\n  fklngth ~ location,\n  data = sturgeon,\n  perm = \"Prob\"\n)\n\n[1] \"Settings:  unique SS \"\n\n\nLa fonction lmp() fait tout le travail pour nous. Ici, cette fonction est effectuÃ©e avec lâ€™option perm pour choisir la rÃ¨gle utilisÃ©e pour stopper les calculs. Lâ€™option Probs arrÃªte les permutations quand la dÃ©viation standard estimÃ©e pour la p-valeur tombe sous un seuil dÃ©terminÃ©. Câ€™est lâ€™une des nombreuses rÃ¨gles qui peuvent possiblement Ãªtre utilisÃ©es pour ne faire les permutations que sur un sous-ensemble des permutations possibles (ce qui prendrait souvent trrrrrÃ¨s longtemps).\n\nsummary(m1Perm)\n\n\nCall:\nlmp(formula = fklngth ~ location, data = sturgeon, perm = \"Prob\")\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-18.40921  -3.75370  -0.08439   3.76598  23.48055 \n\nCoefficients:\n          Estimate Iter Pr(Prob)  \nlocation1   0.8573 2522   0.0385 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.454 on 184 degrees of freedom\nMultiple R-Squared: 0.02419,    Adjusted R-squared: 0.01889 \nF-statistic: 4.562 on 1 and 184 DF,  p-value: 0.03401 \n\n\n\n\nIter: la rÃ¨gle a limitÃ© Ã  2522 permutations le calcul. Notez que ce nombre va varier Ã  chaque fois que vous tournerez cet petit bout de code. Ce sont des rÃ©sultats obtenus par permutations alÃ©atoires, donc vous devez vous attendre Ã  de la variabilitÃ©. .\n\nPr(Prob): La p-valeur estimÃ©e pour H0 est 0.0385. La diffÃ©rence observÃ©e pour fklngth between entre les deux sites Ã©tait plus grande que les valeurs permutÃ©es environ (1 - 0.0385= 96.2%) des 2522 permutations. Notez que 2522 permutations ce nâ€™est pas un si grand nombre de permutations que Ã§a, et donc les faibles valeurs de p ne sont pas trÃ¨s prÃ©cises. Si vous voulez des valeurs prÃ©cises de p, vous devrez faire plus de permutations. Vous pouvez ajuster 2 paramÃ¨tres: maxIter, le nombre maximal de permutations (dÃ©faut 5000) et Ca, le seuil de prÃ©cision dÃ©sirÃ© qui arrÃªte les permutations quand lâ€™erreur- type de p est plus petite que Ca*p (dÃ©faut=0.1)\n\nF-statistic: Le reste est la sortie standard pour un modÃ¨le ajustÃ© Ã  des donnÃ©es, avec le test paramÃ©trique. Ici, la p-valeur, prÃ©sumant que toutes les conditions dâ€™application sont remplies, est 0.034.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Comparaison de deux Ã©chantillons</span>"
    ]
  },
  {
    "objectID": "32-t_test.html#comparer-les-moyennes-de-deux-Ã©chantillons-appariÃ©s",
    "href": "32-t_test.html#comparer-les-moyennes-de-deux-Ã©chantillons-appariÃ©s",
    "title": "\n5Â  Comparaison de deux Ã©chantillons\n",
    "section": "\n5.5 Comparer les moyennes de deux Ã©chantillons appariÃ©s",
    "text": "5.5 Comparer les moyennes de deux Ã©chantillons appariÃ©s\n\n\n\n\n\n\nAvertissement\n\n\n\nPour la section suivante veuillez tÃ©lÃ©charger le nouveau fichier skulldat_2020.csv qui a Ã©tÃ© rÃ©cemment ajoutÃ© sur Brightspace.\n\n\nDans certaines expÃ©riences les mÃªmes individus sont mesurÃ©s deux fois, par exemple avant et aprÃ¨s un traitement ou encore Ã  deux moments au cours de leur dÃ©veloppement. Les mesures obtenues lors de ces deux Ã©vÃ©nements ne sont pas indÃ©pendantes, et des comparaisons de ces mesures appariÃ©es doivent Ãªtre faites.\nLe fichier skulldat_2020.csv contient des mesures de la partie infÃ©rieure du visage de jeunes filles dâ€™AmÃ©rique du Nord prises Ã  5 ans, puis Ã  6 ans (donnÃ©es de Newman and Meredith, 1956).\n\nPour dÃ©buter, Ã©prouvons lâ€™hypothÃ¨se que la largeur de la figure est la mÃªme Ã  5 ans et Ã  6 ans en assumant que les mesures viennent dâ€™Ã©chantillons indÃ©pendants.\n\n\nskull &lt;- read.csv(\"data/skulldat_2020.csv\")\nt.test(width ~ age,\n  data = skull,\n  alternative = \"two.sided\"\n)\n\n\n    Welch Two Sample t-test\n\ndata:  width by age\nt = -1.7812, df = 27.93, p-value = 0.08576\nalternative hypothesis: true difference in means between group 5 and group 6 is not equal to 0\n95 percent confidence interval:\n -0.43002624  0.03002624\nsample estimates:\nmean in group 5 mean in group 6 \n       7.461333        7.661333 \n\n\nJusquâ€™Ã  maintenant, nous avons spÃ©cifiÃ© le test de t en utilisant une notation de type formule avec y ~ x oÃ¹ y est la variable pour laquelle on souhaite comparer les moyennes et x correspond Ã  une variable dÃ©finissant les groupes. Cela marche bien lorsque les donnÃ©es de sont pas pairÃ©es et sont prÃ©sentÃ©es dans un format de type long oÃ¹ les donnÃ©es prise dans une mÃªme catÃ©gorie ou sur une mÃªme personne sont simplement les unes en-dessous des autres avec des colonnes indiquant lâ€™appartenance des mesures aux diffÃ©rentes catÃ©gories (voir la structure de skull par exemple) Dans lâ€™objet skull, il y a 3 colonnes:\n\n\nwidth: largeur de la tÃªte\n\nage: age lors de la mesure\n\nid: identitÃ© de la personne\n\n\nhead(skull)\n\n  width age id\n1  7.33   5  1\n2  7.53   6  1\n3  7.49   5  2\n4  7.70   6  2\n5  7.27   5  3\n6  7.46   6  3\n\n\nQuand les donnÃ©es sont pairÃ©es, il faut indiquer comment elle doivent Ãªtre associÃ©es. Dans notre exemple, elles sont pairÃ©es par individu. Le format de donnÃ©es de type long indique cet appariement via la colonne id. Cependant, la fonction t.test ne permet pas de le prendre en compte. Il faut donc transformer les donnÃ©es en format de type large ou horizontale ou il y a une colonne diffÃ©rente pour chaque catÃ©gorie. Dans notre example, on souhaite avoir un fichier avec une colonne de mesure par age et oÃ¹ chaque ligne correspond Ã  une personne diffÃ©rente. On peut modifier le format des donnÃ©es avec le code suivant.\n\nskull_h &lt;- data.frame(id = unique(skull$id))\nskull_h$width5 &lt;- skull$width[match(skull_h$id, skull$id) & skull$age == 5]\nskull_h$width6 &lt;- skull$width[match(skull_h$id, skull$id) & skull$age == 6]\nhead(skull_h)\n\n  id width5 width6\n1  1   7.33   7.53\n2  2   7.49   7.70\n3  3   7.27   7.46\n4  4   7.93   8.21\n5  5   7.56   7.81\n6  6   7.81   8.01\n\n\nMaintenant, effectuons le test appariÃ© qui est appropriÃ©: Que conclure? Comment les rÃ©sultats diffÃ¨rent-ils de la premiÃ¨re analyse? Pourquoi?\n\nt.test(skull_h$width5, skull_h$width6,\n  alternative = \"two.sided\",\n  paired = TRUE\n)\n\n\n    Paired t-test\n\ndata:  skull_h$width5 and skull_h$width6\nt = -19.72, df = 14, p-value = 1.301e-11\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.2217521 -0.1782479\nsample estimates:\nmean difference \n           -0.2 \n\n\nLa premiÃ¨re analyse a comme supposition que les deux Ã©chantillons de filles de 5 et 6 ans sont indÃ©pendants, alors que la deuxiÃ¨me analyse a comme supposition que la mÃªme fille a Ã©tÃ© mesurÃ©e deux fois, une fois Ã  5 ans, et la deuxiÃ¨me fois Ã  6 ans.\nNotez que, dans le premier cas, on accepte lâ€™hypothÃ¨se nulle, mais que le test appariÃ© rejette lâ€™hypothÃ¨se nulle. Donc, le test qui est appropriÃ© (le test appariÃ©) indique un effet trÃ¨s significatif de lâ€™Ã¢ge, mais le test inappropriÃ© suggÃ¨re que lâ€™Ã¢ge nâ€™importe pas. Câ€™est parce quâ€™il y a une trÃ¨s forte corrÃ©lation entre la largeur du visage Ã  5 et 6 ans:\n\ngraphskull &lt;- ggplot(data = skull_h, aes(x = width5, y = width6)) +\n  geom_point() +\n  labs(x = \"Skull width at age 5\", y = \"Skull width at age 6\") +\n  geom_smooth() +\n  scale_fill_continuous(low = \"lavenderblush\", high = \"red\")\ngraphskull\n\n\n\nRelation entre la taille de la tÃªte Ã  5 et 6 ans\n\n\n\nAvec r = 0.9930841. En prÃ©sence dâ€™une si forte corrÃ©lation, lâ€™erreur-type de la diffÃ©rence appariÃ©e de largeur du visage entre 5 et 6 ans est beaucoup plus petit que lâ€™erreur-type de la diffÃ©rence entre la largeur moyenne Ã  5 ans et la largeur moyenne Ã  6 ans. Par consÃ©quent, la statistique t associÃ©e est beaucoup plus Ã©levÃ©e pour le test appariÃ©, la puissance du test est plus grande, et la valeur de p plus petite.\n\nRÃ©pÃ©tez lâ€™analyse en utilisant lâ€™alternative nonparamÃ©trique, le test Wil-coxon signed-rank. (Que concluez-vous?\n\n\nwilcox.test(skull_h$width5, skull_h$width6,\n  alternative = \"two.sided\",\n  paired = TRUE\n)\n\nWarning in wilcox.test.default(skull_h$width5, skull_h$width6, alternative =\n\"two.sided\", : cannot compute exact p-value with ties\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  skull_h$width5 and skull_h$width6\nV = 0, p-value = 0.0007193\nalternative hypothesis: true location shift is not equal to 0\n\n\nDonc on tire la mÃªme conclusion quâ€™avec le test de t appariÃ© et conclue quâ€™il y a des diffÃ©rences significatives entre la taille des crÃ¢nes de filles Ã¢gÃ©es de 5 et 6 ans (quelle surprise!).\nMais, attendez une minute! On a utilisÃ© des tests bilatÃ©raux ici mais, compte tenu de s connaissances sur la croissance des enfants, une hypothÃ¨se unilatÃ©rale serait prÃ©fÃ©rable. Ceci peut Ãªtre accommodÃ© en modifiant lâ€™option â€œalternativeâ€. On utilise lâ€™hypothÃ¨se alternative pour dÃ©cider entre â€œlessâ€ ou â€œgreaterâ€. Ici on sâ€™attends que si il y a une diffÃ©rence, width5 va Ãªtre infÃ©rieur Ã  width6, donc on utiliserait â€œlessâ€.\n\nt.test(skull_h$width5, skull_h$width6,\n  alternative = \"less\",\n  paired = TRUE\n)\n\n\n    Paired t-test\n\ndata:  skull_h$width5 and skull_h$width6\nt = -19.72, df = 14, p-value = 6.507e-12\nalternative hypothesis: true mean difference is less than 0\n95 percent confidence interval:\n       -Inf -0.1821371\nsample estimates:\nmean difference \n           -0.2 \n\nwilcox.test(skull_h$width5, skull_h$width6,\n  alternative = \"less\",\n  paired = TRUE\n)\n\nWarning in wilcox.test.default(skull_h$width5, skull_h$width6, alternative =\n\"less\", : cannot compute exact p-value with ties\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  skull_h$width5 and skull_h$width6\nV = 0, p-value = 0.0003597\nalternative hypothesis: true location shift is less than 0\n\n\nPour estimer la puissance dâ€™un test de t avec R, il faut utiliser la fonction power.t.test(). Il faut spÃ©cifier lâ€™argument type = \"paired\", utiliser la moyenne et lâ€™Ã©cart-type de la diffÃ©rence au sein des paires dans les arguments delta et sd.\n\nskull_h$diff &lt;- skull_h$width6 - skull_h$width5\npower.t.test(\n  n = 15,\n  delta = mean(skull_h$diff),\n  sd = sd(skull_h$diff),\n  type = \"paired\"\n)\n\n\n     Paired t test power calculation \n\n              n = 15\n          delta = 0.2\n             sd = 0.03927922\n      sig.level = 0.05\n          power = 1\n    alternative = two.sided\n\nNOTE: n is number of *pairs*, sd is std.dev. of *differences* within pairs",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Comparaison de deux Ã©chantillons</span>"
    ]
  },
  {
    "objectID": "32-t_test.html#rÃ©fÃ©rences",
    "href": "32-t_test.html#rÃ©fÃ©rences",
    "title": "\n5Â  Comparaison de deux Ã©chantillons\n",
    "section": "\n5.6 RÃ©fÃ©rences",
    "text": "5.6 RÃ©fÃ©rences\nBumpus, H.C. (1898) The elimination of the unfit as illustrated by the introduced sparrow, Passer domesticus. Biological Lectures, Woods Hole Biology Laboratory, Woods Hole, 11 th Lecture: 209 - 226.\nNewman, K.J. and H.V. Meredith. (1956) Individual growth in skele- tal bigonial diameter during the childhood period from 5 to 11 years of age. Amer. J. Anat. 99: 157 - 187.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Comparaison de deux Ã©chantillons</span>"
    ]
  },
  {
    "objectID": "33-anova.html",
    "href": "33-anova.html",
    "title": "\n6Â  ANOVA Ã  un critÃ¨re de classification\n",
    "section": "",
    "text": "6.1 Paquets et donnÃ©es requises pour le labo\nCe laboratoire nÃ©cessite:\nlibrary(ggplot2)\nlibrary(car)\nlibrary(multcomp)",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>ANOVA Ã  un critÃ¨re de classification</span>"
    ]
  },
  {
    "objectID": "33-anova.html#set-ano",
    "href": "33-anova.html#set-ano",
    "title": "\n6Â  ANOVA Ã  un critÃ¨re de classification\n",
    "section": "",
    "text": "les paquets R:\n\nggplot2\nmultcomp\ncar\n\n\nles fichiers de donnÃ©es\n\nDam10dat.csv",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>ANOVA Ã  un critÃ¨re de classification</span>"
    ]
  },
  {
    "objectID": "33-anova.html#anova-Ã -un-critÃ¨re-de-classification-et-comparaisons-multiples",
    "href": "33-anova.html#anova-Ã -un-critÃ¨re-de-classification-et-comparaisons-multiples",
    "title": "\n6Â  ANOVA Ã  un critÃ¨re de classification\n",
    "section": "\n6.2 ANOVA Ã  un critÃ¨re de classification et comparaisons multiples",
    "text": "6.2 ANOVA Ã  un critÃ¨re de classification et comparaisons multiples\nLâ€™ANOVA Ã  un critÃ¨re de classification est lâ€™analogue du test de t pour des comparaisons de moyennes de plus de deux Ã©chantillons. Les conditions dâ€™application du test sont essentiellement les mÃªmes, et lorsque appliquÃ© Ã  deux Ã©chantillons ce test est mathÃ©matiquement Ã©quivalent au test de t.\nEn 1961-1962, le barrage Grand Rapids Ã©tait construit sur la riviÃ¨re Saskatchewan en amont de Cumberland House. On croit que durant la construction plusieurs gros esturgeons restÃ¨rent prisonniers dans des sections peu profondes et moururent. Des inventaires de la population dâ€™esturgeons furent faits en 1954, 1958, 1965 et 1966. Au cours de ces inventaires, la longueur Ã  la fourche (frklngth) furent mesurÃ©es (pas nÃ©cessairement sur chaque poisson cependant). Ces donnÃ©es sont dans le fichier Dam10dat.csv.\n\n6.2.1 Visualiser les donnÃ©es\n\nÃ€ partir des donnÃ©es, vous devez dâ€™abord changer le type de donnÃ©e de la variable year, pour que R traite year comme une variable discontinue (factor) plutÃ´t que continue.\n\n\nDam10dat &lt;- read.csv(\"data/Dam10dat.csv\")\nDam10dat$year &lt;- as.factor(Dam10dat$year)\nstr(Dam10dat)\n\n'data.frame':   118 obs. of  21 variables:\n $ year    : Factor w/ 4 levels \"1954\",\"1958\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ fklngth : num  45 50 39 46 54.5 49 42.5 49 56 54 ...\n $ totlngth: num  49 NA 43 50.5 NA 51.7 45.5 52 60.2 58.5 ...\n $ drlngth : logi  NA NA NA NA NA NA ...\n $ drwght  : num  16 20.5 10 17.5 19.7 21.3 9.5 23.7 31 27.3 ...\n $ rdwght  : num  24.5 33 15.5 28.5 32.5 35.5 15.3 40.5 51.5 43 ...\n $ sex     : int  1 1 1 2 1 2 1 1 1 1 ...\n $ age     : int  24 33 17 31 37 44 23 34 33 47 ...\n $ lfkl    : num  1.65 1.7 1.59 1.66 1.74 ...\n $ ltotl   : num  1.69 NA 1.63 1.7 NA ...\n $ ldrl    : logi  NA NA NA NA NA NA ...\n $ ldrwght : num  1.2 1.31 1 1.24 1.29 ...\n $ lrdwght : num  1.39 1.52 1.19 1.45 1.51 ...\n $ lage    : num  1.38 1.52 1.23 1.49 1.57 ...\n $ rage    : int  4 6 3 6 7 7 4 6 6 7 ...\n $ ryear   : int  1954 1954 1954 1954 1954 1954 1954 1954 1954 1954 ...\n $ ryear2  : int  1958 1958 1958 1958 1958 1958 1958 1958 1958 1958 ...\n $ ryear3  : int  1966 1966 1966 1966 1966 1966 1966 1966 1966 1966 ...\n $ location: int  1 1 1 1 1 1 1 1 1 1 ...\n $ girth   : logi  NA NA NA NA NA NA ...\n $ lgirth  : logi  NA NA NA NA NA NA ...\n\n\n\nEnsuite, visualisez les donnÃ©es comme dans le labo pour les tests de t. CrÃ©ez un histogramme avec ligne de densitÃ© et un Box plot par annÃ©e. Que vous rÃ©vÃ¨lent ces donnÃ©es?\n\n\nmygraph &lt;- ggplot(Dam10dat, aes(x = fklngth)) +\n  labs(x = \"Fork length (cm)\") +\n  geom_density() +\n  geom_rug() +\n  geom_histogram(aes(y = ..density..),\n    color = \"black\",\n    alpha = 0.3\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(\n      mean = mean(Dam10dat$fklngth),\n      sd = sd(Dam10dat$fklngth)\n    ),\n    color = \"red\"\n  )\n\n# display graph, by year\nmygraph + facet_wrap(~year, ncol = 2)\n\n\n\nDistribution de la longueur des esturgeons par annÃ©e\n\n\n\n\nboxplot(fklngth ~ year, data = Dam10dat)\n\n\n\nBoxplot de la longueur pas annÃ©ee\n\n\n\nIl semble que la taille des esturgeons est un peu plus petite aprÃ¨s la construction du barrage, mais les donnÃ©es sont trÃ¨s variables et les effets ne sont pas parfaitement clairs. Il y a peut-Ãªtre des problÃ¨mes de normalitÃ© avec les Ã©chantillons de 1954 et 1966, et il y a probablement des valeurs extrÃªmes dans les Ã©chantillons de 1958 et 1966. On va continuer en testant les conditions dâ€™application de lâ€™ANOVA. Il faut dâ€™abord faire lâ€™analyse et examiner les rÃ©sidus.\n\n6.2.2 VÃ©rifier les conditions dâ€™application de lâ€™ANOVA paramÃ©trique\nLâ€™ANOVA paramÃ©trique a trois conditions principales dâ€™application :\n\nles rÃ©sidus sont normalement distribuÃ©s,\nla variance des rÃ©sidus est Ã©gale dans tous les traitements (homoscÃ©dasticitÃ©) et\nles rÃ©sidus sont indÃ©pendants les uns des autres.\n\nCes conditions doivent Ãªtre remplies avant quâ€™on puisse se fier aux rÃ©sultats de lâ€™ANOVA paramÃ©trique.\n\nFaites une ANOVA Ã  un critÃ¨re de classification sur fklngth par annÃ©e et produisez les graphiques diagnostiques\n\n\n# Fit anova model and plot residual diagnostics\nanova.model1 &lt;- lm(fklngth ~ year, data = Dam10dat)\npar(mfrow = c(2, 2))\nplot(anova.model1)\n\n\n\nConditions dâ€™applications de lâ€™ANOVA\n\n\n\n\n\n\n\n\n\nAvertissement\n\n\n\nFaire attention dans le cadre dâ€™une ANOVA Ã  ce que la variable indÃ©pendante soit bien un facteur factor. Si la variable indÃ©pendante est reconnu comme du texte character alors vous nâ€™obtiendrez que 3 graphiques et un message dâ€™erreur du type:\n`hat values (leverages) are all = 0.1\nand there are no factor predictors; no plot no. 5`\n\n\nDâ€™aprÃ¨s les graphiques, on peut douter de la normalitÃ© et de lâ€™homogÃ©nÃ©itÃ© des variances. Notez quâ€™il y a un point qui ressort vraiment avec une forte valeur rÃ©siduelle (cas numÃ©ro 59) et quâ€™il ne sâ€™aligne pas bien avec les autres valeurs: câ€™est la valeur extrÃªme qui avait Ã©tÃ© dÃ©tectÃ©e plus tÃ´t. Ce point fera sans doute gonfler la variance rÃ©siduelle du groupe auquel il appartient.\nDes tests formels nous confirmeront ou infirmeront nos conclusions faites Ã  partir de ces graphiques.\n\nFaites un test de normalitÃ© sur les rÃ©sidus de lâ€™ANOVA.\n\n\nshapiro.test(residuals(anova.model1))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(anova.model1)\nW = 0.91571, p-value = 1.63e-06\n\n\nCe test confirme nos soupÃ§ons: les rÃ©sidus ne sont pas distribuÃ©s normalement. Il faut cependant garder Ã  lâ€™esprit que la puissance est grande et que mÃªme de petites dÃ©viations de la normalitÃ© sont suffisantes pour rejeter lâ€™hypothÃ¨se nulle.\n\nEnsuite, Ã©prouvez lâ€™hypothÃ¨se dâ€™Ã©galitÃ© des variances (homoscedasticitÃ©):\n\n\nleveneTest(fklngth ~ year, data = Dam10dat)\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value  Pr(&gt;F)  \ngroup   3  2.8159 0.04234 *\n      114                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLa valeur de p vous dit que vous pouvez rejeter lâ€™hypothÃ¨se nulle quâ€™il nâ€™y a aucune diffÃ©rence dans les variances entre les annÃ©es. Alors, nous concluons que les variances ne sont pas homogÃ¨nes.\n\n6.2.3 Faire lâ€™ANOVA\n\nFaites une ANOVA de fklnght en choisissant / en prÃ©sumant pour lâ€™instant que les conditions dâ€™application sont suffisamment remplies. Que concluez-vous?\n\n\nsummary(anova.model1)\n\n\nCall:\nlm(formula = fklngth ~ year, data = Dam10dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.2116  -2.6866  -0.7116   2.2103  26.7885 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  48.0243     0.8566  56.061  &lt; 2e-16 ***\nyear1958      0.1872     1.3335   0.140  0.88859    \nyear1965     -5.5077     1.7310  -3.182  0.00189 ** \nyear1966     -3.3127     1.1684  -2.835  0.00542 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.211 on 114 degrees of freedom\nMultiple R-squared:  0.1355,    Adjusted R-squared:  0.1128 \nF-statistic: 5.957 on 3 and 114 DF,  p-value: 0.0008246\n\n\n\n\nCoefficients: Estimates Les 4 coefficients peuvent Ãªtre utilisÃ©s pour obtenir les valeurs prÃ©dites par le modÃ¨le (i.e.Â les moyennes de chaque groupe). La fklngth moyenne de la premiÃ¨re annÃ©e (1954) est 48.0243. Les coefficients pour les 3 autres annÃ©es sont la diffÃ©rence entre la moyenne de lâ€™annÃ©e en question et la moyenne de 1954. La moyenne pour 1965 est 48.0243-5.5077=42.5166. Pour chaque coefficient, on a Ã©galement accÃ¨s Ã  lâ€™erreur-type, une valeur de t et la probabilitÃ© qui lui est associÃ©e (H0 que le coefficient est 0). Les poissons Ã©taient plus petits aprÃ¨s la construction du barrage quâ€™en 1954. Vous devez prendre ces p-valeurs avec un grain de sel, car elles ne sont pas corrigÃ©es pour les comparaisons multiples et. En gÃ©nÃ©ral, je porte peu dâ€™attention Ã  cette partie des rÃ©sultats imprimÃ©s et me concentre sur ce qui suit.\n\nResidual standard error: La racine carrÃ©e de la variance des rÃ©sidus (valeurs observÃ©es moins valeurs prÃ©dites) qui correspond Ã  la variabilitÃ© inexpliquÃ©e par le modÃ¨le (variation de la taille des poissons capturÃ©s la mÃªme annÃ©e).\n\nMutiple R-squared Le R-carrÃ© est la proportion de la variabilitÃ© de la variable dÃ©pendante qui peut Ãªtre expliquÃ©e par le modÃ¨le. Ici, le modÃ¨le explique 13.5% de la variabilitÃ©. Les diffÃ©rences de taille dâ€™une annÃ©e Ã  lâ€™autre sont relativement petites lorsquâ€™on les compare Ã  la variation de taille entre les poissons capturÃ©s la mÃªme annÃ©e.\n\n\n\nF-Statistic La p-valeur associÃ©e au test â€œomnibusâ€ que toutes les moyennes sont Ã©gales. Ici, p est beaucoup plus petit que 0.05 et on rejetterait H0 pour conclure que fklngth varie selon les annÃ©es.\n\nLa commande anova() produit le tableau dâ€™ANOVA standard qui contient la plupart de cette information:\n\nanova(anova.model1)\n\nAnalysis of Variance Table\n\nResponse: fklngth\n           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nyear        3  485.26 161.755  5.9574 0.0008246 ***\nResiduals 114 3095.30  27.152                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLa variabilitÃ© totale de fklngth, mesurÃ©e par la somme des carrÃ©s des Ã©carts (Sum sq) est partitionnÃ©e en ce qui peut Ãªtre expliquÃ© par lâ€™annÃ©e (485.26) et la variabilitÃ© rÃ©siduelle inexpliquÃ©e (3095.30). Lâ€™annÃ©e explique bien (485.26/(3095.30+485.26)=.1355 or 13.55% de la variabilitÃ©). Le carrÃ© moyen des rÃ©sidus (Residual Mean Sq) est leur variance.\n\n6.2.4 Les comparaisons multiples\n\nLa fonction pairwise.t.test() peut Ãªtre utilisÃ©e pour comparer des moyennes et ajuster (ou non, si dÃ©sirÃ©) les probabilitÃ©s pour le nombre de comparaisons en utilisant lâ€™une des options pour p.adj:\n\nCompare toutes les moyennes sans ajuster les probabilitÃ©s\n\npairwise.t.test(Dam10dat$fklngth, Dam10dat$year,\n  p.adj = \"none\"\n)\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  Dam10dat$fklngth and Dam10dat$year \n\n     1954   1958   1965  \n1958 0.8886 -      -     \n1965 0.0019 0.0022 -     \n1966 0.0054 0.0079 0.1996\n\nP value adjustment method: none \n\n\nOption bonf ajuste les p-valeurs avec la correction de Bonferroni. Ici, il y a 6 valeurs de p calculÃ©es, et la correction de Bonferroni revient Ã  simplement multiplier la p-valeur par 6 (sauf si le rÃ©sultat est supÃ©rieur Ã  1. Si tel est le cas, la p-value ajustÃ©e est 1).\n\npairwise.t.test(Dam10dat$fklngth, Dam10dat$year,\n  p.adj = \"bonf\"\n)\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  Dam10dat$fklngth and Dam10dat$year \n\n     1954  1958  1965 \n1958 1.000 -     -    \n1965 0.011 0.013 -    \n1966 0.033 0.047 1.000\n\nP value adjustment method: bonferroni \n\n\nOption â€œholmâ€ is est la correction sÃ©quentielle de Bonferroni dans laquelle les p-valeurs sont ordonnÃ©es de (i=1) la plus faible Ã  (N) la plus grande. La correction pour les p-valeurs est (N-i+1). Ici, il y a N=6 paires de moyennes qui sont comparÃ©es. La plus petite valeur de p non corrigÃ©e est 0.0019 pour 1954 vs 1965. La p-valeur corrigÃ©e est donc \\(0.0019*(6-1+1)=0.011\\). La seconde plus petite p-valeur est 0.0022. Sa p-valeur corrigÃ©e est 0.0022*(6-2+1)=0.011. Pour la p-valeur la plus Ã©levÃ©e, la correction est (N-N+1)=1, donc la p-valeur corrigÃ©e est Ã©gale Ã  la p-valeur brute.\n\npairwise.t.test(Dam10dat$fklngth, Dam10dat$year,\n  p.adj = \"holm\"\n)\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  Dam10dat$fklngth and Dam10dat$year \n\n     1954  1958  1965 \n1958 0.889 -     -    \n1965 0.011 0.011 -    \n1966 0.022 0.024 0.399\n\nP value adjustment method: holm \n\n\nLâ€™option â€œfdrâ€ sert Ã  contrÃ´ler le â€œfalse discovery rateâ€.\n\npairwise.t.test(Dam10dat$fklngth, Dam10dat$year,\n  p.adj = \"fdr\"\n)\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  Dam10dat$fklngth and Dam10dat$year \n\n     1954   1958   1965  \n1958 0.8886 -      -     \n1965 0.0066 0.0066 -     \n1966 0.0108 0.0119 0.2395\n\nP value adjustment method: fdr \n\n\nLes quatre mÃ©thodes mÃ¨nent ici Ã  la mÃªme conclusion: les poissons sont plus gros aprÃ¨s la construction du barrage et toutes les comparaisons entre les annÃ©es 50 et 60 sont significatives alors que les diffÃ©rences entre 54 et 58 ou 65 et 66 ne le sont pas. La conclusion ne dÃ©pend pas du choix de mÃ©thode.\nDans dâ€™autres situations, vous pourriez obtenir des rÃ©sultats contradictoires. Alors, quelle mÃ©thode choisir? Les p-valeurs qui ne sont pas corrigÃ©es sont certainement suspectes lorsquâ€™il y a plusieurs comparaisons. Dâ€™un autre cotÃ©, la correction de Bonferroni est conservatrice et le devient encore plus lorsquâ€™il y a de trÃ¨s nombreuses comparaisons. Des travaux rÃ©cents suggÃ¨rent que la correction fdr est un bon compromis lorsquâ€™il y a beaucoup de comparaisons.\nLa mÃ©thode de Tukey est lâ€™une des plus populaires et est facile Ã  utiliser en R (notez cependant quâ€™il y a un petit bug qui se manifeste quand la variable indÃ©pendante peut ressembler Ã  un nombre plutÃ´t quâ€™un facteur, ce qui explique la petite pirouette avec paste0 dans le code):\n\nDam10dat$myyear &lt;- as.factor(paste0(\"m\", Dam10dat$year))\nTukeyHSD(aov(fklngth ~ myyear, data = Dam10dat))\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = fklngth ~ myyear, data = Dam10dat)\n\n$myyear\n                  diff        lwr        upr     p adj\nm1958-m1954  0.1872141  -3.289570  3.6639986 0.9990071\nm1965-m1954 -5.5076577 -10.021034 -0.9942809 0.0100528\nm1966-m1954 -3.3126964  -6.359223 -0.2661701 0.0274077\nm1965-m1958 -5.6948718 -10.436304 -0.9534397 0.0116943\nm1966-m1958 -3.4999106  -6.875104 -0.1247171 0.0390011\nm1966-m1965  2.1949612  -2.240630  6.6305526 0.5710111\n\n\n\nplot(TukeyHSD(aov(fklngth ~ myyear, data = Dam10dat)))\n\n\n\nDiffÃ©rence anuelles dans la longueur des esturgeons\n\n\n\nLes intervalles de confiance, corrigÃ©s pour les comparaisons multiples par la mÃ©thode de Tukey, sont illustrÃ©s pour les diffÃ©rences entre annÃ©es. Malheureusement les lÃ©gendes ne sont pas complÃ¨tes, mais lâ€™ordre est le mÃªme que dans le tableau prÃ©cÃ©dent.\nLe package multcomp peut produire de meilleurs graphiques, mais requiert un peu plus de code:\n\n# Alternative way to compute Tukey multiple comparisons\n# set up a one-way ANOVA\nanova.fkl.vs.year &lt;- aov(aov(fklngth ~ myyear, data = Dam10dat))\n# set up all-pairs comparisons for factor `year'\n\nmeandiff &lt;- glht(anova.fkl.vs.year, linfct = mcp(\n  myyear =\n    \"Tukey\"\n))\nconfint(meandiff)\n\n\n     Simultaneous Confidence Intervals\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: aov(formula = aov(fklngth ~ myyear, data = Dam10dat))\n\nQuantile = 2.5934\n95% family-wise confidence level\n \n\nLinear Hypotheses:\n                   Estimate lwr      upr     \nm1958 - m1954 == 0   0.1872  -3.2710   3.6455\nm1965 - m1954 == 0  -5.5077  -9.9970  -1.0184\nm1966 - m1954 == 0  -3.3127  -6.3430  -0.2824\nm1965 - m1958 == 0  -5.6949 -10.4110  -0.9787\nm1966 - m1958 == 0  -3.4999  -6.8571  -0.1427\nm1966 - m1965 == 0   2.1950  -2.2170   6.6069\n\nplot(meandiff)\n\n\n\nDiffÃ©rence anuelles dans la longueur des esturgeons\n\n\n\nCâ€™est un peu mieux, mais ce qui le serait encore plus câ€™est un graphique des moyennes, avec leurs intervalles de confiance ajustÃ©s pour les comparaisons multiples:\n\n# Compute and plot means and Tukey CI\nmeans &lt;- glht(\n  anova.fkl.vs.year,\n  linfct = mcp(myyear = \"Tukey\")\n)\ncimeans &lt;- cld(means)\n# use sufficiently large upper margin\n# plot\nold.par &lt;- par(mai = c(1, 1, 1.25, 1))\nplot(cimeans)\n\n\n\nDiffÃ©rence anuelles dans la longueur des esturgeons\n\n\n\nNotez les lettres au dessus du graphique: les annÃ©es Ã©tiquetÃ©es avec la mÃªme lettre ne diffÃ¨rent pas significativement lâ€™une de lâ€™autre.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>ANOVA Ã  un critÃ¨re de classification</span>"
    ]
  },
  {
    "objectID": "33-anova.html#transformations-de-donnÃ©es-et-anova-non-paramÃ©trique",
    "href": "33-anova.html#transformations-de-donnÃ©es-et-anova-non-paramÃ©trique",
    "title": "\n6Â  ANOVA Ã  un critÃ¨re de classification\n",
    "section": "\n6.3 Transformations de donnÃ©es et ANOVA non-paramÃ©trique",
    "text": "6.3 Transformations de donnÃ©es et ANOVA non-paramÃ©trique\nDans lâ€™exemple prÃ©cÃ©dent sur les diffÃ©rences annuelles de la variable fklgnth, on a notÃ© que les conditions dâ€™application de lâ€™ANOVA nâ€™Ã©taient pas remplies. Si les donnÃ©es ne remplissent pas les conditions de lâ€™ANOVA paramÃ©trique, il y a 3 options :\n\nNe rien faire. Si les effectifs dans chaque groupe sont grands, on peut relaxer les conditions dâ€™application car lâ€™ANOVA est alors assez robuste aux violations de normalitÃ© (mais moins aux violations dâ€™homoscedasticitÃ©),\non peut transformer les donnÃ©es\non peut faire une analyse non-paramÃ©trique.\n\n\nRefaites lâ€™ANOVA de la section prÃ©cÃ©dente aprÃ¨s avoir transformÃ© en faisant le logarithme Ã  la base de 10. Avec les donnÃ©es transformÃ©es, est-ce que les problÃ¨mes qui avaient Ã©tÃ© identifiÃ©s disparaissent ?\n\n\n# Fit anova model on log10 of fklngth and plot residual diagnostics\npar(mfrow = c(2, 2))\nanova.model2 &lt;- lm(log10(fklngth) ~ year, data = Dam10dat)\nplot(anova.model2)\n\n\n\nConditions dâ€™application de lâ€™ANOVA\n\n\n\nLes graphiques diagnostiques des rÃ©sidus donnent:\nLes graphiques sont Ã  peine mieux ici. Si on fait le test Wilk-Shapiro sur les rÃ©sidus, on obtient:\n\nshapiro.test(residuals(anova.model2))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(anova.model2)\nW = 0.96199, p-value = 0.002048\n\n\nAlors, on a toujours des problÃ¨mes avec la normalitÃ© et on est juste sur le seuil de dÃ©cision pour lâ€™Ã©galitÃ© des variances. Vous avez le choix Ã  ce point:\n\nessayer de trouver une autre transformation pour mieux rencontrer les conditions dâ€™application\nassumer que les donnÃ©es sont rencontrent suffisamment les conditions dâ€™application\nfaire une ANOVA non-paramÃ©trique.\n\n\nLâ€™analogue non-paramÃ©trique de lâ€™ANOVA Ã  un critÃ¨re de classification le plus employÃ© est le test de Kruskall-Wallis. Faites ce test sur fklngth et comparez les rÃ©sultats Ã  ceux de lâ€™analyse paramÃ©trique. Que concluez-vous?\n\n\nkruskal.test(fklngth ~ year, data = Dam10dat)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  fklngth by year\nKruskal-Wallis chi-squared = 15.731, df = 3, p-value = 0.001288\n\n\nLa conclusion est donc la mÃªme quâ€™avec lâ€™ANOVA paramÃ©trique: on rejette lâ€™hypothÃ¨se nulle que le rang moyen est le mÃªme pour chaque annÃ©e. Donc, mÃªme si les conditions dâ€™application de lâ€™analyse paramÃ©trique nâ€™Ã©taient pas parfaitement rencontrÃ©es, les conclusions sont les mÃªmes, ce qui illustre la robustesse de lâ€™ANOVA paramÃ©trique.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>ANOVA Ã  un critÃ¨re de classification</span>"
    ]
  },
  {
    "objectID": "33-anova.html#examen-des-valeurs-extrÃªmes",
    "href": "33-anova.html#examen-des-valeurs-extrÃªmes",
    "title": "\n6Â  ANOVA Ã  un critÃ¨re de classification\n",
    "section": "\n6.4 Examen des valeurs extrÃªmes",
    "text": "6.4 Examen des valeurs extrÃªmes\nVous devriez avoir remarquÃ© au cours des analyses prÃ©cÃ©dentes quâ€™il y avait peut-Ãªtre des valeurs extrÃªmes dans les donnÃ©es. Ces points Ã©taient Ã©vidents dans le Box Plot de fklngth by year et ont Ã©tÃ© notÃ©s comme les points 59, 23, et 87 dans les diagrammes de probabilitÃ© des rÃ©sidus et dans le diagramme de dispersion des rÃ©sidus et des valeurs estimÃ©es. En gÃ©nÃ©ral, vous devez avoir de trÃ¨s bonnes raisons pour enlever des valeurs extrÃªmes de la base de donnÃ©es (i.e.Â vous savez quâ€™il y a eu une erreur avec un cas). Cependant, il est quand mÃªme toujours valable de voir comment lâ€™analyse change en enlevant des valeurs extrÃªmes de la base de donnÃ©es.\n\nRÃ©pÃ©tez lâ€™ANOVA originale sur fklngth et year mais faites le avec un sous-ensemble de donnÃ©es sans les valeurs extrÃªmes. Est-ce que les conclusions ont changÃ©?\n\n\nDamsubset &lt;- Dam10dat[-c(23, 59, 87), ] # removes obs 23, 59 and 87\naov.Damsubset &lt;- aov(fklngth ~ as.factor(year), Damsubset)\nsummary(aov.Damsubset)\n\n                 Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nas.factor(year)   3  367.5  122.50   6.894 0.000267 ***\nResiduals       111 1972.4   17.77                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nshapiro.test(residuals(aov.Damsubset))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(aov.Damsubset)\nW = 0.98533, p-value = 0.2448\n\n\n\nleveneTest(fklngth ~ year, Damsubset)\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value   Pr(&gt;F)   \ngroup   3  4.6237 0.004367 **\n      111                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLâ€™Ã©limination de trois valeurs extrÃªmes amÃ©liore un peu les choses, mais ce nâ€™est pas parfait. On a toujours une problÃ¨me avec les variances, mais les rÃ©sidus sont maintenant normaux. Cependant, le fait que la conclusion quâ€™on tire de lâ€™ANOVA originale ne change pas en enlevant les points renforce le fait quâ€™on nâ€™a pas une bonne raison pour enlever les points.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>ANOVA Ã  un critÃ¨re de classification</span>"
    ]
  },
  {
    "objectID": "33-anova.html#test-de-permutation",
    "href": "33-anova.html#test-de-permutation",
    "title": "\n6Â  ANOVA Ã  un critÃ¨re de classification\n",
    "section": "\n6.5 Test de permutation",
    "text": "6.5 Test de permutation\nCommande R pour un test de permutation dâ€™une ANOVA Ã  un critÃ¨re de classification.\n\n#############################################################\n# Permutation Test for one-way ANOVA\n# modified from code written by David C. Howell\n# http://www.uvm.edu/~dhowell/StatPages/More_Stuff/Permutation%20Anova/PermTestsAnova.html\n# set desired number of permutations\nnreps &lt;- 500\n# to simplify reuse of this code, copy desired dataframe to mydata\nmydata &lt;- Dam10dat\n# copy model formula to myformula\nmyformula &lt;- as.formula(\"fklngth ~ year\")\n# copy dependent variable vector to mydep\nmydep &lt;- mydata$fklngth\n# copy independent variable vector to myindep\nmyindep &lt;- as.factor(mydata$year)\n################################################\n# You should not need to modify code chunk below\n################################################\n# Compute observed F value for original sample\nmod1 &lt;- lm(myformula, data = mydata) # Standard Anova\nANOVA &lt;- summary(aov(mod1)) # Save summary to variable\nobservedF &lt;- ANOVA[[1]]$\"F value\"[1] # Save observed F value\n# Print standard ANOVA results\ncat(\n  \" The standard ANOVA for these data follows \",\n  \"\\n\"\n)\n\nprint(ANOVA, \"\\n\")\ncat(\"\\n\")\ncat(\"\\n\")\nprint(\"Resampling as in Manly with unrestricted sampling of observations. \")\n\n# Now start resampling\nFboot &lt;- numeric(nreps) # initalize vector to receive permuted\nvalues\nFboot[1] &lt;- observedF\nfor (i in 2:nreps) {\n  newdependent &lt;- sample(mydep, length(mydep)) # randomize dep\n  var\n  mod2 &lt;- lm(newdependent ~ myindep) # refit model\n  b &lt;- summary(aov(mod2))\n  Fboot[i] &lt;- b[[1]]$\"F value\"[1] # store F stats\n}\npermprob &lt;- length(Fboot[Fboot &gt;= observedF]) / nreps\ncat(\n  \" The permutation probability value is: \", permprob,\n  \"\\n\"\n)\n# end of code chunk for permutation\n\nVersion lmPerm du test de permutation.\n\n## lmPerm version of permutation test\nlibrary(lmPerm)\n# for generality, copy desired dataframe to mydata\n# and model formula to myformula\nmydata &lt;- Dam10dat\nmyformula &lt;- as.formula(\"fklngth ~ year\")\n# Fit desired model on the desired dataframe\nmymodel &lt;- lm(myformula, data = mydata)\n# Calculate permutation p-value\nanova(lmp(myformula, data = mydata, perm = \"Prob\", center = FALSE, Ca = 0.001))",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>ANOVA Ã  un critÃ¨re de classification</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html",
    "href": "34-anova_mult.html",
    "title": "\n7Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "",
    "text": "7.1 Paquets et donnÃ©es requises pour le labo\nCe laboratoire nÃ©cessite:\nlibrary(multcomp)\nlibrary(car)\nlibrary(tidyverse)",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html#set-anomul",
    "href": "34-anova_mult.html#set-anomul",
    "title": "\n7Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "",
    "text": "les paquets R:\n\nmulticomp\ncar\ntidyverse\n\n\nles fichiers de donnÃ©es\n\nStu2wdat.csv\nStu2mdat.csv\nnr2wdat.csv\nnestdat.csv\nwmcdat2.csv\nwmc2dat2.csv",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html#plan-factoriel-Ã -deux-facteurs-de-classification-et-rÃ©plication",
    "href": "34-anova_mult.html#plan-factoriel-Ã -deux-facteurs-de-classification-et-rÃ©plication",
    "title": "\n7Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "\n7.2 Plan factoriel Ã  deux facteurs de classification et rÃ©plication",
    "text": "7.2 Plan factoriel Ã  deux facteurs de classification et rÃ©plication\nIl est frÃ©quent de vouloir analyser lâ€™effet de plusieurs facteurs simultanÃ©ment. Lâ€™ANOVA factorielle Ã  deux critÃ¨res de classification permet dâ€™examiner deux facteurs Ã  la fois, mais la mÃªme approche peut Ãªtre utilisÃ©e pour 3, 4 ou mÃªme 5 facteurs quoique lâ€™interprÃ©tation des rÃ©sultats devienne beaucoup plus complexe.\nSupposons que vous Ãªtes intÃ©ressÃ©s par lâ€™effet de deux facteurs : site (location, Cumberland House ou The Pas) et sexe (sex, mÃ¢le ou femelle) sur la taille des esturgeons. Comme lâ€™effectif nâ€™est pas le mÃªme pour tous les groupes, câ€™est un plan qui nâ€™est pas balancÃ©. Notez aussi quâ€™il y a des valeurs manquantes pour certaines variables, ce qui veut dire que chaque mesure nâ€™a pas Ã©tÃ© effectuÃ©e sur chaque poisson.\n\n7.2.1 ANOVA Ã  effets fixes\n\nExaminez dâ€™abord les donnÃ©es en faisant des box plots de rdwght pour sex et location des donnÃ©es du fichier Stu2wdat.csv .\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nStu2wdat &lt;- read.csv(\"data/Stu2wdat.csv\")\n\nggplot(Stu2wdat, aes(x = sex, y = rdwght)) +\ngeom_boxplot(notch = TRUE) +\nfacet_grid(~location)\n\nWarning: Removed 4 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\nLes graphiques montrent quâ€™aux deux sites les femelles sont probablement plus grandes que les mÃ¢les, mais que les tailles ne varient pas beaucoup dâ€™un site Ã  lâ€™autre. La prÃ©sence de valeurs extrÃªmes sur ces graphiques suggÃ¨re quâ€™il y aura peut-Ãªtre des problÃ¨mes avec la condition de normalitÃ© des rÃ©sidus.\n\nGÃ©nÃ©rez les statistiques sommaires pour RDWGHT par sex et Location.\n\n\nStu2wdat %&gt;%\n  group_by(sex, location) %&gt;%\n  summarise(\n    mean = mean(rdwght, na.rm = TRUE), sd = sd(rdwght, na.rm = TRUE), n = n()\n  )\n\n`summarise()` has grouped output by 'sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 4 Ã— 5\n# Groups:   sex [2]\n  sex            location        mean    sd     n\n  &lt;chr&gt;          &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 \"FEMALE      \" \"CUMBERLAND  \"  27.4  9.33    51\n2 \"FEMALE      \" \"THE_PAS     \"  28.0 12.5     55\n3 \"MALE        \" \"CUMBERLAND  \"  22.1  4.79    34\n4 \"MALE        \" \"THE_PAS     \"  20.6  9.92    46\n\n\nCes rÃ©sultats supportent lâ€™interprÃ©tation des box plots: Les femelles sont plus grosses que les mÃ¢les, et la diffÃ©rence de taille entre les deuxsites sont petites.\n\nÃ€ lâ€™aide du fichier Stu2wdat.csv faites une ANOVA factorielle Ã  deux critÃ¨res de classification:\n\n\n# Fit anova model and plot residual diagnostics\n# but first, save current par and set graphic page to hold 4 graphs\nopar &lt;- par(mfrow = c(2, 2))\nanova.model1 &lt;- lm(rdwght ~ sex + location + sex:location,\n  contrasts = list(sex = contr.sum, location = contr.sum),\n  data = Stu2wdat\n)\nanova(anova.model1)\n\nAnalysis of Variance Table\n\nResponse: rdwght\n              Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nsex            1  1839.6 1839.55 18.6785 2.569e-05 ***\nlocation       1     4.3    4.26  0.0433    0.8355    \nsex:location   1    48.7   48.69  0.4944    0.4829    \nResiduals    178 17530.4   98.49                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nAvertissement\n\n\n\nAttention, R imprime les sommes des carrÃ©s sÃ©quentielles (Type I) les carrÃ©s moyens et probabilitÃ©s associÃ©s. Vous ne pouvez pas vous y fier si votre plan dâ€™expÃ©rience nâ€™est pas parfaitement balancÃ©. Dans cet exemple, le nombre de poissons capturÃ©s change selon le site et le sexe et le plan dâ€™expÃ©rience nâ€™est donc pas balancÃ©.\n\n\nVous devez extraire les sommes de carrÃ©s partielles (Type III). Le moyen le plus simple que jâ€™ai trouvÃ© est dâ€™utiliser la fonction Anova()du package car (notez la diffÃ©rence subtile, Anova() nâ€™est pas la mÃªme chose que anova(), R est impitoyable et distingue les majuscules des minuscules). Malheureusement, Anova() ne suffit pas; il faut Ã©galement spÃ©cifier le type de contraste dans le modÃ¨le aveclâ€™argument contrasts = list(sex = contr.sum,location = contr.sum)\n\nlibrary(car)\nAnova(anova.model1, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: rdwght\n             Sum Sq  Df   F value    Pr(&gt;F)    \n(Intercept)  106507   1 1081.4552 &lt; 2.2e-16 ***\nsex            1745   1   17.7220 4.051e-05 ***\nlocation          9   1    0.0891    0.7656    \nsex:location     49   1    0.4944    0.4829    \nResiduals     17530 178                        \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSuite Ã  lâ€™ANOVA, on accepte deux hypothÃ¨ses nulles: (1) que lâ€™effet du sexe ne varie pas entre les sites (pas dâ€™interaction significative) et (2) quâ€™il nâ€™y a pas de diffÃ©rence de taille des esturgeons (peu importe le sexe) entre les deux sites. Dâ€™un autre cotÃ©, on rejette lâ€™hypothÃ¨se nulle quâ€™il nâ€™y a pas de diffÃ©rence de taille entre les esturgeons mÃ¢les et les femelles, tel que suggÃ©rÃ© par les graphiques.\n\npar(mfrow = c(2, 2))\nplot(anova.model1)\n\n\n\nConditions dâ€™application ANOVA model1\n\n\n\nCependant, on ne peut se fier Ã  ces rÃ©sultats sans vÃ©rifier si les conditions dâ€™application de lâ€™ANOVA Ã©taient remplies. Un examen des graphiques des rÃ©sidus, en haut, montre que les rÃ©sidus semblent Ãªtre distribuÃ©s plus ou moins normalement, si ce nâ€™est des 3 valeurs extrÃªmes qui sont notÃ©es sur le diagramme de probabilitÃ© (cas 101, 24,& 71). Dâ€™aprÃ¨s le graphique des rÃ©sidus vs les valeurs prÃ©dites, on voit que lâ€™Ã©tendue des rÃ©sidus est plus ou moins Ã©gale pour les valeurs estimÃ©es, sauf encore pour 2 ou 3 cas. Si on Ã©prouve la normalitÃ©, on obtient:\n\nshapiro.test(residuals(anova.model1))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(anova.model1)\nW = 0.87213, p-value = 2.619e-11\n\n\nAlors, il y a Ã©vidence que les rÃ©sidus ne sont pas distribuÃ©s normalement.\nNous allons utiliser le test de Levene pour examiner lâ€™homoscÃ©dasticitÃ© des rÃ©sidus, de la mÃªme faÃ§on quâ€™on a fait pour lâ€™ANOVA Ã  un critÃ¨re de classification.\n\nlibrary(car)\nleveneTest(rdwght ~ sex * location, data = Stu2wdat)\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value  Pr(&gt;F)  \ngroup   3  3.8526 0.01055 *\n      178                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSi les rÃ©sidus Ã©taient homoscÃ©dastiques, on accepterait lâ€™hypothÃ¨se nulle que le absres moyen ne varie pas entre les niveaux de sexe et location (i.e., sexloc). Le tableau dâ€™ANOVA ci-dessus montre que lâ€™hypothÃ¨se est rejetÃ©e. Il y a donc Ã©vidence dâ€™hÃ©tÃ©roscÃ©dasticitÃ©. En bref, nous avons donc plusieurs conditions dâ€™application qui ne sont pas respectÃ©es. La question qui reste est: ces violations sont-elles suffisantes pour invalider nos conclusions ?\n\n\n\n\n\n\nExercice\n\n\n\nRÃ©pÃ©tez la mÃªme analyse avec les donnÃ©es du fichier stu2mdat.csv . Que concluez-vous? Supposons que vous vouliez comparer la taille des mÃ¢les et des femelles. Comment cette comparaison diffÃ¨re entre les deux ensembles de donnÃ©es ?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nStu2mdat &lt;- read.csv(\"data/Stu2mdat.csv\")\nanova.model2 &lt;- lm(\n  formula = rdwght ~ sex + location + sex:location,\n  contrasts = list(sex = contr.sum, location = contr.sum),\n  data = Stu2mdat\n)\nsummary(anova.model2)\nAnova(anova.model2, type = 3)\n\n\n\n\n\n\n\nCall:\nlm(formula = rdwght ~ sex + location + sex:location, data = Stu2mdat, \n    contrasts = list(sex = contr.sum, location = contr.sum))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.917  -6.017  -0.580   4.445  65.743 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     24.5346     0.7461  32.885  &lt; 2e-16 ***\nsex1            -0.5246     0.7461  -0.703    0.483    \nlocation1        0.2227     0.7461   0.299    0.766    \nsex1:location1   3.1407     0.7461   4.210 4.05e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.924 on 178 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared:  0.09744,   Adjusted R-squared:  0.08223 \nF-statistic: 6.405 on 3 and 178 DF,  p-value: 0.0003817\n\n\nNotez que cette fois les femelles sont plus grandes que les mÃ¢les Ã  Cumberland House, mais que câ€™est le contraire Ã  The Pas. Quel est le rÃ©sultat de lâ€™ANOVA (nâ€™oubliez pas quâ€™il faut des Type III sums of squares pour les rÃ©sultats)?\n\n\nAnova Table (Type III tests)\n\nResponse: rdwght\n             Sum Sq  Df   F value    Pr(&gt;F)    \n(Intercept)  106507   1 1081.4552 &lt; 2.2e-16 ***\nsex              49   1    0.4944    0.4829    \nlocation          9   1    0.0891    0.7656    \nsex:location   1745   1   17.7220 4.051e-05 ***\nResiduals     17530 178                        \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDans ce cas, le terme de lâ€™interaction (sex:location) est maintenant significatif mais les effets principaux ne le sont pas.\n\nVous trouverez utile ici de crÃ©er des graphiques pour les deux fichiers de donnÃ©es pour comparer les interactions entre sex et location. Le graphique dâ€™interaction montre les relations entre les moyennes de chaque combinaison de facteurs (appelÃ©es aussi les moyennes des ce$lules).GÃ©nÃ©rez un graphique illustrant les intÃ©ractions en utilisant la fonction allEffects du package effects :\n\n\nlibrary(effects)\n\nlattice theme set by effectsTheme()\nSee ?effectsTheme for details.\n\nallEffects(anova.model1)\n\n model: rdwght ~ sex + location + sex:location\n\n sex*location effect\n              location\nsex            CUMBERLAND   THE_PAS     \n  FEMALE           27.37347     27.97717\n  MALE             22.14118     20.64652\n\nplot(allEffects(anova.model1), \"sex:location\")\n\n\n\nEffet du sexe et du lieu sur le poids des esturgeons\n\n\n\n\nallEffects(anova.model2)\n\n model: rdwght ~ sex + location + sex:location\n\n sex*location effect\n              location\nsex            CUMBERLAND   THE_PAS     \n  FEMALE           27.37347     20.64652\n  MALE             22.14118     27.97717\n\nplot(allEffects(anova.model2), \"sex:location\")\n\n\n\nEffet du sexe et du lieu sur le poids des esturgeons\n\n\n\nIl y a une diffÃ©rence importante entre les rÃ©sultats obtenus avec stu2wdat et stu2mdat. Dans le premier cas, puisquâ€™il nâ€™y a pas dâ€™interaction, on peut regrouper les donnÃ©es des deux niveaux dâ€™un facteur (le site, par exemple) pour Ã©prouver lâ€™hypothÃ¨se dâ€™un effet de lâ€™autre facteur (le sexe). En fait, si on fait cela et que lâ€™on calcule une ANOVA Ã  un critÃ¨re de classification (sex), on obtient:\n\nAnova(aov(rdwght ~ sex, data = Stu2wdat), type = 3)\n\nAnova Table (Type III tests)\n\nResponse: rdwght\n            Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept)  78191   1 800.440 &lt; 2.2e-16 ***\nsex           1840   1  18.831 2.377e-05 ***\nResiduals    17583 180                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNotez que la somme des carrÃ©s des rÃ©sidus (17583) est presque Ã©gale Ã  celle du modÃ¨le complet (17530) de lâ€™ANOVA factorielle Ã  deux facteurs. Câ€™est parce que dans cette anova factorielle, le terme dâ€™interaction et le terme reprÃ©sentant lâ€™effet du site nâ€™expliquent quâ€™une partie infime de la variabilitÃ©. Dâ€™un autre cotÃ©, si on essaie le mÃªme truc avec stu2mdat, on obtient:\n\nAnova(aov(rdwght ~ sex, data = Stu2mdat), type = 3)\n\nAnova Table (Type III tests)\n\nResponse: rdwght\n            Sum Sq  Df  F value Pr(&gt;F)    \n(Intercept)  55251   1 515.0435 &lt;2e-16 ***\nsex            113   1   1.0571 0.3053    \nResiduals    19309 180                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIci la somme des carrÃ©es des rÃ©sidus (19309) est beaucoup plus grande que celle de lâ€™ANOVA factorielle (175306) parce quâ€™une partie importante de la variabilitÃ© expliquÃ©e par le modÃ¨le est associÃ©e Ã  lâ€™interaction. Notez que si on nâ€™avait fait que cette analyse, on conclurait que les esturgeons mÃ¢les et femelles ont la mÃªme taille. Mais en fait leur taille diffÃ¨re; seulement la diffÃ©rence est Ã  lâ€™avantage des mÃ¢les Ã  un site et Ã  lâ€™avantage des femelles Ã  lâ€™autre. Il est donc dÃ©licat dâ€™interprÃ©ter lâ€™effet principal (sexe) en prÃ©sence dâ€™une interaction significativeâ€¦\n\n7.2.2 ANOVA Ã  effets mixtes\nLes analyses qui prÃ©cÃ¨dent nÃ©gligent un point important: location pourrait Ãªtre traitÃ© comme un facteur alÃ©atoire et sex est fixe. Par consÃ©quent le modÃ¨le appropriÃ© dâ€™ANOVA est de type mixte.\nNotez que dans toutes les analyses qui prÃ©cÃ¨dent, R a traitÃ© cette ANOVA comme si elle etait de type effet fixe seulement, et les termes principaux et celui dâ€™interaction ont Ã©tÃ© testÃ©s en utilisant le carrÃ© moyen des rÃ©sidus comme dÃ©nominateur des tests de F. Cependant, pour une ANOVA de type mixte, ces effets devraient Ãªtre testÃ©s en utilisant le carrÃ© moyen du terme dâ€™interaction, ou en combinant la somme des carrÃ©s de lâ€™erreur et de lâ€™interaction (selon le statisticien consultÃ©!).\nEn utilisant Stu2wdat, refaites un tableau dâ€™ANOVA pour RDWGHT en considÃ©rant location comme facteur alÃ©atoire et sex comme un facteur fixe. Pour ce faire, vous devrez recalculer les valeurs de F pour sex et location en utilisant le carrÃ© moyen de lâ€™interaction sex:location au lieu du carrÃ© moyen des rÃ©sidus comme dÃ©nominateur. Le mieux câ€™est de le faire Ã  la mitaine ent travaillant avec les Type III Sums of squares du tableau dâ€™ANOVA.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nAnova(anova.model1, type = 3)\n\n\n\n\n\n\nAnova Table (Type III tests)\n\nResponse: rdwght\n             Sum Sq  Df   F value    Pr(&gt;F)    \n(Intercept)  106507   1 1081.4552 &lt; 2.2e-16 ***\nsex            1745   1   17.7220 4.051e-05 ***\nlocation          9   1    0.0891    0.7656    \nsex:location     49   1    0.4944    0.4829    \nResiduals     17530 178                        \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPour sex, la nouvelle valeur de F (le rapport des carrÃ©s moyens) est de\n\\[F = \\frac{(1745/1)}{(49/1)} = 35.6\\]\nPour obtenir la valeur de p correspondant Ã  cette statistique F, il faut utilisez la fonction de probabilitÃ© de la distribtuion de F pf(F, df1, df2, lower.tail = FALSE), oÃ¹ F est la valeur de F calculÃ©e, et df1 et df2 sont les degrÃ©s de libertÃ© du numÃ©rateur (sex) et dÃ©nominateur(SEX:location).\n\npf(35.6, 1, 1, lower.tail = FALSE)\n\n[1] 0.1057152\n\n\nNotez que maintenant la valeur de p pour sex nâ€™est plus significative. Câ€™est parce que le carrÃ© moyen de lâ€™erreur dans lâ€™ANOVA initiale est plus petit que celui associÃ© Ã  lâ€™interaction, mais surtout parce que le nombre de degrÃ©s de libertÃ© pour le dÃ©nominateur du test de F est passÃ© de 178 Ã  1 seulement. En gÃ©nÃ©ral, câ€™est beaucoup plus difficile dâ€™obtenir des rÃ©sultats significatifs quand les degrÃ©s de libertÃ© pour le dÃ©nominateur sont petits.\n\n\n\n\n\n\nNote\n\n\n\nLes modÃ¨les mixtes qui sont une gÃ©nÃ©ralisation de lâ€™ANOVA Ã  effets mixtes sont maintenant extrÃªmement bien dÃ©veloppÃ© et sont Ã  favoriser lors dâ€™analyse incluant des effets dit alÃ©atoires.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html#plan-factoriel-Ã -deux-facteurs-de-classification-sans-rÃ©plication",
    "href": "34-anova_mult.html#plan-factoriel-Ã -deux-facteurs-de-classification-sans-rÃ©plication",
    "title": "\n7Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "\n7.3 Plan factoriel Ã  deux facteurs de classification sans rÃ©plication",
    "text": "7.3 Plan factoriel Ã  deux facteurs de classification sans rÃ©plication\nDans certains plans dâ€™expÃ©rience il nâ€™y a pas de rÃ©plicats pour chaque combinaison de facteurs, par exemple parce quâ€™il serait trop coÃ»teux de faire plus dâ€™une observation. Lâ€™ANOVA Ã  deux critÃ¨res de classification est quand mÃªme possible dans ces circonstances, mais il y a une limitation importante.\n\n\n\n\n\n\nAvertissement\n\n\n\nComme il nâ€™y a pas de rÃ©plicats, on ne peut estimer la variance du terme dâ€™erreur. En effet on ne peut quâ€™estimer la somme des carrÃ©s associÃ©s Ã  chacun des facteurs principaux, et la quantitÃ© de variabilitÃ© qui reste (Remainder Mean Square) reprÃ©sente la somme de la variabilitÃ© attribuable Ã  lâ€™interaction et au terme dâ€™erreur. Cela a une implication importante. Dans le cas dâ€™un modÃ¨le avec uniquement des effets fixes ou pour lâ€™effet alÃ©atoire dâ€™un modÃ¨le dâ€™ANOVA mixtes on ne peut tester les effets principaux que si on est sur quâ€™il nâ€™y a pas dâ€™interaction.\n\n\nUn limnologiste qui Ã©tudie Round Lake dans le Parc Algonquin prend une seule mesure de tempÃ©rature (temp,en degrÃ©s C) Ã  10 profondeurs diffÃ©rentes (depth, en m) Ã  quatre dates (date) au cours de lâ€™Ã©tÃ©. Ses donnÃ©es sont au fichier nr2wdat.csv.\n\nEffectuez une ANOVA Ã  deux critÃ¨res de classification en utilisant temp comme variable dÃ©pendante et date et depth comme variables indÃ©pendantes (vous devez changer le type de donnÃ©es pour DEPTH pour que R traite cette variable comme un facteur et non pas une var$able continue).\n\n\nnr2wdat &lt;- read.csv(\"data/nr2wdat.csv\")\nnr2wdat$depth &lt;- as.factor(nr2wdat$depth)\nanova.model4 &lt;- lm(temp ~ date + depth, data = nr2wdat)\nAnova(anova.model4, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: temp\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 1511.99  1 125.5652 1.170e-11 ***\ndate         591.15  3  16.3641 2.935e-06 ***\ndepth       1082.82  9   9.9916 1.450e-06 ***\nResiduals    325.12 27                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSi on suppose que câ€™est un modÃ¨le dâ€™ANOVA mixte (date alÃ©atoire, Depth fixe), que concluez vous? (Indice: faites un graphique dâ€™interaction tempÃ©rature en fonction de la profondeur et la date, pour voir ce qui se passe).\n\ninteraction.plot(nr2wdat$depth, nr2wdat$date, nr2wdat$temp)\n\n\n\nEffet du mois et de la profondeur sur la tempÃ©rature\n\n\n\nLa tempÃ©rature diminue significativement en profondeur. Pour tester lâ€™effet du mois (le facteur alÃ©atoire), on doit prÃ©sumer quâ€™il nâ€™y a pas dâ€™interaction entre la profondeur et le mois (donc que lâ€™effet de la profondeur sur la tempÃ©rature est le mÃªme Ã  chaque mois). Câ€™est peu probable: si vous faites un graphique de la tempÃ©rature en fonction de la profondeur pour chaque mois, vous observerez que le profil de tempÃ©rature change au fur et Ã  mesure du dÃ©veloppement de la thermocline. Bref, comme le profil change au cours de lâ€™Ã©tÃ©, ce modÃ¨le ne fait pas de trÃ¨s bonnes prÃ©dictions.\nJetez un coup dâ€™oeil sur les graphiques des rÃ©sidus:\n\npar(mfrow = c(2, 2))\nplot(anova.model4)\n\n\n\nConditions dâ€™applications du modÃ¨le anova.model4\n\n\n\n\nshapiro.test(residuals(anova.model4))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(anova.model4)\nW = 0.95968, p-value = 0.1634\n\n\nLe test de normalitÃ© sur les rÃ©sidus donne p = 0.16, donc lâ€™hypothÃ¨se de normalitÃ© ne semble pas Ãªtre sÃ©rieusement en doute. Pour lâ€™Ã©galitÃ© des variances, on peut seulement comparer entre les mois en utilisant les profondeurs comme rÃ©plicats (ou lâ€™inverse). En utilisant les profondeurs comme rÃ©plicats, on obtient:\n\nleveneTest(temp ~ date, data = nr2wdat)\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value    Pr(&gt;F)    \ngroup  3  17.979 2.679e-07 ***\n      36                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIl y a donc un problÃ¨me dâ€™hÃ©tÃ©roscÃ©dasticitÃ©, comme on peut trÃ¨s bien voir dans le graphique des rÃ©sidus vs les valeurs estimÃ©es. Cette analyse nâ€™est donc pas trÃ¨s satisfaisante: il y a des violations des conditions dâ€™application et il semble y avoir une interaction entre depth et date qui pourrait invalider lâ€™analyse.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html#plans-hiÃ©rarchiques",
    "href": "34-anova_mult.html#plans-hiÃ©rarchiques",
    "title": "\n7Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "\n7.4 Plans hiÃ©rarchiques",
    "text": "7.4 Plans hiÃ©rarchiques\nUn design expÃ©rimental frÃ©quent implique la division de chaque groupe du facteur majeur en sous-groupes alÃ©atoires. Par exemple, une gÃ©nÃ©ticienne intÃ©ressÃ©e par lâ€™effet du gÃ©notype sur la rÃ©sistance Ã  la dessiccation chez la drosophile effectue une expÃ©rience. Pour chaque gÃ©notype (facteur principal) elle prÃ©pare trois chambres de croissance (sous-groupes) avec une tempÃ©rature et humiditÃ© contrÃ´lÃ©es. Dans chaque chambre de croissance, elle place cinq larves, puis mesure le nombre dâ€™heures pendant lesquelles chaque larve survit. Les donnÃ©es ont donc un structure hiÃ©rarchique. Il ya des observations rÃ©pÃ©tÃ©es dans chaque chambre au sein de chaque gÃ©notype.\n\nLe fichier nestdat.csv contient les rÃ©sultats dâ€™une expÃ©rience semblable. Il contient trois variables : genotype, chamber et survival. Effectuez une ANOVA hiÃ©rarchique avec survival comme variable dÃ©pendante et genotype et chamber/genotype comme variables indÃ©pendantes.\n\n\nnestdat &lt;- read.csv(\"data/nestdat.csv\")\nnestdat$chamber &lt;- as.factor(nestdat$chamber)\nnestdat$genotype &lt;- as.factor(nestdat$genotype)\nanova.nested &lt;- lm(survival ~ genotype / chamber, data = nestdat)\n\nQue concluez-vous de cette analyse ? Que devrait Ãªtre la prochaine Ã©tape ? (Indice: si lâ€™effet de Chamber / genotype nâ€™est pas significatif, vous pouvez augmenter la puissance des comparaisons entre gÃ©notypes en regroupant les chambres de chaque gÃ©notype.). Faites-le ! Nâ€™oubliez pas de vÃ©rifier les conditions dâ€™applications de lâ€™ANOVA!\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nanova(anova.nested)\n\nAnalysis of Variance Table\n\nResponse: survival\n                 Df  Sum Sq Mean Sq  F value Pr(&gt;F)    \ngenotype          2 2952.22 1476.11 292.6081 &lt;2e-16 ***\ngenotype:chamber  6   40.65    6.78   1.3432 0.2639    \nResiduals        36  181.61    5.04                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow = c(2, 2))\nplot(anova.nested)\n\n\n\nConditions dâ€™applications du modÃ¨le anova.nested\n\n\n\n\n\n\nOn conclue de cette analyse que la variation entre les chambres de croissance nâ€™est pas significative, mais quâ€™on doit rejeter lâ€™hypothÃ¨se nulle que tous les gÃ©notypes ont la mÃªme rÃ©sistance Ã  la dessiccation.\nComme lâ€™effet hiÃ©rarchique chamber / genotype nâ€™est pas significatif, on peut regrouper les observations pour augmenter le nombre de degrÃ©s de libertÃ©:\n\nanova.simple &lt;- lm(survival ~ genotype, data = nestdat)\nanova(anova.simple)\n\nAnalysis of Variance Table\n\nResponse: survival\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \ngenotype   2 2952.22 1476.11  278.93 &lt; 2.2e-16 ***\nResiduals 42  222.26    5.29                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDonc on conclue quâ€™il y a une variation significative de rÃ©sistance Ã  la dessiccation entre les trois gÃ©notypes.\nLe graphique de survival en fonction du gÃ©notype suggÃ¨re que la rÃ©sistance Ã  la dessiccation varie entre chaque gÃ©notype. On peut combiner cela avec un test de Tukey.\n\npar(mfrow = c(1, 1))\n# Compute and plot means and Tukey CI\nmeans &lt;- glht(anova.simple, linfct = mcp(\n  genotype =\n    \"Tukey\"\n))\ncimeans &lt;- cld(means)\n# use sufficiently large upper margin\nold.par &lt;- par(mai = c(1, 1, 1.25, 1))\n# plot\nplot(cimeans, las = 1) # las option to put y-axis labels as God intended them\n\n\n\nEffet du genotype sur la rÃ©sistance Ã  la dessication avec un test de Tukey\n\n\n\nOn conclue donc que la rÃ©sistance Ã  la dessiccation (R), telle que mesurÃ©e par la survie dans des conditions chaudes et sÃ¨ches, varie significativement entre les trois gÃ©notypes avec R(AA) &gt; R(Aa) &gt; R(aa).\nCependant, avant dâ€™accepter cette conclusion, il faut Ã©prouver les conditions dâ€™application du test. Voici les diagnostics des rÃ©sidus pour lâ€™ANOVA Ã  un critÃ¨re de classification (non hiÃ©rarchique):\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npar(mfrow = c(2, 2))\nplot(anova.simple)\n\n\n\nConditions dâ€™applications du modÃ¨le anova.simple\n\n\n\n\n\n\nDonc, toutes les conditions dâ€™application semblent Ãªtre remplies, et on peut donc accepter les conclusions. Notez que si lâ€™on compare le carrÃ© moyen des rÃ©sidus de lâ€™ANOVA hiÃ©rarchique et de lâ€™ANOVA Ã  un critÃ¨re de classification (5.045 vs 5.292), ils sont presque identiques. Cela nâ€™est pas surprenant compte tenu de la faible variabilitÃ© associÃ©e aux chambres de croissance pour chaque gÃ©notype.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html#anova-non-paramÃ©trique-avec-deux-facteurs-de-classification",
    "href": "34-anova_mult.html#anova-non-paramÃ©trique-avec-deux-facteurs-de-classification",
    "title": "\n7Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "\n7.5 ANOVA non paramÃ©trique avec deux facteurs de classification",
    "text": "7.5 ANOVA non paramÃ©trique avec deux facteurs de classification\nLâ€™ANOVA non paramÃ©trique Ã  deux critÃ¨res de classification est une extension de celle Ã  un critÃ¨re de classification vue prÃ©cÃ©demment. Elle dÃ©bute par une ANOVA faite sur les donnÃ©es transformÃ©es en rangs. Elle peut se faire sur des donnÃ©es avec ou sans rÃ©plicats.\nÃ€ partir du fichier stu2wdat.csv, effectuez une ANOVA non paramÃ©trique Ã  deux facteurs de classification pour examiner lâ€™effet de sex et location sur rank(rdwght).\n\naov.rank &lt;- aov(\n  rank(rdwght) ~ sex * location,\n  contrasts = list(\n    sex = contr.sum, location = contr.sum\n  ),\n  data = Stu2wdat\n)\n\nLâ€™extension de Schreirer-Ray-Hare au test de Kruskall-Wallis se fait ensuite Ã  la main. Il faut dâ€™abord calculer la statistique H Ã©gale au rapport de la somme des carrÃ©es de lâ€™effet testÃ©, divisÃ©e par le carrÃ© moyen total. On calcule la statistique H pour chacun des termes. Les statistiques H sont ensuite comparÃ©es Ã  une distribution thÃ©orique de \\(\\chi^2\\) (chi-carrÃ©) en utilisant la commande pchisq(H, df, lower.tail = FALSE), oÃ¹ H et df sont les statistiques H calculÃ©es et les degrÃ©s de libertÃ©s, respectivement.\nTestez lâ€™effet de sex et location sur rdwght. Que concluez-vous ? Comment ce rÃ©sultat se compare-t-il Ã  celui obtenu en faisant lâ€™ANOVA paramÃ©trique faite prÃ©cÃ©demment ?\n\nAnova(aov.rank, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: rank(rdwght)\n              Sum Sq  Df  F value    Pr(&gt;F)    \n(Intercept)  1499862   1 577.8673 &lt; 2.2e-16 ***\nsex            58394   1  22.4979 4.237e-06 ***\nlocation        1128   1   0.4347    0.5105    \nsex:location    1230   1   0.4738    0.4921    \nResiduals     472383 182                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPour calculer lâ€™extension Schreirer-Ray-Hare au test de Kruskall-Wallis, on doit dâ€™abord calculer le carrÃ© moyen total (MS), i.e.Â la variance des donnÃ©es transformÃ©es en rang. Ici, on a 186 observations, donc des rangs; 1, 2, 3, â€¦ 186. La variance de cette sÃ©rie de 186 valeurs peut Ãªtre calculÃ©e simplement par var(1:186).\nDonc on peut calculer la statistique H pour chaque terme:\n\nHsex &lt;- 58394 / var(1:186)\nHlocation &lt;- 1128 / var(1:186)\nHsexloc &lt;- 1230 / var(1:186)\n\nEt convertir ces statistiques en valeur de ps:\n\n# sex\nHsex\n\n[1] 20.14628\n\npchisq(Hsex, 1, lower.tail = FALSE)\n\n[1] 7.173954e-06\n\n# location\nHlocation\n\n[1] 0.3891668\n\npchisq(Hlocation, 1, lower.tail = FALSE)\n\n[1] 0.5327377\n\n# sex:location\nHsexloc\n\n[1] 0.4243574\n\npchisq(Hsexloc, 1, lower.tail = FALSE)\n\n[1] 0.5147707\n\n\nCes rÃ©sultats sont semblables aux rÃ©sultats de lâ€™ANOVA non-paramÃ©trique Ã  deux critÃ¨res de classification. MalgrÃ© la puissance rÃ©duite, il y a encore un effet significatif du sexe, mais ni interaction ni effet du site.\nIl y a toutefois une diffÃ©rence importante. Rappelez-vous que dans lâ€™ANOVA paramÃ©trique il y avait un effet significatif de sex en considÃ©rant le problÃ¨me comme un modÃ¨le ANOVA Ã  effet fixe. Cependant, si on traite le problÃ¨me comme un modÃ¨le dâ€™ANOVA Ã  effet mixte lâ€™effet significatif de sex peut en principe disparaÃ®tre parce que le nombre de degrÃ© de libertÃ© (dl) associÃ©s au carrÃ© moyen (CM) de lâ€™interaction est plus faible que le nombre de dl du CM de lâ€™erreur du modÃ¨le Ã  effet fixes. Dans ce cas ci, cependant, le CM de lâ€™interaction est environ la moitiÃ© du CM de lâ€™erreur. Par consÃ©quent, lâ€™effet significatif de sex pourrait devenir encore plus significatif si le problÃ¨me est analysÃ© (comme il se doit) comme une ANOVA mixte. Encore une fois on peut voir lâ€™importance de spÃ©cifier le modÃ¨le adÃ©quat en ANOVA.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html#comparaisons-multiples",
    "href": "34-anova_mult.html#comparaisons-multiples",
    "title": "\n7Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "\n7.6 Comparaisons multiples",
    "text": "7.6 Comparaisons multiples\nLes Ã©preuves dâ€™hypothÃ¨ses subsÃ©quentes en ANOVA Ã  plus dâ€™un critÃ¨re de classification dÃ©pendent des rÃ©sultats initiaux de lâ€™ANOVA. Si vous Ãªtes intÃ©ressÃ©s Ã  comparer des effets moyens dâ€™un facteur pour tous les niveaux dâ€™un autre facteur (par exemple lâ€™effet du sexe sur la taille des esturgeons peu importe dâ€™oÃ¹ ils viennent), alors vous pouvez procÃ©der exactement tel que dÃ©crit dans la section sur les comparaisons multiples suivant lâ€™ANOVA Ã  un critÃ¨re de classification. Pour comparer les moyennes des cellules entre elles, il faut spÃ©cifier lâ€™interaction comme variable qui reprÃ©sente le groupe.\nLe fichier wmcdat2.csv contient des mesures de consommation dâ€™oxygÃ¨ne, o2cons, de deux espÃ¨ces, species, dâ€™un mollusque (une patelle) Ã  trois concentrations diffÃ©rentes dâ€™eau de mer, conc. Ces donnÃ©es sont prÃ©sentÃ©es Ã  la p.Â 332 de Sokal et Rohlf 1995.\n\nEffectuez une ANOVA factorielle Ã  deux critÃ¨res de classification sur ces donnÃ©es en utilisant o2cons comme variable dÃ©pendante et species et conc comme les facteurs (il va probablement falloir changer le type de donnÃ©es de variable conc Ã  facteur). Que concluez-vous ?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nwmcdat2 &lt;- read.csv(\"data/wmcdat2.csv\")\nwmcdat2$species &lt;- as.factor(wmcdat2$species)\nwmcdat2$conc &lt;- as.factor(wmcdat2$conc)\nanova.model5 &lt;- lm(o2cons ~ species * conc, data = wmcdat2)\nAnova(anova.model5, type = 3)\n\n\n\n\n\n\nAnova Table (Type III tests)\n\nResponse: o2cons\n              Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)  1185.60  1 124.0165 4.101e-14 ***\nspecies         0.09  1   0.0097   0.92189    \nconc           74.90  2   3.9172   0.02755 *  \nspecies:conc   23.93  2   1.2514   0.29656    \nResiduals     401.52 42                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nComme lâ€™effectif dans chaque cellule est relativement petit, il faudrait idÃ©alement refaire cette analyse avec une ANOVA non-paramÃ©trique. Pour le moment, contentons nous de la version paramÃ©trique.\nExaminons les graphiques diagnostiques:\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npar(mfrow = c(2, 2))\nplot(anova.model5)\n\n\n\n\n\n\n\n\n\n\nLes variances semblent donc Ã©gales. Le test de normalitÃ© donne:\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nshapiro.test(residuals(anova.model5))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(anova.model5)\nW = 0.93692, p-value = 0.01238\n\n\n\n\n\nIl y a donc Ã©vidence de non-normalitÃ©, mais Ã  part Ã§a tout semble aller. Comme lâ€™ANOVA est relativement robuste Ã  la non-normalitÃ©, on va regarder de lâ€™autre cotÃ©. (Si vous voulez Ãªtre plus confiants, vous pouvez tourner une ANOVA non paramÃ©trique. Vous arriverez aux mÃªmes conclusions.)\n\nÃ€ la suite des rÃ©sultats que vous venez dâ€™obtenir, quelles moyennes voudriez-vous comparer ? Pourquoi?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\najouter une explication ici\n\n\n\nOn conclue donc quâ€™il nâ€™y a pas de diffÃ©rence entre les espÃ¨ces et que lâ€™effet de la concentration ne dÃ©pends pas de lâ€™espÃ¨ce (il nâ€™y a pas dâ€™interaction). Par consÃ©quent, les seules comparaisons justifiables sont entre les concentrations:\n\n# fit simplified model\nanova.model6 &lt;- aov(o2cons ~ conc, data = wmcdat2)\n# Make Tukey multiple comparisons\nTukeyHSD(anova.model6)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = o2cons ~ conc, data = wmcdat2)\n\n$conc\n           diff       lwr        upr     p adj\n75-50  -4.63625 -7.321998 -1.9505018 0.0003793\n100-50 -3.25500 -5.940748 -0.5692518 0.0141313\n100-75  1.38125 -1.304498  4.0669982 0.4325855\n\npar(mfrow = c(1, 1))\n# Graph of all comparisons for conc\ntuk &lt;- glht(anova.model6, linfct = mcp(conc = \"Tukey\"))\n# extract information\ntuk.cld &lt;- cld(tuk)\n# use sufficiently large upper margin\nold.par &lt;- par(mai = c(1, 1, 1.25, 1))\n# plot\nplot(tuk.cld)\n\n\n\nComparaison de Tukey des moyennes de consommation dâ€™oxygÃ¨n en fonction del la concentration\n\n\npar(old.par)\n\nIl y a donc une diffÃ©rence de consommation dâ€™oxygÃ¨ne significative lorsque la salinitÃ© est rÃ©duite de 50%, mais pas Ã  25% de rÃ©duction.\n\nRÃ©pÃ©tez les deux analyses prÃ©cÃ©dentes sur les donnÃ©es du fichier wmc2dat2.csv. Comment les rÃ©sultats se comparent-ils Ã  ceux obt$nus prÃ©cÃ©demment ?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nwmc2dat2 &lt;- read.csv(\"data/wmc2dat2.csv\")\nwmc2dat2$species &lt;- as.factor(wmc2dat2$species)\nwmc2dat2$conc &lt;- as.factor(wmc2dat2$conc)\nanova.model7 &lt;- lm(o2cons ~ species * conc, data = wmc2dat2)\n\n\n\n\nEn utilisant wmc2dat2.csv, on obtient:\n\n\nAnova Table (Type III tests)\n\nResponse: o2cons\n             Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)  343.09  1 36.2132 3.745e-07 ***\nspecies      133.52  1 14.0929 0.0005286 ***\nconc          66.76  2  3.5232 0.0385011 *  \nspecies:conc 168.15  2  8.8742 0.0006101 ***\nResiduals    397.91 42                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDans ce cas ci, il y a une interaction significative, et il nâ€™est par consÃ©quent pas appropriÃ© de comparer les moyennes regroupÃ©es par espÃ¨ce ou concentration. Ceci est clairement visualisÃ© par un graphique dâ€™interaction:\n\nwith(wmc2dat2, interaction.plot(conc, species, o2cons))\n\n\n\n\n\n\n\n\nToujours en utilisant les donnÃ©es de wmc2dat2.csv, comparez les 6 moyennes avec lâ€™ajustement Bonferonni. Pour ce faire, il sera utile de crÃ©er une nouvelle variable qui combine species et conc:\n\n\nwmc2dat2$species.conc &lt;- as.factor(paste0(wmc2dat2$species, wmc2dat2$conc))\n\nensuite on peut faire les comparaisons de Bonferroni:\n\nwith(wmc2dat2, pairwise.t.test(o2cons, species.conc, p.adj = \"bonf\"))\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  o2cons and species.conc \n\n     A100   A50    A75    B100   B50   \nA50  0.1887 -      -      -      -     \nA75  1.0000 1.0000 -      -      -     \nB100 0.7223 1.0000 1.0000 -      -     \nB50  1.0000 0.0079 0.0929 0.0412 -     \nB75  0.6340 1.0000 1.0000 1.0000 0.0350\n\nP value adjustment method: bonferroni \n\n\nCes comparaisons sont un peu plus difficiles Ã  interprÃ©ter, mais lâ€™analyse examine essentiellement les diffÃ©rences entre les concentrations de lâ€™eau dans lâ€™espÃ¨ce A (nommÃ© adj1) et pour les diffÃ©rences entre les concentrations dans lâ€™espÃ¨ce B (nommÃ© adj2). Cette analyse indique que la diffÃ©rence principale est entre la concentration de 50% pour lâ€™espÃ¨ce B et les concentrations de 75 et 100% de lâ€™espÃ¨ce B, tandis quâ€™il nâ€™y a aucunes diffÃ©rences significatives pour lâ€™espÃ¨ce A.\nJe trouve ces tableaux de rÃ©sultats peu satisfaisants parce quâ€™ils indiquent seulement les valeur de ps sans indices de la taille de lâ€™effet. On peut obtenir Ã  la fois le rÃ©sultat des tests de comparaison multiple et un indice de la taille de lâ€™effet Ã  lâ€™aide du code suivant:\n\n# fit one-way anova comparing all combinations of species.conc combinations\nanova.modelx &lt;- aov(o2cons ~ species.conc, data = wmc2dat2)\ntuk2 &lt;- glht(anova.modelx, linfct = mcp(species.conc = \"Tukey\"))\n# extract information\ntuk2.cld &lt;- cld(tuk2)\n# use sufficiently large upper margin\nold.par &lt;- par(mai = c(1, 1, 1.25, 1))\n# plot\nplot(tuk2.cld)\n\n\n\n\n\n\npar(old.par)\n\nDans cette analyse on a utilisÃ© le CM = 9.474 du modÃ¨le dâ€™ANOVA pour comparer les moyennes. En ce faisant, on prÃ©sume quâ€™il sâ€™agit dâ€™une situation dâ€™ANOVA Ã  effet fixes, ce qui nâ€™est peut-Ãªtre pas le cas (conc est certainement fixe, mais species peut Ãªtre fixe ou alÃ©atoire).",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html#test-de-permutation-pour-lanova-Ã -deux-facteurs-de-classification",
    "href": "34-anova_mult.html#test-de-permutation-pour-lanova-Ã -deux-facteurs-de-classification",
    "title": "\n7Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "\n7.7 Test de permutation pour lâ€™ANOVA Ã  deux facteurs de classification",
    "text": "7.7 Test de permutation pour lâ€™ANOVA Ã  deux facteurs de classification\nQuand les donnÃ©es ne rencontrent pas les conditions dâ€™application des tests paramÃ©triques dâ€™ANOVA Ã  un ou plusieurs facteurs de classification, il est possible dâ€™utiliser les tests de permutation comme une alternative aux tests non-paramÃ©triques pour calculer des p-valeurs. Le code suivant est pour un modÃ¨le I dâ€™une ANOVA Ã  deux facteurs de classification. Je vous laisse le soin dâ€™adapter ce code pour dâ€™autres modÃ¨les. (Jâ€™offre mÃªme des points boni pour une solution Ã©lÃ©gante pour des modÃ¨les Ã  plusieurs facteurs de classification).\n\n###########################################################\n# Permutation test for two way ANOVA\n# Ter Braak creates residuals from cell means and then permutes across\n# all cells\n# This can be accomplished by taking residuals from the full model\n# modified from code written by David C. Howell\n# http://www.uvm.edu/~dhowell/StatPages/More_Stuff/Permutation%20Anova/PermTestsAnova.html\nnreps &lt;- 500\ndependent &lt;- Stu2wdat$rdwght\nfactor1 &lt;- as.factor(Stu2wdat$sex)\nfactor2 &lt;- as.factor(Stu2wdat$location)\nmy.dataframe &lt;- data.frame(dependent, factor1, factor2)\nmy.dataframe.noNA &lt;- my.dataframe[complete.cases(my.dataframe), ]\nmod &lt;- lm(dependent ~ factor1 + factor2 + factor1:factor2,\n  data = my.dataframe.noNA\n)\nres &lt;- mod$residuals\nTBint &lt;- numeric(nreps)\nTB1 &lt;- numeric(nreps)\nTB2 &lt;- numeric(nreps)\nANOVA &lt;- summary(aov(mod))\ncat(\n  \" The standard ANOVA for these data follows \",\n  \"\\n\"\n)\nF1 &lt;- ANOVA[[1]]$\"F value\"[1]\nF2 &lt;- ANOVA[[1]]$\"F value\"[2]\nFinteract &lt;- ANOVA[[1]]$\"F value\"[3]\nprint(ANOVA)\ncat(\"\\n\")\ncat(\"\\n\")\nTBint[1] &lt;- Finteract\nfor (i in 2:nreps) {\n  newdat &lt;- sample(res, length(res), replace = FALSE)\n  modb &lt;- summary(aov(newdat ~ factor1 + factor2 +\n    factor1:factor2,\n  data = my.dataframe.noNA\n  ))\n  TBint[i] &lt;- modb[[1]]$\"F value\"[3]\n  TB1[i] &lt;- modb[[1]]$\"F value\"[1]\n  TB2[i] &lt;- modb[[1]]$\"F value\"[2]\n}\nprobInt &lt;- length(TBint[TBint &gt;= Finteract]) / nreps\nprob1 &lt;- length(TB1[TB1 &gt;= F1]) / nreps\nprob2 &lt;- length(TB2[TB1 &gt;= F2]) / nreps\ncat(\"\\n\")\ncat(\"\\n\")\nprint(\"Resampling as in ter Braak with unrestricted sampling\nof cell residuals. \")\ncat(\n  \"The probability for the effect of Interaction is \",\n  probInt, \"\\n\"\n)\ncat(\n  \"The probability for the effect of Factor 1 is \",\n  prob1, \"\\n\"\n)\ncat(\n  \"The probability for the effect of Factor 2 is \",\n  prob2, \"\\n\"\n)\n\nSi vous avez la chance dâ€™avoir accÃ¨s au package lmPerm, vous pouvez effectuer le test de permutation beaucoup plus rapidement et facilement:\n\n#######################################################################\n## lmPerm version of permutation test\nlibrary(lmPerm)\n# for generality, copy desired dataframe to mydata\n# and model formula to myformula\nmydata &lt;- Stu2wdat\nmyformula &lt;- as.formula(\"rdwght ~ sex+location+sex:location\")\n# Fit desired model on the desired dataframe\nmymodel &lt;- lm(myformula, data = mydata)\n# Calculate permutation p-value\nanova(lmp(myformula, data = mydata, perm = \"Prob\", center = FALSE, Ca = 0.001))",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "34-anova_mult.html#bootstrap-pour-lanova-Ã -deux-facteurs-de-classification",
    "href": "34-anova_mult.html#bootstrap-pour-lanova-Ã -deux-facteurs-de-classification",
    "title": "\n7Â  ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques\n",
    "section": "\n7.8 Bootstrap pour lâ€™ANOVA Ã  deux facteurs de classification",
    "text": "7.8 Bootstrap pour lâ€™ANOVA Ã  deux facteurs de classification\nDans la plupart des cas, les tests de permutation seront plus appropriÃ©s que le bootstrap pour les designs dâ€™ANOVA. Jâ€™ai quand mÃªme un bout de code qui pourra servir si vous en avez besoin:\n\n############################################################\n###########\n# Bootstrap for two-way ANOVA\n# You possibly want to edit bootfunction.mod1 to return other values\n# Here it returns the standard coefficients of the fitted model\n# Requires boot library\n#\nnreps &lt;- 5000\ndependent &lt;- Stu2wdat$rdwght\nfactor1 &lt;- as.factor(Stu2wdat$sex)\nfactor2 &lt;- as.factor(Stu2wdat$location)\nmy.dataframe &lt;- data.frame(dependent, factor1, factor2)\nmy.dataframe.noNA &lt;- my.dataframe[complete.cases(my.dataframe), ]\nlibrary(boot)\n# Fit model on observed data\nmod1 &lt;- aov(dependent ~ factor1 + factor2 + factor1:factor2,\n  data = my.dataframe.noNA\n)\n\n\n# Bootstrap 1000 time using the residuals bootstraping methods to\n# keep the same unequal number of observations for each level of the indep. var.\nfit &lt;- fitted(mod1)\ne &lt;- residuals(mod1)\nX &lt;- model.matrix(mod1)\nbootfunction.mod1 &lt;- function(data, indices) {\n  y &lt;- fit + e[indices]\n  bootmod &lt;- lm(y ~ X)\n  coefficients(bootmod)\n}\nbootresults &lt;- boot(my.dataframe.noNA, bootfunction.mod1,\n  R = 1000\n)\nbootresults\n## Calculate 90% CI and plot bootstrap estimates separately for each model parameter\nboot.ci(bootresults, conf = 0.9, index = 1)\nplot(bootresults, index = 1)\nboot.ci(bootresults, conf = 0.9, index = 3)\nplot(bootresults, index = 3)\nboot.ci(bootresults, conf = 0.9, index = 4)\nplot(bootresults, index = 4)\nboot.ci(bootresults, conf = 0.9, index = 5)\nplot(bootresults, index = 5)",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ANOVA Ã  critÃ¨res multiples : plans factoriels et hiÃ©rarchiques</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html",
    "href": "35-reg_mult.html",
    "title": "\n8Â  RÃ©gression multiple\n",
    "section": "",
    "text": "8.1 Paquets et donnÃ©es requises pour le labo\nCe laboratoire nÃ©cessite:",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#set-reg-mul",
    "href": "35-reg_mult.html#set-reg-mul",
    "title": "\n8Â  RÃ©gression multiple\n",
    "section": "",
    "text": "les paquets R:\n\nggplot2\ncar\nlmtest\nsimpleboot\nboot\nMuMIn\n\n\nles fichiers de donnÃ©es\n\nMregdat.csv",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#conseils-gÃ©nÃ©raux",
    "href": "35-reg_mult.html#conseils-gÃ©nÃ©raux",
    "title": "\n8Â  RÃ©gression multiple\n",
    "section": "\n8.2 Conseils gÃ©nÃ©raux",
    "text": "8.2 Conseils gÃ©nÃ©raux\nLes variables qui intÃ©ressent les biologistes sont gÃ©nÃ©ralement influencÃ©es par plusieurs facteurs, et une description exacte ou une prÃ©diction de la variable dÃ©pendante requiert que plus dâ€™une variable soit incluse dans le modÃ¨le. La rÃ©gression multiple permet de quantifier lâ€™effet de plusieurs variables continues sur la variable dÃ©pendante.\nIl est important de rÃ©aliser que la maÃ®trise de la rÃ©gression multiple ne sâ€™acquiert pas instantanÃ©ment. Les dÃ©butants doivent garder Ã  lâ€™esprit plusieurs points importants :\n\nUn modÃ¨le de rÃ©gression multiple peut Ãªtre hautement significatif mÃªme si aucun des termes pris isolÃ©ment ne lâ€™est (ceci est causÃ© par la multicolinÃ©aritÃ©),\nUn modÃ¨le peut ne pas Ãªtre significatif alors que lâ€™un ou plusieurs des termes le sont (ceci est un signe dâ€™un modÃ¨le trop complexe (â€œoverfittingâ€)) et,\nÃ€ moins que les variables indÃ©pendantes soient parfaitement orthogonales (câ€™est-Ã -dire quâ€™il nâ€™y ait aucune corrÃ©lation entre elles et donc pas de multicolinÃ©aritÃ©) les diverses approches de sÃ©lection des variables indÃ©pendantes peuvent mener Ã  des modÃ¨les diffÃ©rents.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#premiÃ¨res-rÃ©gressions-multiples",
    "href": "35-reg_mult.html#premiÃ¨res-rÃ©gressions-multiples",
    "title": "\n8Â  RÃ©gression multiple\n",
    "section": "\n8.3 PremiÃ¨res rÃ©gressions multiples",
    "text": "8.3 PremiÃ¨res rÃ©gressions multiples\nLe fichier Mregdat.csv contient des donnÃ©es de richesse spÃ©cifique de quatre groupes dâ€™organismes dans 30 marais de la rÃ©gion Ottawa-Cornwall-Kingston. Les variables sont:\n\nla richesse spÃ©cifique:\n\ndes oiseaux (bird, et son logarithme base 10 logbird)\ndes mammifÃ¨res (mammal, logmam)\ndes amphibiens et reptiles (herptile, logherp)\ndes vertÃ©brÃ©s (totsp, logtot)\n\n\nles coordonnÃ©es des sites (lat, long)\nla superficie du marais (logarea)\nle pourcentage du marais inondÃ© toute lâ€™annÃ©e (swamp)\nle pourcentage des terres couvertes par des forÃªts dans un rayon de 1km du marais (cpfor2)\nla densitÃ© des routes pavÃ©es (en m/ha) dans un rayon de 1km du marais (thtden).\n\nNous allons nous concentrer sur les amphibiens et les reptiles (herptile) pour cet exemple, il est donc avisÃ© dâ€™examiner la distribution de cette variable et les corrÃ©lations avec les variables indÃ©pendantes potentielles:\n\nmydata &lt;- read.csv(\"data/Mregdat.csv\")\nscatterplotMatrix(\n  ~ logherp + logarea + cpfor2 + thtden + swamp,\n  regLine = TRUE, smooth = TRUE, diagonal = TRUE,\n  data = mydata\n)\n\n\n\nMatrice de rÃ©lation et densitÃ© pour la richesse spÃ©cifique des amphibiens et reptiles\n\n\n\n\nEn utilisant les donnÃ©es de ce fichier, faites la rÃ©gression simple de logherp en fonction de logarea . Que concluez-vous Ã  partir de cette analyse?\n\n\nmodel.loga &lt;- lm(logherp ~ logarea, data = mydata)\nsummary(model.loga)\n\n\nCall:\nlm(formula = logherp ~ logarea, data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.38082 -0.09265  0.00763  0.10409  0.46977 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.18503    0.15725   1.177 0.249996    \nlogarea      0.24736    0.06536   3.784 0.000818 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1856 on 26 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.3552,    Adjusted R-squared:  0.3304 \nF-statistic: 14.32 on 1 and 26 DF,  p-value: 0.0008185\n\npar(mfrow = c(2, 2))\nplot(model.loga)\n\n\n\nConditions dâ€™applications de la rÃ©gression de logherp sur logarea\n\n\n\nIl semble donc y avoir une relation positive entre la richesse spÃ©cifique des reptiles et des amphibiens et la surface des marais. La rÃ©gression nâ€™explique cependant quâ€™environ le tiers de la variabilitÃ© (R 2 =0.355). Lâ€™analyse des rÃ©sidus indique quâ€™il nâ€™y a pas de problÃ¨me avec la normalitÃ©, lâ€™homoscÃ©dasticitÃ©, ni lâ€™indÃ©pendance.\n\nFaites ensuite la rÃ©gression de logherp en fonction de cpfor2 . Que concluez-vous?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.logcp &lt;- lm(logherp ~ cpfor2, data = mydata)\nsummary(model.logcp)\n\n\nCall:\nlm(formula = logherp ~ cpfor2, data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.49095 -0.10266  0.05881  0.16027  0.25159 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.609197   0.104233   5.845 3.68e-06 ***\ncpfor2      0.002706   0.001658   1.632    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2202 on 26 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.09289,   Adjusted R-squared:  0.058 \nF-statistic: 2.662 on 1 and 26 DF,  p-value: 0.1148\n\n\n\n\n\nIci, on doit accepter lâ€™hypothÃ¨se nulle et conclure quâ€™il nâ€™y a pas de relation entre la richesse spÃ©cifique dans les marais (logherp) et la proportion de forÃªts sur les terres adjacentes (cpfor2). Quâ€™est-ce qui arrive quand on fait une rÃ©gression avec les 2 variables indÃ©pendantes?\n\nRefaites la rÃ©gression de logherp enfonction de logarea et cpfor2 Ã  la fois. Que concluez-vous?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.mcp &lt;- lm(logherp ~ logarea + cpfor2, data = mydata)\nsummary(model.mcp)\n\n\nCall:\nlm(formula = logherp ~ logarea + cpfor2, data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40438 -0.11512  0.01774  0.08187  0.36179 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.027058   0.166749   0.162 0.872398    \nlogarea     0.247789   0.061603   4.022 0.000468 ***\ncpfor2      0.002724   0.001318   2.067 0.049232 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.175 on 25 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.4493,    Adjusted R-squared:  0.4052 \nF-statistic:  10.2 on 2 and 25 DF,  p-value: 0.0005774\n\n\n\n\n\nOn voit donc quâ€™on peut rejeter les 2 hypothÃ¨ses nulles que la pente de la rÃ©gression de logherp sur logarea est zÃ©ro et que la pente de la rÃ©gression de logherp sur cpfor2 est zÃ©ro. Pourquoi cpfor2 devient-il un facteur significatif dans la rÃ©gression multiple alors quâ€™il nâ€™est pas significatif dans la rÃ©gression simple? Parce quâ€™il est parfois nÃ©cessaire de contrÃ´ler pour lâ€™effet dâ€™une variable pour pouvoir dÃ©tecter les effets plus subtils dâ€™autres variables. Ici, il y a une relation significative entre logherp et logarea qui masque lâ€™effet de cpfor2 sur logherp . Lorsque le modÃ¨le tient compte des deux variables explicatives, il devient possible de dÃ©tecter lâ€™effet de cpfor2 .\n\nAjustez un autre modÃ¨le, cette fois en remplaÃ§ant cpfor2 par thtden (logherp ~ logarea + thtden). Que concluez-vous?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.mden &lt;- lm(logherp ~ logarea + thtden, data = mydata)\nsummary(model.mden)\n\n\nCall:\nlm(formula = logherp ~ logarea + thtden, data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.31583 -0.12326  0.02095  0.13201  0.31674 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.37634    0.14926   2.521 0.018437 *  \nlogarea      0.22504    0.05701   3.947 0.000567 ***\nthtden      -0.04196    0.01345  -3.118 0.004535 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1606 on 25 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.5358,    Adjusted R-squared:  0.4986 \nF-statistic: 14.43 on 2 and 25 DF,  p-value: 6.829e-05\n\n\n\n\n\nOn rejette donc lâ€™hypothÃ¨se nulle que la richesse spÃ©cifique nâ€™est pas influencÃ©e par la taille des marais (logarea) ni par la densitÃ© des routes (thtden). Notez quâ€™ici il y a une relation nÃ©gative significative entre la richesse spÃ©cifique des amphibiens et reptiles et la densitÃ© des routes sur les terres adjacentes, tandis que la relation est positive pour la taille des marais et pour la densitÃ© des forÃªts (cpfor2 ; rÃ©sultat de la derniÃ¨re rÃ©gression).\nLe \\(R^2\\) de ce modÃ¨le est plus Ã©levÃ© que pour le prÃ©cÃ©dent, reflÃ©tant une corrÃ©lation plus forte entre logherp et thtden quâ€™entre logherp et cpfor2 .\nLa richesse spÃ©cifique des reptiles et amphibiens semble donc reliÃ©e Ã  la surface de marais (logarea), la densitÃ© des routes (thtden), et possiblement au couvert forestier sur les terres adjacentes aux marais (cpfor2). Cependant, les trois variables ne sont peut-Ãªtre pas nÃ©cessaires dans un modÃ¨le prÃ©dictif. Si deux des trois variables (disons cpfor2 et thtden) sont parfaitement corrÃ©lÃ©es, alors lâ€™effet de thtden ne serait rien de plus que celui de cpfor2 (et vice-versa) et un modÃ¨le incluant lâ€™une des deux variables ferait des prÃ©dictions identiques Ã  un modÃ¨le incluant ces deux variables (en plus de logarea).\n\nEstimez un modÃ¨le de rÃ©gression avec logherp comme variable dÃ©pendante et logarea, cpfor2 et thtden comme variables indÃ©pendantes. Que concluez-vous?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.mtri &lt;- lm(logherp ~ logarea + cpfor2 + thtden, data = mydata)\nsummary(model.mtri)\n\n\nCall:\nlm(formula = logherp ~ logarea + cpfor2 + thtden, data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.30729 -0.13779  0.02627  0.11441  0.29582 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.284765   0.191420   1.488 0.149867    \nlogarea      0.228490   0.057647   3.964 0.000578 ***\ncpfor2       0.001095   0.001414   0.774 0.446516    \nthtden      -0.035794   0.015726  -2.276 0.032055 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1619 on 24 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.5471,    Adjusted R-squared:  0.4904 \nF-statistic: 9.662 on 3 and 24 DF,  p-value: 0.0002291\n\n\n\n\n\nPlusieurs choses sont Ã  noter ici: 1. Tel que prÃ©dit, le coefficient de rÃ©gression pour cpfor2 nâ€™est plus significativement diffÃ©rent de 0. Une fois que la variabilitÃ© attribuable Ã  logarea et thtden est enlevÃ©e, il ne reste quâ€™une fraction nonsignificative de la variabilitÃ© attribuable Ã  cpfor2 . 2. Le \\(R^2\\) pour ce modÃ¨le(0.547) nâ€™est que lÃ©gÃ¨rement supÃ©rieur au \\(R^2\\) du modÃ¨le avec seulement logarea et thtden (.536), ce qui confirme que cpfor2 nâ€™explique pas grand-chose de plus.\nNotez aussi que mÃªme si le coefficient de rÃ©gression pour thtden nâ€™a pas beaucoup changÃ© par rapport Ã  ce qui avait Ã©tÃ© estimÃ© lorsque seul thtden et logarea Ã©taient dans le modÃ¨le (0-.036 vs -0.042), lâ€™erreur type pour lâ€™estimÃ© du coefficient est plus grand, et ce modÃ¨le plus complexe mÃ¨ne Ã  un estimÃ© moins prÃ©cis. Si la corrÃ©lation entre thtden et cpfor2 Ã©tait plus forte, la dÃ©croissance de la prÃ©cision serait encore plus grande.\nOn peut comparer les deux derniers modÃ¨les (i.e., le modÃ¨le incluant les 3 variables et celui avec seulement logarea and thtden) pour dÃ©cider lequel privilÃ©gier.\n\nanova(model.mtri, model.mden)\n\nAnalysis of Variance Table\n\nModel 1: logherp ~ logarea + cpfor2 + thtden\nModel 2: logherp ~ logarea + thtden\n  Res.Df     RSS Df Sum of Sq     F Pr(&gt;F)\n1     24 0.62937                          \n2     25 0.64508 -1 -0.015708 0.599 0.4465\n\n\nCette comparaison rÃ©vÃ¨le que le modÃ¨le Ã  3 variables ne fait pas de prÃ©dictions significativement meilleures que le modÃ¨le avec seulement Logarea et thtden . Ce rÃ©sultat nâ€™est pas surprenant puisque le test de signification pour cpfor2 dans le modÃ¨le complet indique quâ€™il faut accepter lâ€™hypothÃ¨se nulle.\nÃ€ la suite de cette analyse, on doit conclure que:\n\nLe meilleur modÃ¨le est celui incluant thtden et logarea .\nIl y a une relation nÃ©gative entre la richesse spÃ©cifique des amphibiens et reptiles et la densitÃ© des routes sur les terres adjacentes.\nIl y a une relation positive entre la richesse spÃ©cifique et la taille des marais.\n\nNotez que le â€œmeilleurâ€ modÃ¨le nâ€™est pas nÃ©cessairement le modÃ¨le parfait, seulement le meilleur nâ€™utilisant que ces trois variables indÃ©pendantes. Il est Ã©vident quâ€™il y a dâ€™autres facteurs qui contrÃ´lent la richesse spÃ©cifique dans les marais puisque, mÃªme le â€œmeilleurâ€ modÃ¨le nâ€™explique que la moitiÃ© de la variabilitÃ©.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#rÃ©gression-multiple-pas-Ã -pas-stepwise",
    "href": "35-reg_mult.html#rÃ©gression-multiple-pas-Ã -pas-stepwise",
    "title": "\n8Â  RÃ©gression multiple\n",
    "section": "\n8.4 RÃ©gression multiple pas-Ã -pas (stepwise)",
    "text": "8.4 RÃ©gression multiple pas-Ã -pas (stepwise)\nQuand le nombre de variables prÃ©dictives est restreint, comme dans lâ€™exemple prÃ©cÃ©dent, il est aisÃ© de comparer manuellement les modÃ¨les pour sÃ©lectionner le plus adÃ©quat. Cependant, lorsque le nombre de variables indÃ©pendantes augmente, cette approche nâ€™est rapidement plus utilisable et il est alors utile dâ€™utiliser une mÃ©thode automatisÃ©e.\nLa sÃ©lection pas Ã  pas avec R utilise le CritÃ¨re Informatif de Akaike (Akaike Information Criterion, \\(AIC = 2* ln(RSS) + 2K\\) oÃ¹ K le nombre de variables indÃ©pendantes, n est le nombre dâ€™observations, et RSS est la somme des carrÃ©s des rÃ©sidus) comme mesure de la qualitÃ© dâ€™ajustement des modÃ¨les. Cette mesure favorise la prÃ©cision des prÃ©dictions et pÃ©nalise la complexitÃ©. Lorsque lâ€™on compare des modÃ¨les par AIC, le modÃ¨le avec le plus petit AIC est le modÃ¨le Ã  prÃ©fÃ©rer.\n\nUtiliser la fonction step pour activer la sÃ©lection pas Ã  pas des variables indÃ©pendantes sur le modÃ¨les de rÃ©gression incluant logarea, cpfor2 et thtden:\n\n\n# Stepwise Regression\nstep.mtri &lt;- step(model.mtri, direction = \"both\")\n\nStart:  AIC=-98.27\nlogherp ~ logarea + cpfor2 + thtden\n\n          Df Sum of Sq     RSS     AIC\n- cpfor2   1   0.01571 0.64508 -99.576\n&lt;none&gt;                 0.62937 -98.267\n- thtden   1   0.13585 0.76522 -94.794\n- logarea  1   0.41198 1.04135 -86.167\n\nStep:  AIC=-99.58\nlogherp ~ logarea + thtden\n\n          Df Sum of Sq     RSS     AIC\n&lt;none&gt;                 0.64508 -99.576\n+ cpfor2   1   0.01571 0.62937 -98.267\n- thtden   1   0.25092 0.89600 -92.376\n- logarea  1   0.40204 1.04712 -88.013\n\nstep.mtri$anova # display results\n\n      Step Df   Deviance Resid. Df Resid. Dev       AIC\n1          NA         NA        24  0.6293717 -98.26666\n2 - cpfor2  1 0.01570813        25  0.6450798 -99.57640\n\n\nR nous donne:\n\nLâ€™ajustement (mesurÃ© par AIC) du modÃ¨le complet en premier lieu.\nLâ€™AIC des modÃ¨les dans lesquels une variable a Ã©tÃ© enlevÃ©e du modÃ¨le complet. Notez que câ€™est seulement en enlevant cpfor2 du modÃ¨le quâ€™on peut rÃ©duire lâ€™AIC\nLa valeur de AIC pour les modÃ¨les auxquels on enlÃ¨ve ou on ajoute une variable au modÃ¨le sÃ©lectionnÃ© Ã  la premiÃ¨re Ã©tape.(i.e.Â logherp ~ logarea + thtden). Notez quâ€™aucun des modÃ¨les nâ€™a un AIC infÃ©rieur Ã  ce modÃ¨le.\n\nAu lieu de dÃ©buter par le modÃ¨le complet (saturÃ©) et enlever des termes, on peut commencer par le modÃ¨le nul et ajouter des termes:\n\n# Forward selection approach\nmodel.null &lt;- lm(logherp ~ 1, data = mydata)\nstep.f &lt;- step(\n  model.null,\n  scope = ~ . + logarea + cpfor2 + thtden, direction = \"forward\"\n)\n\nStart:  AIC=-82.09\nlogherp ~ 1\n\n          Df Sum of Sq    RSS     AIC\n+ logarea  1   0.49352 0.8960 -92.376\n+ thtden   1   0.34241 1.0471 -88.013\n+ cpfor2   1   0.12907 1.2605 -82.820\n&lt;none&gt;                 1.3895 -82.091\n\nStep:  AIC=-92.38\nlogherp ~ logarea\n\n         Df Sum of Sq     RSS     AIC\n+ thtden  1   0.25093 0.64508 -99.576\n+ cpfor2  1   0.13078 0.76522 -94.794\n&lt;none&gt;                0.89600 -92.376\n\nStep:  AIC=-99.58\nlogherp ~ logarea + thtden\n\n         Df Sum of Sq     RSS     AIC\n&lt;none&gt;                0.64508 -99.576\n+ cpfor2  1  0.015708 0.62937 -98.267\n\nstep.f$anova # display results\n\n       Step Df  Deviance Resid. Df Resid. Dev       AIC\n1           NA        NA        27  1.3895281 -82.09073\n2 + logarea -1 0.4935233        26  0.8960048 -92.37639\n3  + thtden -1 0.2509250        25  0.6450798 -99.57640\n\n\nLe rÃ©sultat final est le mÃªme, mais la trajectoire est diffÃ©rente. Dans ce cas, R dÃ©bute avec le modÃ¨le le plus simple et ajoute une variable indÃ©pendante Ã  chaque Ã©tape, sÃ©lectionnant la variable minimisant AIC Ã  cette Ã©tape. Le modÃ¨le de dÃ©part a donc seulement une ordonnÃ©e Ã  lâ€™origine. Puis, logarea est ajoutÃ©, suivi de thtden. cpfor2 nâ€™est pas ajoutÃ© au modÃ¨le, car son addition fait augmenter lâ€™AIC.\nIl est recommandÃ© de comparer le rÃ©sultat final de plusieurs approches. Si le modÃ¨le retenu diffÃ¨re selon lâ€™approche utilisÃ©e, câ€™est un signe que le â€œmeilleurâ€ modÃ¨le est possiblement difficile Ã  identifier et que vous devriez Ãªtre circonspects dans vos infÃ©rences. Dans notre exemple, pas de problÃ¨me: toutes les mÃ©thodes convergent sur le mÃªme modÃ¨le final.\nPour conclure cette section, quelques conseils concernant les mÃ©thodes automatisÃ©es de sÃ©lection des variables indÃ©pendantes:\n\nLes diffÃ©rentes mÃ©thodes de sÃ©lection des variables indÃ©pendantes peuvent mener Ã  des modÃ¨les diffÃ©rents. Il est souvent utile dâ€™essayer plus dâ€™une mÃ©thode et de comparer les rÃ©sultats. Si les rÃ©sultats diffÃ¨rent, câ€™est presque toujours Ã  cause de multicolinÃ©aritÃ© entre les variables indÃ©pendantes.\nAttention Ã  la rÃ©gression pas-Ã -pas. Les auteurs de SYSTAT en disent:\n\n\nStepwise regression is probably the most abused computerized statistical technique ever devised. If you think you need automated stepwise regression to solve a particular problem, you probably donâ€™t. Professional statisticians rarely use automated stepwise regression because it does not necessarily find the â€œbestâ€ fitting model, the â€œrealâ€ model, or alternative â€œplausibleâ€ models. Furthermore, the order in which variables enter or leave a stepwise program is usually of no theoretical significance. You are always better off thinking about why a model could generate your data and then testing that model.\n\nEn bref, on abuse trop souvent de cette technique.\n\nIl faut toujours garder Ã  lâ€™esprit que lâ€™existence dâ€™une rÃ©gression significative nâ€™est pas suffisante pour prouver une relation causale.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#dÃ©tecter-la-multicolinÃ©aritÃ©",
    "href": "35-reg_mult.html#dÃ©tecter-la-multicolinÃ©aritÃ©",
    "title": "\n8Â  RÃ©gression multiple\n",
    "section": "\n8.5 DÃ©tecter la multicolinÃ©aritÃ©",
    "text": "8.5 DÃ©tecter la multicolinÃ©aritÃ©\nLa multicolinÃ©aritÃ© est la prÃ©sence de corrÃ©lations entre les variables indÃ©pendantes. Lorsquâ€™elle est extrÃªme (multicolinÃ©aritÃ© parfaite) elle empÃªche lâ€™estimation des modÃ¨les statistiques. Lorsquâ€™elle est grande ou modÃ©rÃ©e, elle rÃ©duit la puissance de dÃ©tection de lâ€™effet des variables indÃ©pendantes individuellement, mais elle nâ€™empÃªche pas le modÃ¨le de faire des prÃ©dictions.\nUn des indices les plus utilisÃ©s pour quantifier la multicolinÃ©aritÃ© et le facteur dâ€™inflation de la variance (VIF, variance inflation factor). Le fichier dâ€™aide du package HH explique ainsi son calcul:\n\nA simple diagnostic of collinearity is the variance inflation factor, VIF one for each regression coefficient (other than the intercept). Since the condition of collinearity involves the predictors but not the response, this measure is a function of the Xâ€™s but not of Y. The VIF for predictor i is \\(1/(1-R_i^2)\\), where \\(R_i^2\\) is the \\(R^2\\) from a regression of predictor i against the remaining predictors. If \\(R_i^2\\) is close to 1, this means that predictor i is well explained by a linear function of the remaining predictors, and, therefore, the presence of predictor i in the model is redundant. Values of VIF exceeding 5 are considered evidence of collinearity: The information carried by a predictor having such a VIF is contained in a subset of the remaining predictors. If, however, all of a modelâ€™s regression coefficients differ significantly from 0 (p-value &lt; .05), a somewhat larger VIF may be tolerable.\n\nBref, les VIF indiquent de combien lâ€™incertitude de chaque coefficient de rÃ©gression est augmentÃ©e par la multicolinÃ©aritÃ©.\nAttrappe. Il y a plusieurs fonctions vif() (jâ€™en connais au moins trois dans les extensions car, HH et DAAG), et je ne sais pas en quoi elles diffÃ¨rent.\nOn peut calculer les VIF avec la fonction vif() de lâ€™extension car: :\n\nlibrary(car)\nvif(model.mtri)\n\n logarea   cpfor2   thtden \n1.022127 1.344455 1.365970 \n\n\nIci, il nâ€™y a pas dâ€™Ã©vidence de multicolinÃ©aritÃ© car toutes les valeurs de VIF sont prÃ¨s de 1.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#rÃ©gression-polynomiale",
    "href": "35-reg_mult.html#rÃ©gression-polynomiale",
    "title": "\n8Â  RÃ©gression multiple\n",
    "section": "\n8.6 RÃ©gression polynomiale",
    "text": "8.6 RÃ©gression polynomiale\nLa rÃ©gression requiert la linÃ©aritÃ© de la relation entre les variables dÃ©pendante et indÃ©pendante(s). Lorsque la relation nâ€™est pas linÃ©aire, il est parfois possible de linÃ©ariser la relation en effectuant une transformation sur une ou plusieurs variables. Cependant, dans bien des cas il est impossible de transformer les axes pour rendre la relation linÃ©aire. On doit alors utiliser une forme ou lâ€™autre de rÃ©gression nonlinÃ©aire. La forme la plus simple de rÃ©gression non-linÃ©aire est la rÃ©gression polynomiale dans laquelle les variables indÃ©pendantes sont Ã  une puissance plus grande que 1 (Ex : \\(X^2\\) ou \\(X^3\\)).\n\nFaites un diagramme de dispersion des rÃ©sidus (residual) de la rÃ©gression logherp ~ logarea en fonction de swamp .\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# problÃ¨me avec les donnÃ©es de manquantes dans logherp\nmysub &lt;- subset(mydata, !is.na(logherp))\n# ajouter les rÃ©sidus dans les donnÃ©e\nmysub$resloga &lt;- residuals(model.loga)\nggplot(data = mysub, aes(y = resloga, x = swamp)) +\n  geom_point() +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\nRelation entre swamp et les rÃ©sidus de la rÃ©gression entre logherp et logarea\n\n\n\n\n\n\n\nLâ€™examen de ce graphique suggÃ¨re quâ€™il y a une forte relation entre les deux variables, mais quâ€™elle nâ€™est pas linÃ©aire. Essayez de faire une rÃ©gression de residual sur swamp . Quelle est votre conclusion?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.resloga &lt;- lm(resloga ~ swamp, mysub)\nsummary(model.resloga)\n\n\nCall:\nlm(formula = resloga ~ swamp, data = mysub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.35088 -0.13819  0.00313  0.10849  0.45802 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  0.084571   0.109265   0.774    0.446\nswamp       -0.001145   0.001403  -0.816    0.422\n\nResidual standard error: 0.1833 on 26 degrees of freedom\nMultiple R-squared:  0.02498,   Adjusted R-squared:  -0.01252 \nF-statistic: 0.666 on 1 and 26 DF,  p-value: 0.4219\n\n\n\n\n\nEn deux mots, lâ€™ajustement est Ã©pouvantable! MalgrÃ© le fait que le graphique suggÃ¨re une relation trÃ¨s forte entre les deux variables. Cependant, cette relation nâ€™est pas linÃ©aireâ€¦ (ce qui est Ã©galement apparent si vous examinez les rÃ©sidus du modÃ¨le linÃ©aire).\n\nRefaites la rÃ©gression dâ€™en haut, mais cette fois incluez un terme pour reprÃ©senter \\(swamp^2\\) . Lâ€™expression devrait apparaÃ®tre comme: \\(Y ~ X + I(X^2)\\) . Que concluez-vous? Quâ€™est-ce que lâ€™examen des rÃ©sidus de cette rÃ©gression multiple rÃ©vÃ¨le?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.resloga2 &lt;- lm(resloga ~ swamp + I(swamp^2), mysub)\nsummary(model.resloga2)\n\n\nCall:\nlm(formula = resloga ~ swamp + I(swamp^2), data = mysub)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.181185 -0.085350  0.007377  0.067327  0.242455 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -7.804e-01  1.569e-01  -4.975 3.97e-05 ***\nswamp        3.398e-02  5.767e-03   5.892 3.79e-06 ***\nI(swamp^2)  -2.852e-04  4.624e-05  -6.166 1.90e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1177 on 25 degrees of freedom\nMultiple R-squared:  0.6132,    Adjusted R-squared:  0.5823 \nF-statistic: 19.82 on 2 and 25 DF,  p-value: 6.972e-06\n\n\n\n\n\nIl devient Ã©vident que si on corrige la richesse spÃ©cifique pour la taille des marais, une fraction importante de la variabilitÃ© rÃ©siduelle peut Ãªtre associÃ©e Ã  swamp, selon une relation quadratique. Si vous examinez les rÃ©sidus, vous observerez que lâ€™ajustement est nettement meilleur quâ€™avec le modÃ¨le linÃ©aire.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npar(mfrow = c(2, 2))\nplot(model.resloga2)\n\n\n\nRelation\n\n\n\n\n\n\n\nEn vous basant sur les rÃ©sultats de la derniÃ¨re analyse, comment suggÃ©rez-vous de modifier le modÃ¨le de rÃ©gression multiple? Quel est, dâ€™aprÃ¨s vous, le meilleur modÃ¨le? Pourquoi? Ordonnez les diffÃ©rents facteurs en ordre croissant de leur effet sur la richesse spÃ©cifique des reptiles.\n\nSuite Ã  ces analyses, il semble opportun dâ€™essayer dâ€™ajuster un modÃ¨le incluant logarea, thtden, cpfor2, swamp et swamp^2 :\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.poly1 &lt;- lm(\n  logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2),\n  data = mydata\n)\nsummary(model.poly1)\n\n\nCall:\nlm(formula = logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2), \n    data = mydata)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.201797 -0.056170 -0.002072  0.051814  0.205626 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -3.203e-01  1.813e-01  -1.766   0.0912 .  \nlogarea      2.202e-01  3.893e-02   5.656 1.09e-05 ***\ncpfor2      -7.864e-04  9.955e-04  -0.790   0.4380    \nthtden      -2.929e-02  1.048e-02  -2.795   0.0106 *  \nswamp        3.113e-02  5.898e-03   5.277 2.70e-05 ***\nI(swamp^2)  -2.618e-04  4.727e-05  -5.538 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1072 on 22 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.8181,    Adjusted R-squared:  0.7767 \nF-statistic: 19.78 on 5 and 22 DF,  p-value: 1.774e-07\n\n\n\n\n\nLes rÃ©sultats de cette analyse suggÃ¨rent quâ€™on devrait probablement exclure cpfor2 du modÃ¨le:\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.poly2 &lt;- lm(\n  logherp ~ logarea + thtden + swamp + I(swamp^2),\n  data = mydata\n)\nsummary(model.poly2)\n\n\nCall:\nlm(formula = logherp ~ logarea + thtden + swamp + I(swamp^2), \n    data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.19621 -0.05444 -0.01202  0.07116  0.21295 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -3.461e-01  1.769e-01  -1.957   0.0626 .  \nlogarea      2.232e-01  3.842e-02   5.810 6.40e-06 ***\nthtden      -2.570e-02  9.364e-03  -2.744   0.0116 *  \nswamp        2.956e-02  5.510e-03   5.365 1.89e-05 ***\nI(swamp^2)  -2.491e-04  4.409e-05  -5.649 9.46e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1063 on 23 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.8129,    Adjusted R-squared:  0.7804 \nF-statistic: 24.98 on 4 and 23 DF,  p-value: 4.405e-08\n\n\n\n\n\nEst-ce quâ€™il y a possiblement un problÃ¨me de multicolinÃ©aritÃ©?\n\nvif(model.poly2)\n\n   logarea     thtden      swamp I(swamp^2) \n  1.053193   1.123491  45.845845  45.656453 \n\n\nLes valeurs dâ€™inflation de la variance (VIF) pour les deux termes de swamp sont beaucoup plus Ã©levÃ©s que le seuil de 5. Cependant, câ€™est la norme pour les termes polynomiaux et on ne doit pas sâ€™en prÃ©occuper outre mesure, surtout quand les deux termes sont hautement significatifs dans le modÃ¨le. Les fortes valeurs de VIF indiquent que les coefficients pour ces deux termes ne sont pas estimÃ©s prÃ©cisÃ©ment, mais leur utilisation dans le modÃ¨le permet tout de mÃªme de faire de bonnes prÃ©dictions (i.e.Â ils dÃ©crivent la rÃ©ponse Ã  swamp).",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#vÃ©rifier-les-conditions-dapplication-de-modÃ¨les-de-rÃ©gression-multiple",
    "href": "35-reg_mult.html#vÃ©rifier-les-conditions-dapplication-de-modÃ¨les-de-rÃ©gression-multiple",
    "title": "\n8Â  RÃ©gression multiple\n",
    "section": "\n8.7 VÃ©rifier les conditions dâ€™application de modÃ¨les de rÃ©gression multiple",
    "text": "8.7 VÃ©rifier les conditions dâ€™application de modÃ¨les de rÃ©gression multiple\nToutes les techniques de sÃ©lection des modÃ¨les prÃ©sument que les conditions dâ€™applications (indÃ©pendance, normalitÃ©, homoscÃ©dasticitÃ©, linÃ©aritÃ©) sont remplies. Comme il y a un grand nombre de modÃ¨les qui peuvent Ãªtre ajustÃ©s, il peut paraÃ®tre quasi impossible de vÃ©rifier si les conditions sont remplies Ã  chaque Ã©tape de construction. Cependant, il est souvent suffisant dâ€™examiner les rÃ©sidus du modÃ¨le complet (saturÃ©) puis du modÃ¨le final. Les termes qui ne contribuent pas significativement Ã  lâ€™ajustement nâ€™affectent pas beaucoup les rÃ©sidus et donc les rÃ©sidus du modÃ¨le final sont gÃ©nÃ©ralement similaires Ã  ceux du modÃ¨le complet.\nExaminons donc les graphiques diagnostiques du modÃ¨le final:\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npar(mfrow = c(2, 2))\nplot(model.poly2)\n\n\n\nConditions dâ€™application du modÃ¨le model.poly2\n\n\n\n\n\n\nTout semble acceptable dans ce cas. Pour convaincre les sceptiques, on peut faire les tests formels des conditions dâ€™application:\n\nshapiro.test(residuals(model.poly2))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(model.poly2)\nW = 0.9837, p-value = 0.9278\n\n\nLes rÃ©sidus ne dÃ©vient pas significativement de la normalitÃ©. Bien.\n\nlibrary(lmtest)\nbptest(model.poly2)\n\n\n    studentized Breusch-Pagan test\n\ndata:  model.poly2\nBP = 3.8415, df = 4, p-value = 0.4279\n\n\nPas de dÃ©viation dâ€™homoscÃ©dasticitÃ© non plus. Bien.\n\ndwtest(model.poly2)\n\n\n    Durbin-Watson test\n\ndata:  model.poly2\nDW = 1.725, p-value = 0.2095\nalternative hypothesis: true autocorrelation is greater than 0\n\n\nPas de corrÃ©lation sÃ©rielle des rÃ©sidus, donc pas dâ€™Ã©vidence de nonindÃ©pendance.\n\nresettest(model.poly2, type = \"regressor\", data = mydata)\n\n\n    RESET test\n\ndata:  model.poly2\nRESET = 0.9823, df1 = 8, df2 = 15, p-value = 0.4859\n\n\nEt finalement, pas de dÃ©viation significative de la linÃ©aritÃ©. Donc tout semble acceptable.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#visualiser-la-taille-deffet",
    "href": "35-reg_mult.html#visualiser-la-taille-deffet",
    "title": "\n8Â  RÃ©gression multiple\n",
    "section": "\n8.8 Visualiser la taille dâ€™effet",
    "text": "8.8 Visualiser la taille dâ€™effet\nLes coefficients de la rÃ©gression multiple peuvent mesurer la taille dâ€™effet, quoiquâ€™il puisse Ãªtre nÃ©cessaire de les standardiser pour quâ€™ils ne soient pas influencÃ©s par les unitÃ©s de mesure. Mais un graphique est souvent plus informatif. Dans ce contexte, les graphiques des rÃ©sidus partiels (appelÃ©s components+residual plots dans R) sont particuliÃ¨rement utiles. Ces graphique illustrent comment la variable dÃ©pendante, corrigÃ©e pour lâ€™effet des autres variables dans le modÃ¨le, varie avec chacune des variables indÃ©pendantes du modÃ¨le. Voyons voir:\n\n# Evaluate visually linearity and effect size\n# component + residual plot\ncrPlots(model.poly2)\n\n\n\nGraphiques de rÃ©sidus partiels du modÃ¨le model.poly2\n\n\n\nNotez que lâ€™Ã©chelle de lâ€™axe des y varie sur chaque graphique. Pour thtden, la variable dÃ©pendante (log10(richesse des herptiles)) varie dâ€™environ 0.4 unitÃ©s entre la valeur minimum et maximum de thtden. Pour logarea, la variation est dâ€™environ 0.6 unitÃ© log. Pour swamp, lâ€™interprÃ©tation est plus compliquÃ©e parce quâ€™il y a deux termes qui quantifient son effet, et que ces termes ont des signes opposÃ©s (positif pour swamp et nÃ©gatif pour swamp^2) ce qui donne une relation curvilinÃ©aire de type parabole. Le graphique ne permet pas de bien visualiser cela. Ceci dit, ces graphique nâ€™indiquent pas vraiment de violation de linÃ©aritÃ©.\nPour illustrer ce qui serait visible sur ces graphiques si il y avait une dÃ©viation de linÃ©aritÃ©, enlevons le terme du second degrÃ© pour swamp, puis on va refaire ces graphiques et effectuer le test RESET.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.nopoly &lt;- lm(\n  logherp ~ logarea + thtden + swamp,\n  data = mydata\n)\ncrPlots(model.nopoly)\n\n\n\nGraphiques de rÃ©sidus partiels du modÃ¨le model.nopoly\n\n\n\n\n\n\nLa relation non-linÃ©aire avec swamp devient Ã©vidente. Et le test RESET dÃ©tecte bien cette non-linÃ©aritÃ©:\n\nresettest(model.nopoly, type = \"regressor\")\n\n\n    RESET test\n\ndata:  model.nopoly\nRESET = 6.7588, df1 = 6, df2 = 18, p-value = 0.0007066",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#tester-la-prÃ©sence-dinteractions",
    "href": "35-reg_mult.html#tester-la-prÃ©sence-dinteractions",
    "title": "\n8Â  RÃ©gression multiple\n",
    "section": "\n8.9 Tester la prÃ©sence dâ€™interactions",
    "text": "8.9 Tester la prÃ©sence dâ€™interactions\nLorsquâ€™il y a plusieurs variables indÃ©pendantes, vous devriez toujours garder Ã  lâ€™esprit la possibilitÃ© dâ€™interactions. Dans la majoritÃ© des situations de rÃ©gression multiple cela nâ€™est pas Ã©vident parce que lâ€™addition de termes dâ€™interaction augmente la multicolinÃ©aritÃ© des termes du modÃ¨le, et parce quâ€™il nâ€™y a souvent pas assez dâ€™observations pour Ã©prouver toutes les interactions ou que les observations ne sont pas suffisamment balancÃ©es pour faire des tests puissants pour les interactions. Retournons Ã  notre modÃ¨le â€œfinalâ€ et voyons ce qui se passe si on essaie dâ€™ajuster un modÃ¨le saturÃ© avec toutes les interactions:\n\nfullmodel.withinteractions &lt;- lm(\n  logherp ~ logarea * cpfor2 * thtden * swamp * I(swamp^2),\n  data = mydata\n)\nsummary(fullmodel.withinteractions)\n\n\nCall:\nlm(formula = logherp ~ logarea * cpfor2 * thtden * swamp * I(swamp^2), \n    data = mydata)\n\nResiduals:\nALL 28 residuals are 0: no residual degrees of freedom!\n\nCoefficients: (4 not defined because of singularities)\n                                         Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)                            -5.948e+03        NaN     NaN      NaN\nlogarea                                 3.293e+03        NaN     NaN      NaN\ncpfor2                                  7.080e+01        NaN     NaN      NaN\nthtden                                  9.223e+02        NaN     NaN      NaN\nswamp                                   1.176e+02        NaN     NaN      NaN\nI(swamp^2)                             -3.517e-01        NaN     NaN      NaN\nlogarea:cpfor2                         -3.771e+01        NaN     NaN      NaN\nlogarea:thtden                         -4.781e+02        NaN     NaN      NaN\ncpfor2:thtden                          -1.115e+01        NaN     NaN      NaN\nlogarea:swamp                          -7.876e+01        NaN     NaN      NaN\ncpfor2:swamp                           -1.401e+00        NaN     NaN      NaN\nthtden:swamp                           -1.920e+01        NaN     NaN      NaN\nlogarea:I(swamp^2)                      5.105e-01        NaN     NaN      NaN\ncpfor2:I(swamp^2)                       3.825e-03        NaN     NaN      NaN\nthtden:I(swamp^2)                       7.826e-02        NaN     NaN      NaN\nswamp:I(swamp^2)                       -2.455e-03        NaN     NaN      NaN\nlogarea:cpfor2:thtden                   5.359e+00        NaN     NaN      NaN\nlogarea:cpfor2:swamp                    8.743e-01        NaN     NaN      NaN\nlogarea:thtden:swamp                    1.080e+01        NaN     NaN      NaN\ncpfor2:thtden:swamp                     2.620e-01        NaN     NaN      NaN\nlogarea:cpfor2:I(swamp^2)              -5.065e-03        NaN     NaN      NaN\nlogarea:thtden:I(swamp^2)              -6.125e-02        NaN     NaN      NaN\ncpfor2:thtden:I(swamp^2)               -1.551e-03        NaN     NaN      NaN\nlogarea:swamp:I(swamp^2)               -4.640e-04        NaN     NaN      NaN\ncpfor2:swamp:I(swamp^2)                 3.352e-05        NaN     NaN      NaN\nthtden:swamp:I(swamp^2)                 2.439e-04        NaN     NaN      NaN\nlogarea:cpfor2:thtden:swamp            -1.235e-01        NaN     NaN      NaN\nlogarea:cpfor2:thtden:I(swamp^2)        7.166e-04        NaN     NaN      NaN\nlogarea:cpfor2:swamp:I(swamp^2)                NA         NA      NA       NA\nlogarea:thtden:swamp:I(swamp^2)                NA         NA      NA       NA\ncpfor2:thtden:swamp:I(swamp^2)                 NA         NA      NA       NA\nlogarea:cpfor2:thtden:swamp:I(swamp^2)         NA         NA      NA       NA\n\nResidual standard error: NaN on 0 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:      1, Adjusted R-squared:    NaN \nF-statistic:   NaN on 27 and 0 DF,  p-value: NA\n\n\nNotez les coefficients manquants aux derniÃ¨res lignes: on ne peut inclure les 32 termes si on a seulement 28 observations. Il manque des observations, le R carrÃ© est 1, et le modÃ¨le â€œprÃ©ditâ€ parfaitement les donnÃ©es.\nSi on essaie une mÃ©thode automatique pour identifier le â€œmeilleurâ€ modÃ¨le dans ce gÃ¢chis, R refuse:\n\nstep(fullmodel.withinteractions)\n\nError in step(fullmodel.withinteractions): AIC is -infinity for this model, so 'step' cannot proceed\n\n\nBon, est-ce quâ€™on oublie tout Ã§a et quâ€™on accepte le modÃ¨le final sans ce soucier des interactions? Non, pas encore. Il y a un compromis possible: comparer notre modÃ¨le â€œfinalâ€ Ã  un modÃ¨le qui contient au moins un sous-ensemble des interactions, par exemple toutes les interactions du second degrÃ©, pour Ã©prouver si lâ€™addition de ces interactions amÃ©liore beaucoup lâ€™ajustement du modÃ¨le.\n\nfull.model.2ndinteractions &lt;- lm(\n  logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2)\n    + logarea:cpfor2\n    + logarea:thtden\n    + logarea:swamp\n    + cpfor2:thtden\n    + cpfor2:swamp\n    + thtden:swamp,\n  data = mydata\n)\nsummary(full.model.2ndinteractions)\n\n\nCall:\nlm(formula = logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2) + \n    logarea:cpfor2 + logarea:thtden + logarea:swamp + cpfor2:thtden + \n    cpfor2:swamp + thtden:swamp, data = mydata)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.216880 -0.036534  0.003506  0.042990  0.175490 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     4.339e-01  6.325e-01   0.686 0.502581    \nlogarea        -1.254e-01  2.684e-01  -0.467 0.646654    \ncpfor2         -9.344e-03  7.205e-03  -1.297 0.213032    \nthtden         -1.833e-01  9.035e-02  -2.028 0.059504 .  \nswamp           3.569e-02  7.861e-03   4.540 0.000334 ***\nI(swamp^2)     -3.090e-04  7.109e-05  -4.347 0.000500 ***\nlogarea:cpfor2  2.582e-03  2.577e-03   1.002 0.331132    \nlogarea:thtden  7.017e-02  3.359e-02   2.089 0.053036 .  \nlogarea:swamp  -5.290e-04  2.249e-03  -0.235 0.816981    \ncpfor2:thtden  -2.095e-04  6.120e-04  -0.342 0.736544    \ncpfor2:swamp    4.651e-05  5.431e-05   0.856 0.404390    \nthtden:swamp    2.248e-04  4.764e-04   0.472 0.643336    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.108 on 16 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.8658,    Adjusted R-squared:  0.7735 \nF-statistic: 9.382 on 11 and 16 DF,  p-value: 4.829e-05\n\n\nCe modÃ¨le sâ€™ajuste un peu mieux aux donnÃ©es que les modÃ¨le â€œfinalâ€ (il explique 86.6% de la variance de logherp, comparÃ© Ã  81.2% pour le modÃ¨le â€œfinalâ€ sans interactions), mais il compte deux fois plus de paramÃ¨tres. De plus, si vous examinez les coefficients, il se passe dâ€™Ã©tranges choses: le signe pour logare a changÃ© par exemple. Câ€™est un des symptÃ´mes de la multicolinÃ©aritÃ©. Allons voir les facteurs dâ€™inflation de la variance:\n\nvif(full.model.2ndinteractions)\n\nthere are higher-order terms (interactions) in this model\nconsider setting type = 'predictor'; see ?vif\n\n\n       logarea         cpfor2         thtden          swamp     I(swamp^2) \n      49.86060       78.49622      101.42437       90.47389      115.08457 \nlogarea:cpfor2 logarea:thtden  logarea:swamp  cpfor2:thtden   cpfor2:swamp \n      66.97792       71.69894       67.27034       14.66814       29.41422 \n  thtden:swamp \n      20.04410 \n\n\nAie! tous les VIF sont plus grands que 5, pas seulement les termes incluant swamp. Cette forte multicolinÃ©aritÃ© empÃªche de quantifier avec prÃ©cision lâ€™effet de ces interactions. De plus, ce modÃ¨le avec interactions nâ€™est pas plus informatif que le modÃ¨le â€œfinalâ€ puisque son AIC est plus Ã©levÃ© (souvenez-vous quâ€™on privilÃ©gie le modÃ¨le avec la valeur dâ€™AIC la plus basse):\n\nAIC(model.poly1)\n\n[1] -38.3433\n\nAIC(full.model.2ndinteractions)\n\n[1] -34.86123\n\n\nOn peut Ã©galement utiliser la fonction anova() pour comparer lâ€™ajustement des deux modÃ¨les et vÃ©rifier si lâ€™addition des termes dâ€™intÃ©ration amÃ©liore significativement lâ€™ajustement:\n\nanova(model.poly1, full.model.2ndinteractions)\n\nAnalysis of Variance Table\n\nModel 1: logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2)\nModel 2: logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2) + logarea:cpfor2 + \n    logarea:thtden + logarea:swamp + cpfor2:thtden + cpfor2:swamp + \n    thtden:swamp\n  Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)\n1     22 0.25282                           \n2     16 0.18651  6  0.066314 0.9481  0.489\n\n\nIci, lâ€™addition des termes dâ€™interaction ne rÃ©duit pas significativement la variabilitÃ© rÃ©siduelle du modÃ¨le â€œcompletâ€. Quâ€™en est-il de la si on compare le modÃ¨le avec interaction et notre modÃ¨le â€œfinalâ€?\n\nanova(model.poly2, full.model.2ndinteractions)\n\nAnalysis of Variance Table\n\nModel 1: logherp ~ logarea + thtden + swamp + I(swamp^2)\nModel 2: logherp ~ logarea + cpfor2 + thtden + swamp + I(swamp^2) + logarea:cpfor2 + \n    logarea:thtden + logarea:swamp + cpfor2:thtden + cpfor2:swamp + \n    thtden:swamp\n  Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)\n1     23 0.25999                           \n2     16 0.18651  7  0.073486 0.9006 0.5294\n\n\nLe test indique que ces deux modÃ¨les ont des variances rÃ©siduelles comparables, et donc que lâ€™addition des termes dâ€™interaction et de cpfor2 au modÃ¨le final nâ€™apporte pas grand chose.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#recherche-du-meilleur-modÃ¨le-fondÃ©e-sur-la-thÃ©orie-de-linformation",
    "href": "35-reg_mult.html#recherche-du-meilleur-modÃ¨le-fondÃ©e-sur-la-thÃ©orie-de-linformation",
    "title": "\n8Â  RÃ©gression multiple\n",
    "section": "\n8.10 Recherche du meilleur modÃ¨le fondÃ©e sur la thÃ©orie de lâ€™information",
    "text": "8.10 Recherche du meilleur modÃ¨le fondÃ©e sur la thÃ©orie de lâ€™information\nUne des principales critiques des mÃ©thodes pas-Ã -pas (stepwise) est que les valeurs de p ne sont pas strictement interprÃ©tables Ã  cause du grand nombre de tests qui sont implicites dans le processus. Câ€™est le problÃ¨me des comparaisons ou tests multiples: en construisant un modÃ¨le linÃ©aire (comme une rÃ©gression multiple) Ã  partir dâ€™un grand nombre de variables et de leurs interactions, il y a tellement de combinaisons possibles quâ€™un ajustement de Bonferroni rendrait les tests trop conservateurs.\nUne alternative, dÃ©fendue par Burnham et Anderson (2002, Model selection and multimodel inference: a practical information-theoretic approach. 2nd ed), est dâ€™utiliser lâ€™AIC (ou mieux encore AICc qui est plus appropriÃ© quand le nombre dâ€™observations est infÃ©rieur Ã  40 fois le nombre de variables indÃ©pendantes) pour ordonner les modÃ¨les et identifier un sousensemble de modÃ¨les qui sont les meilleurs. On peut ensuite calculer les moyennes des coefficients pondÃ©rÃ©es par la probabilitÃ© que chacun des modÃ¨les soit le meilleur pour obtenir des coefficients qui sont plus robustes et moins sensibles Ã  la multicolinÃ©aritÃ©.\nLâ€™approche de comparaison par AIC a dâ€™abord Ã©tÃ© dÃ©veloppÃ© pour comparer un ensemble de modÃ¨le prÃ©alablement dÃ©fini basÃ© sur les connaissance du sytÃ¨me et les hypothÃ¨ses biologiques. Cependant, certains ont dÃ©veloppÃ© une approche plutÃ´t brutale et sans scrupule de faire tous les modÃ¨les possibles et de les comparer par AIC. Cette approche a Ã©tÃ© suivie dans le package MuMIn. Les comparaisons de modÃ¨le par AICdoivent Ãªtre faites en utilisant exactement le mÃªme jeu de donnÃ©es pour chaque modÃ¨le. Il faut donc sâ€™arrurer dâ€™enlever les donnÃ©es manquantes et de spÃ©cifier dans la fonction lm de ne pas marcher sâ€™il y a des donnÃ©es manquantes.\n\n\n\n\n\n\nNote\n\n\n\nJe ne supporte pas lâ€™approche stepwise ni lâ€™approche par AIC. Je dÃ©teste lâ€™approche par la fonction dredge() qui selon moi va Ã  lâ€™encontre de la philosophie des AIC et de la parsimonie. Je soutiens de dÃ©velooper un modÃ¨le basÃ© sur des hypothÃ¨ses biologiques et de reporter ce modÃ¨le avec tous les effets significatifs ou non.\n\n\n\n# refaire le modÃ¨le en s'assurant qu'il n'y a pas de \"NA\" et en spÃ©cificant na.action\nfull.model.2ndinteractions &lt;- update(\n  full.model.2ndinteractions,\n  . ~ .,\n  data = mysub,\n  na.action = \"na.fail\"\n)\n\nlibrary(MuMIn)\ndd &lt;- dredge(full.model.2ndinteractions)\n\nFixed term is \"(Intercept)\"\n\n\nLâ€™objet dd contient tous les modÃ¨les possibles (i.e.Â ceux qui ont toutes les combinaisons possibles) en utilisant les termes du modÃ¨le full.model.2ndinteractions ajustÃ© prÃ©cÃ©demment. On peut ensuite extraire de lâ€™objet dd le sous-ensemble de modÃ¨les qui ont un AICc semblable au meilleur modÃ¨le (Burnham et Anderson suggÃ¨rent que les modÃ¨les qui dÃ©vient par plus de 7 unitÃ©s dâ€™AICc du meilleur modÃ¨le ont peu de support empirique).\n\n# get models within 2 units of AICc from the best model\ntop.models.1 &lt;- get.models(dd, subset = delta &lt; 2)\navgmodel1 &lt;- model.avg(top.models.1) # compute average parameters\nsummary(avgmodel1) # display averaged model\n\n\nCall:\nmodel.avg(object = top.models.1)\n\nComponent model call: \nlm(formula = logherp ~ &lt;2 unique rhs&gt;, data = mysub, na.action = \n     na.fail)\n\nComponent models: \n      df logLik   AICc delta weight\n12345  7  27.78 -35.95  0.00   0.55\n1234   6  25.78 -35.56  0.39   0.45\n\nTerm codes: \n    I(swamp^2)        logarea          swamp         thtden logarea:thtden \n             1              2              3              4              5 \n\nModel-averaged coefficients:  \n(full average) \n                 Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)    \n(Intercept)    -2.145e-01  2.308e-01   2.406e-01   0.891    0.373    \nlogarea         1.356e-01  1.089e-01   1.119e-01   1.213    0.225    \nswamp           3.180e-02  5.971e-03   6.273e-03   5.070    4e-07 ***\nI(swamp^2)     -2.669e-04  4.770e-05   5.011e-05   5.326    1e-07 ***\nthtden         -6.985e-02  5.233e-02   5.361e-02   1.303    0.193    \nlogarea:thtden  2.131e-02  2.487e-02   2.545e-02   0.837    0.403    \n \n(conditional average) \n                 Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)    \n(Intercept)    -2.145e-01  2.308e-01   2.406e-01   0.891   0.3727    \nlogarea         1.356e-01  1.089e-01   1.119e-01   1.213   0.2253    \nswamp           3.180e-02  5.971e-03   6.273e-03   5.070    4e-07 ***\nI(swamp^2)     -2.669e-04  4.770e-05   5.011e-05   5.326    1e-07 ***\nthtden         -6.985e-02  5.233e-02   5.361e-02   1.303   0.1927    \nlogarea:thtden  3.882e-02  2.114e-02   2.237e-02   1.735   0.0827 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nconfint(avgmodel1) # display CI for averaged coefficients\n\n                       2.5 %       97.5 %\n(Intercept)    -0.6860022996  0.257064603\nlogarea        -0.0836067896  0.354883299\nswamp           0.0195105703  0.044099316\nI(swamp^2)     -0.0003650809 -0.000168656\nthtden         -0.1749296690  0.035236794\nlogarea:thtden -0.0050266778  0.082666701\n\n\n\nLa liste des modÃ¨les qui sont Ã  4 unitÃ©s ou moins de lâ€™AICc du meilleur modÃ¨le. Les variables dans chaque modÃ¨le sont codÃ©es et on retrouve la clÃ© en dessous du tableau.\nPour chaque modÃ¨le, en plus de lâ€™AICc, le poids Akaike est calculÃ©. Câ€™est un estimÃ© de la probabilitÃ© que ce modÃ¨le est le meilleur. Ici on voit que le premier modÃ¨le (le meilleur) a seulement 34% des chance dâ€™Ãªtre vraiment le meilleur.\nÃ€ partir de ce sous-ensemble de modÃ¨les, la moyenne pondÃ©rÃ©e des coefficients (en utilisant les poids Akaike) est calculÃ©e, avec in IC Ã  95%. Notez que les termes absents dâ€™un modÃ¨le sont considÃ©rÃ©s avoir un coefficient de 0 pour ce terme.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#bootstrap-et-rÃ©gression-multiple",
    "href": "35-reg_mult.html#bootstrap-et-rÃ©gression-multiple",
    "title": "\n8Â  RÃ©gression multiple\n",
    "section": "\n8.11 Bootstrap et rÃ©gression multiple",
    "text": "8.11 Bootstrap et rÃ©gression multiple\nQuand les donnÃ©es ne rencontrent pas les conditions dâ€™application de normalitÃ© et dâ€™homoscÃ©dasticitÃ© et que les transformations nâ€™arrivent pas Ã  corriger ces violations, le bootstrap peut Ãªtre utilisÃ© pour calculer des intervalles de confiance pour les coefficients. Si la distribution des coefficients bootstrappÃ©s est symÃ©trique et approximativement normale, on peut utiliser les percentiles empiriques pour calculer les limites de confiance.\nLe code qui suit, utilisant le package simpleboot, a Ã©tÃ© conÃ§u pour Ãªtre facilement modifiable et calcule les limites des IC Ã  partir des percentiles empiriques.\n\n############################################################\n#######\n# Bootstrap analysis the simple way with library simpleboot\n# Define model to be bootstrapped and the data source used\nmymodel &lt;- lm(logherp ~ logarea + thtden + swamp + I(swamp^2), data = mydata)\n# Set the number of bootstrap iterations\nnboot &lt;- 1000\nlibrary(simpleboot)\n# R is the number of bootstrap iterations\n# Setting rows to FALSE indicates resampling of residuals\nmysimpleboot &lt;- lm.boot(mymodel, R = nboot, rows = FALSE)\n# Extract bootstrap coefficients\nmyresults &lt;- sapply(mysimpleboot$boot.list, function(x) x$coef)\n# Transpose matrix so that lines are bootstrap iterations and columns are coefficients\ntmyresults &lt;- t(myresults)\n\nVous pouvez ensuite faire des graphiques pour voir les rÃ©sultats. Lorsque vous tournerez ce code, il y aura une pause pour vous permettre dâ€™examiner la distribution pour chaque coefficient du modÃ¨le sur des graphiques:\n\n# Plot histograms of bootstrapped coefficients\nncoefs &lt;- length(data.frame(tmyresults))\npar(mfrow = c(1, 2), mai = c(0.5, 0.5, 0.5, 0.5), ask = TRUE)\nfor (i in 1:ncoefs) {\n  lab &lt;- colnames(tmyresults)[i]\n  x &lt;- tmyresults[, i]\n  plot(density(x), main = lab, xlab = \"\")\n  abline(v = mymodel$coef[i], col = \"red\")\n  abline(v = quantile(x, c(0.025, 0.975)))\n  hist(x, main = lab, xlab = \"\")\n  abline(v = quantile(x, c(0.025, 0.975)))\n  abline(v = mymodel$coef[i], col = \"red\")\n}\n\n\n\n\n\nDistribution des estimÃ© par bootstrap pour logarea\n\n\n\nLe graphique de droite illustre la densitÃ© lissÃ©e (kernel density) et celui de gauche est lâ€™histogramme des estimÃ©s bootstrap du coefficient. La ligne rouge sur le graphique indique la valeur du coefficient ordinaire (pas bootstrap) et les deux lignes verticales noires marquent les limites de lâ€™intervalle de confiance Ã  95%. Ici lâ€™IC ne contient pas 0, et donc on peut conclure que lâ€™effet de logarea sur logherp est significativement positif.\nLes limites prÃ©cises peuvent Ãªtre obtenues par:\n\n# Display empirical bootstrap quantiles (not corrected for bias)\np &lt;- c(0.005, 0.01, 0.025, 0.05, 0.95, 0.975, 0.99, 0.995)\napply(tmyresults, 2, quantile, p)\n\n      (Intercept)   logarea       thtden      swamp    I(swamp^2)\n0.5%  -0.76307584 0.1291407 -0.047584473 0.01772250 -0.0003497203\n1%    -0.72831577 0.1409443 -0.046010909 0.01863688 -0.0003424577\n2.5%  -0.66810810 0.1575280 -0.042287583 0.02058147 -0.0003247691\n5%    -0.60753598 0.1681706 -0.039566732 0.02145910 -0.0003126071\n95%   -0.09290077 0.2808696 -0.011264473 0.03773842 -0.0001842991\n97.5% -0.03427477 0.2943330 -0.008526632 0.03888998 -0.0001770746\n99%   -0.01146876 0.3031307 -0.005051748 0.04089202 -0.0001621921\n99.5%  0.01210649 0.3091569 -0.002046873 0.04175795 -0.0001581856\n\n\nCes intervalles de confiances ne sont pas fiables si la distribution des estimÃ©s bootstrap nâ€™est pas Gaussienne. Dans ce cas, il vaut mieux calculer des coefficients non-biaisÃ©s (bias-corrected accelerated confidence limits, BCa):\n\n################################################\n# Bootstrap analysis in multiple regression with BCa confidence intervals\n# Preferable when parameter distribution is far from normal\n# Bootstrap 95% BCa CI for regression coefficients\n\nlibrary(boot)\n# function to obtain regression coefficients for each iteration\nbs &lt;- function(formula, data, indices) {\n  d &lt;- data[indices, ] # allows boot to select sample\n  fit &lt;- lm(formula, data = d)\n  return(coef(fit))\n}\n# bootstrapping with 1000 replications\nresults &lt;- boot(\n  data = mydata, statistic = bs, R = 1000,\n  formula = logherp ~ logarea + thtden + swamp + I(swamp^2)\n)\n# view results\n\nPour obtenir les rÃ©sultats, le code suivant va produire le graphique standard pour chaque coefficient, et les estimÃ©s BCa pour lâ€™intervalle de confiance\n\nplot(results, index = 1) # intercept\nplot(results, index = 2) # logarea\nplot(results, index = 3) # thtden\nplot(results, index = 4) # swamp\nplot(results, index = 5) # swamp^2\n\n# get 95% confidence intervals\nboot.ci(results, type = \"bca\", index = 1)\nboot.ci(results, type = \"bca\", index = 2)\nboot.ci(results, type = \"bca\", index = 3)\nboot.ci(results, type = \"bca\", index = 4)\nboot.ci(results, type = \"bca\", index = 5)\n\nPour logarea, cela donne:\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results, type = \"bca\", index = 2)\n\nIntervals : \nLevel       BCa          \n95%   ( 0.1118,  0.3206 )  \nCalculations and Intervals on Original Scale\n\n\n\n\n\n\n\n\nNotez que lâ€™intervalle BCa va de 0.12 Ã  0.32, alors que lâ€™intervalle standard Ã©tait de 0.16 Ã  0.29. Lâ€™intervalle BCa est ici plus grand du cÃ´tÃ© infÃ©rieur et plus petit du cÃ´tÃ© supÃ©rieur comme il se doit compte tenu de la distribution non-Gaussienne et asymÃ©trique des estimÃ©s bootstrap.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "35-reg_mult.html#perm_reg_mult",
    "href": "35-reg_mult.html#perm_reg_mult",
    "title": "\n8Â  RÃ©gression multiple\n",
    "section": "\n8.12 Test de permutation",
    "text": "8.12 Test de permutation\nLes tests de permutations sont plus rarement effectuÃ©s en rÃ©gression multiple que le bootstrap. Voici un fragment de code pour le faire tout de mÃªme.\n\n############################################################\n##########\n# Permutation in multiple regression\n#\n# using lmperm library\nlibrary(lmPerm)\n# Fit desired model on the desired dataframe\nmymodel &lt;- lm(logherp ~ logarea + thtden + swamp + I(swamp^2),\n  data = mydata\n)\nmymodelProb &lt;- lmp(\n  logherp ~ logarea + thtden + swamp + I(swamp^2),\n  data = mydata, perm = \"Prob\"\n)\nsummary(mymodel)\nsummary(mymodelProb)",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>RÃ©gression multiple</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html",
    "href": "36-ancova_glm.html",
    "title": "\n9Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "",
    "text": "9.1 Paquets et donnÃ©es requises pour le labo\nCe laboratoire nÃ©cessite:",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html#set-anco",
    "href": "36-ancova_glm.html#set-anco",
    "title": "\n9Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "",
    "text": "les paquets R:\n\nggplot2\ncar\nlmtest\n\n\nles fichiers de donnÃ©es\n\nanc1dat.csv\nanc3dat.csv",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html#modÃ¨le-linÃ©aire-gÃ©nÃ©ral",
    "href": "36-ancova_glm.html#modÃ¨le-linÃ©aire-gÃ©nÃ©ral",
    "title": "\n9Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "\n9.2 ModÃ¨le linÃ©aire gÃ©nÃ©ral",
    "text": "9.2 ModÃ¨le linÃ©aire gÃ©nÃ©ral\nLes modÃ¨les linÃ©aires gÃ©nÃ©raux ou General Linear Model en anglais sont diffÃ©rent des modÃ¨les linÃ©aires gÃ©nÃ©ralisÃ©s (ou generalized linear model, GLM). Les modÃ¨les linÃ©aires gÃ©nÃ©raux sont des modÃ¨les statistiques de la forme \\(Y = B \\mathbf{X} + E\\), ou Y est un vecteur contenant la variable dÃ©pendante continue, B est un vecteur des paramÃ¨tres estimÃ©s, \\(\\mathbf{X}\\) et la matrice des diffÃ©rents variables indÃ©pendantes et E est un vecteur de rÃ©sidus homoscÃ©dastiques et normalement distribuÃ©s. Tous les tests que nous avons Ã©tudiÃ©s Ã  date (test de t, rÃ©gression linÃ©aire simple, ANOVA Ã  un facteur de classification, ANOVA Ã  plusieurs facteurs de classification et rÃ©gression multiple) sont formulÃ©s ainsi. Notez que tous les modÃ¨les que nous avons rencontrÃ©s Ã  ce jour ne contiennent quâ€™un type de variable indÃ©pendante (soit continue ou discontinue). Dans cet exercice de laboratoire, vous allez ajuster des modÃ¨les qui ont les deux types de variables indÃ©pendantes.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html#ancova",
    "href": "36-ancova_glm.html#ancova",
    "title": "\n9Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "\n9.3 ANCOVA",
    "text": "9.3 ANCOVA\nANCOVA est lâ€™abrÃ©viation pour lâ€™analyse de covariance. Câ€™est un type de modÃ¨le linÃ©aire gÃ©nÃ©ral dans lequel il y a une (ou plusieurs) variable indÃ©pendante continue (parfois appelÃ© la covariable) et une (ou plusieurs) variable indÃ©pendante discontinue. Dans la prÃ©sentation traditionnelle de lâ€™ANCOVA dans les manuels de biostatistique, le modÃ¨le ANCOVA ne contient pas de termes dâ€™interaction entre les variables continues et discontinues. Par consÃ©quent, on doit prÃ©cÃ©der lâ€™ajustement de ce modÃ¨le (rÃ©duit parce que sans terme dâ€™interaction), par un test de signification de lâ€™interaction qui correspond Ã  Ã©prouver lâ€™Ã©galitÃ© des pentes (coefficients pour la ou les variables continues) entre les diffÃ©rents niveaux de la ou les variables discontinues (i.e un test dâ€™homogÃ©nÃ©itÃ© des pentes).",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html#homogÃ©nÃ©itÃ©-des-pentes",
    "href": "36-ancova_glm.html#homogÃ©nÃ©itÃ©-des-pentes",
    "title": "\n9Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "\n9.4 HomogÃ©nÃ©itÃ© des pentes",
    "text": "9.4 HomogÃ©nÃ©itÃ© des pentes\nPour rÃ©pondre Ã  de nombreuses questions biologiques, il est nÃ©cessaire de dÃ©terminer si deux (ou plus de deux) rÃ©gressions diffÃ¨rent significativement. Par exemple, pour comparer lâ€™efficacitÃ© de deux insecticides on doit comparer la relation entre leur dose et la mortalitÃ©. Ou encore, pour comparer le taux de croissance des mÃ¢les et des femelles on doit comparer la relation entre la taille et lâ€™Ã¢ge des mÃ¢les et des femelles.\nComme chaque rÃ©gression linÃ©aire est dÃ©crite par deux paramÃ¨tres, la pente et lâ€™ordonnÃ©e Ã  lâ€™origine, on doit considÃ©rer les deux dans la comparaison. Le modÃ¨le dâ€™ANCOVA, Ã  strictement parler, nâ€™Ã©prouve que lâ€™hypothÃ¨se dâ€™Ã©galitÃ© des ordonnÃ©es Ã  lâ€™origine. Cependant, avant dâ€™ajuster ce modÃ¨le, il faut Ã©prouver lâ€™hypothÃ¨se dâ€™Ã©galitÃ© des pentes (homogÃ©nÃ©itÃ© des pentes).\n\n9.4.1 Cas 1 - La taille en fonction de lâ€™Ã¢ge (exemple avec pente commune)\n\n\n\n\n\n\nExercice\n\n\n\nEn utilisant les donnÃ©es du fichier anc1dat.csv, Ã©prouvez lâ€™hypothÃ¨se que le taux de croissance des esturgeons mÃ¢les et femelles de The Pas est le mÃªme (donnÃ©es de 1978-1980). Comme mesure du taux de croissance, nous allons utiliser la pente de la rÃ©gression du log 10 de la longueur Ã  la fourche, lfkl, sur le log 10 de lâ€™Ã¢ge, lâ€™age.\n\n\nCommenÃ§ons par examiner les donnÃ©es. Pour faciliter la comparaison, il serait utile de tracer la droite de rÃ©gression et la trace lowess pour ainsi plus facilement Ã©valuer la linÃ©aritÃ©. On peut aussi ajouter un peu de trucs R pour obtenir des lÃ©gendes plus complÃ¨tes (remarquez lâ€™utilisation de la commande expression() pour obtenir des indices):\n\nanc1dat &lt;- read.csv(\"data/anc1dat.csv\")\nanc1dat$sex &lt;- as.factor(anc1dat$sex)\nmyplot &lt;- ggplot(data = anc1dat, aes(x=lage,    y=log10(fklngth)))+facet_grid(.~sex)+geom_point()\nmyplot &lt;- myplot+\n  stat_smooth(method = lm, se=FALSE)+\n  stat_smooth(se=FALSE, color=\"red\") +\n  labs(\n    y = expression(log[10]~(Fork~length)),\n    x = expression(log[10]~(Age))\n)\nmyplot\n\n\n\nLongueur des esturgeons en fonction de lâ€™age\n\n\n\nLa transformation log-log rend la relation linÃ©aire et, Ã  premiÃ¨re vue, il ne semble pas y avoir de problÃ¨me Ã©vident avec les conditions dâ€™application. Ajustons donc le modÃ¨le complet avec lâ€™interaction:\n\nmodel.full1&lt;-lm(lfkl ~ sex + lage + sex:lage, data = anc1dat)\nAnova(model.full1, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 0.64444  1 794.8182 &lt; 2.2e-16 ***\nsex         0.00041  1   0.5043    0.4795    \nlage        0.07259  1  89.5312 4.588e-15 ***\nsex:lage    0.00027  1   0.3367    0.5632    \nResiduals   0.07135 88                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nProbabilitÃ© que le terme lage*sex nâ€™affecte pas la longueur Ã  la fourche (i.e.Â que la pente ne diffÃ¨re pas entre les sexes, et que la diffÃ©rence de taille entre les mÃ¢les et femelles ne varie pas avec lâ€™Ã¢ge)\nAttrape. Notez que jâ€™ai utilisÃ© la fonction Anova() du package car avec un â€œaâ€ majuscule au lieu de la fonction native anova() (avec un â€œaâ€ minusculeâ€) associÃ©e aux objets produits par lm() pour obtenir les sommes de carrÃ©s de type III. Ces sommes des carrÃ©s des Ã©carts de type III (partiels) sont calculÃ©es comme si la variable Ã©tait entrÃ©e la derniÃ¨re dans le modÃ¨le et correspondent Ã  la diffÃ©rence entre la variance expliquÃ©e par le modÃ¨le complet et par le modÃ¨le dans lequel seule cette variable est omise. La fonction native anova() donne les sommes des carrÃ©s sÃ©quentielles, calculÃ©es au fur et Ã  mesure que chaque variable est ajoutÃ©e au modÃ¨le nul avec seulement une ordonnÃ©e Ã  lâ€™origine. Dans de rares cas, les sommes des carrÃ©s de type I et III sont Ã©gales (quand le design est parfaitement orthogonal ou balancÃ©). Dans la vaste majoritÃ© des cas, les sommes des carrÃ©s de type I et III sont diffÃ©rentes et je vous conseille de toujours utiliser les sommes des carrÃ©s de type III dans vos analyses.\nÃ€ partir de cette analyse, on devrait accepter les hypothÃ¨ses nulles (1) dâ€™Ã©galitÃ© des pentes pour les deux sexes, et (2) que les ordonnÃ©es Ã  lâ€™origine sont les mÃªmes pour les deux sexes. Mais, avant dâ€™accepter ces conclusions, il faut vÃ©rifier si les donnÃ©es rencontrent les conditions dâ€™application, comme dâ€™habitudeâ€¦\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npar(mfrow = c(2,2))\nplot(model.full1)\n\n\n\nConditions dâ€™applications du modÃ¨le model.full1\n\n\n\n\n\n\nEn ce qui concerne la normalitÃ©, Ã§a a lâ€™air dâ€™aller quoiquâ€™il y a quelques points, en haut Ã  droite, qui dÃ©vient de la droite. Si on effectue le test de Wilk-Shapiro (W = .9764, p = 0.09329), on confirme que les rÃ©sidus ne dÃ©vient pas significativement de la normalitÃ©. Les rÃ©sidus semblent homoscÃ©dastiques, mais si vous voulez vous en assurer, vous pouvez lâ€™Ã©prouver par un des tests formels. Ici jâ€™utilise le test Breusch-Pagan, qui est appropriÃ© quand certaines des variables indÃ©pendantes sont continues (Le test de Levene nâ€™est appropriÃ© que lorsquâ€™il nâ€™y a que des variables discontinues).\n\nbptest(model.full1)\n\n\n    studentized Breusch-Pagan test\n\ndata:  model.full1\nBP = 0.99979, df = 3, p-value = 0.8013\n\n\nComme lâ€™hypothÃ¨se nulle de ce test est que les rÃ©sidus sont homoscÃ©dastiques, et que p est relativement Ã©levÃ©, le test confirme lâ€™Ã©valuation visuelle. De plus, il nâ€™y a pas de tendance Ã©vidente dans les rÃ©sidus, suggÃ©rant quâ€™il nâ€™y a pas de problÃ¨me de linÃ©aritÃ©. Ce qui peut Ã©galement Ãªtre Ã©prouvÃ© formellement:\n\nresettest(model.full1, power = 2:3, type = \"regressor\", data = anc1dat)\n\n\n    RESET test\n\ndata:  model.full1\nRESET = 0.59861, df1 = 2, df2 = 86, p-value = 0.5519\n\n\nLa derniÃ¨re condition dâ€™application est quâ€™il nâ€™y a pas dâ€™erreur de mesure sur la variable indÃ©pendante continue. On ne peut vraiment Ã©prouver cette condition,, mais on sait que des estimÃ©s indÃ©pendants de lâ€™Ã¢ge des poissons obtenus par diffÃ©rents chercheurs donnent des Ã¢ges qui concordent avec moins de 1-2 ans dâ€™Ã©cart., ce qui est infÃ©rieur au 10% de la fourchette observÃ©e des Ã¢ges et donc acceptable pour des analyses de modÃ¨les de type I (attention ici on ne parle pas des SC de type I, je sais, câ€™est facile de confondreâ€¦)\nVous noterez quâ€™il y a une observation qui a un rÃ©sidu normalisÃ© (studentized residual) qui est Ã©levÃ©, i.e.Â une valeur extrÃªme (cas numÃ©ro 49). Ã‰liminez-la de lâ€™ensemble de donnÃ©es et refaites lâ€™analyse. Vos conclusions changent-elles?\n\nmodel.full.no49&lt;-lm(lfkl ~ sex + lage + sex:lage, data = anc1dat[c(-49),])\nAnova(model.full.no49, type=3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df  F value Pr(&gt;F)    \n(Intercept) 0.64255  1 895.9394 &lt;2e-16 ***\nsex         0.00038  1   0.5273 0.4697    \nlage        0.07378  1 102.8746 &lt;2e-16 ***\nsex:lage    0.00022  1   0.3135 0.5770    \nResiduals   0.06239 87                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLa conclusion ne change pas aprÃ¨s avoir enlevÃ© la valeur extrÃªme. Comme on nâ€™a pas de bonne raison dâ€™Ã©liminer cette valeur, il est probablement mieux de la conserver. Un examen des conditions dâ€™application aprÃ¨s avoir enlevÃ© cette valeur rÃ©vÃ¨le quâ€™elles sont toutes rencontrÃ©es.\n\n9.4.2 Cas 2 - Taille en fonction de lâ€™Ã¢ge (exemple avec des pentes diffÃ©rentes)\n\n\n\n\n\n\nExercice\n\n\n\nLe fichier anc3dat.csv contient des donnÃ©es sur des esturgeons mÃ¢les de deux sites (locate) : Lake of the Woods dans le Nord-Ouest de lâ€™Ontario et Chruchill River dans le Nord du Manitoba. En utilisant la mÃªme procÃ©dure, Ã©prouvez lâ€™hypothÃ¨se que la pente de la rÃ©gression de lfkl sur lage est la mÃªme aux deux sites (alors Locate est la variable en catÃ©gories et non pas sex). Que concluez-vous?\n\n\n\nanc3dat &lt;- read.csv(\"data/anc3dat.csv\")\nmyplot &lt;- ggplot(data = anc3dat, aes(x=lage, y = log10(fklngth))) +\n  facet_grid(.~locate) +\n  geom_point() +\n  stat_smooth(method = lm, se=FALSE)+\n  stat_smooth(se=FALSE, color=\"red\")+\n  labs(\n    y = expression(log[10]~(Fork~length)),\n    x = expression(log[10]~(Age))\n)\nmyplot\n\n\n\nLongueur des esturgeons en fonction de lâ€™age dâ€™aprÃ¨s anc3dat\n\n\nmodel.full2&lt;-lm(lfkl ~ lage + locate + lage:locate, data = anc3dat)\nAnova(model.full2, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 0.62951  1 1078.632 &lt; 2.2e-16 ***\nlage        0.07773  1  133.185 &lt; 2.2e-16 ***\nlocate      0.00968  1   16.591 0.0001012 ***\nlage:locate 0.00909  1   15.575 0.0001592 ***\nResiduals   0.05136 88                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIci, on rejette les hypothÃ¨ses nulles (1) que les pentes sont les mÃªmes dans les deux sites et (2) que les ordonnÃ©es Ã  lâ€™origine sont Ã©gales. En dâ€™autres mots, si on veut prÃ©dire la longueur Ã  la fourche dâ€™un esturgeon Ã  un Ã¢ge donnÃ© prÃ©cisÃ©ment, il faut savoir de quel site il provient. Puisque les pentes diffÃ¨rent, il faut estimer des rÃ©gressions sÃ©parÃ©es.\nMais avant dâ€™accepter ces conclusions, on doit se convaincre que les conditions dâ€™application sont rencontrÃ©es:\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npar(mfrow = c(2,2))\nplot(model.full2)\n\n\n\nConditions dâ€™applications du modÃ¨le model.full2\n\n\n\n\n\n\nSi on examine les rÃ©sidus selon les mÃ©thodes habituelles, on voit quâ€™il nâ€™y a pas de problÃ¨me de linÃ©aritÃ©, ni dâ€™homoscÃ©dasticitÃ© (BP = 2.8721, p = 0.4118). Cependant, le test de Wilk-Shapiro est significatif (W=0.97, p = 0.03). Ã‰tant donnÃ© la taille assez grande de lâ€™Ã©chantillon (N=92), ce test a beaucoup de puissance, mÃªme si la dÃ©viation de normalitÃ© ne semble pas trÃ¨s grande. Compte-tenu de la robustesse relative des LM, de la taille de lâ€™Ã©chantillon, on ne devrait pas ^tre trop inquiet de cette dÃ©viation de normalitÃ©.\nDonc, comme les conditions des LM sont suffisamment remplies, on peut accepter les rÃ©sultats donnÃ©s par R. Tous les termes sont significatifs (location, lage, interaction). Ce modÃ¨le complet est Ã©quivalent Ã  ajuster des rÃ©gressions sÃ©parÃ©es pour chaque site. Pour obtenir les coefficients, on peut ajuster des rÃ©gressions simples sur chaque sous-ensemble, ou extraire les coefficients ajustÃ©s du modÃ¨le complet:\n\nmodel.full2\n\n\nCall:\nlm(formula = lfkl ~ lage + locate + lage:locate, data = anc3dat)\n\nCoefficients:\n            (Intercept)                     lage       locateNELSON        \n                 1.2284                   0.3253                   0.2207  \nlage:locateNELSON        \n                -0.1656  \n\n\nPar dÃ©faut, la variable locate est encodÃ©e comme 0 pour le site qui vient le premier en ordre alphabÃ©tique (LofW) et 1 pour lâ€™autre (Nelson). Les rÃ©gressions pour chaque site deviennent donc:\nPour LofW: \\[\\begin{aligned}\nlfkl &= 1.2284 + 0.3253 \\times lage + 0.2207 \\times 0 - 0.1656 \\times 0 \\times lage \\\\\n&= 1.2284 + 0.3253 \\times lage\n\\end{aligned}\\]\nPour Nelson: \\[\\begin{aligned}\nlfkl &= 1.2284 + 0.3253 \\times lage + 0.2207 \\times 1 - 0.1656 \\times 1 \\times lage \\\\\n&= 1.4491 + 0.1597 \\times lage\n\\end{aligned}\\]\nVous pouvez vÃ©rifier en ajustant sÃ©parÃ©ment les rÃ©gressions pour chaque site:\n\nby(anc3dat, anc3dat$locate,function(x) lm(lfkl~lage, data=x))\n\nanc3dat$locate: LOFW        \n\nCall:\nlm(formula = lfkl ~ lage, data = x)\n\nCoefficients:\n(Intercept)         lage  \n     1.2284       0.3253  \n\n------------------------------------------------------------ \nanc3dat$locate: NELSON      \n\nCall:\nlm(formula = lfkl ~ lage, data = x)\n\nCoefficients:\n(Intercept)         lage  \n     1.4491       0.1597",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html#le-modÃ¨le-dancova",
    "href": "36-ancova_glm.html#le-modÃ¨le-dancova",
    "title": "\n9Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "\n9.5 Le modÃ¨le dâ€™ANCOVA",
    "text": "9.5 Le modÃ¨le dâ€™ANCOVA\nSi le test dâ€™homogÃ©nÃ©itÃ© des pentes indique quâ€™elles diffÃ¨rent, alors on devrait estimer des rÃ©gressions individuelles pour chaque niveau des variables discontinues. Cependant, si on accepte lâ€™hypothÃ¨se dâ€™Ã©galitÃ© des pentes, lâ€™Ã©tape suivante est de comparer les ordonnÃ©es Ã  lâ€™origine. Selon la â€œvieille Ã©coleâ€ i.e.Â lâ€™approche traditionnelle, on ajuste un modÃ¨le avec la variable catÃ©gorique et la variable continue, mais sans interaction (le modÃ¨le ANCOVA sensus stricto) et on utilise la somme des carrÃ©s des Ã©carts de type III, disons avec la fonction Anova(). Câ€™est ce que la majoritÃ© des manuels de biostatistiques prÃ©sentent.\nLâ€™autre approche consiste Ã  utiliser les rÃ©sultats de lâ€™analyse du modÃ¨le complet, et tester la signification de chaque terme Ã  partir des sommes des carrÃ©s partiels. Câ€™est plus rapide, mais moins puissant. Dans la plupart des cas, cette perte de puissance nâ€™est pas trop prÃ©occupante, sauf lorsque le modÃ¨le est trÃ¨s complexe et contient de nombreuses interactions non-significatives. Je vous suggÃ¨re dâ€™utiliser lâ€™approche simplifiÃ©e, et de nâ€™utiliser lâ€™approche traditionnelle que lorsque vous acceptez lâ€™hypothÃ¨se dâ€™Ã©galitÃ© des ordonnÃ©es Ã  lâ€™origine. Pourquoi?\nPuisque lâ€™approche simplifiÃ©e est moins puissante, si vous rejetez quand mÃªme H0, alors votre conclusion ne changera pas, mais sera seulement renforcÃ©e, en utilisant lâ€™approche traditionnelle.\nIci, je vais comparer lâ€™approche traditionnelle et lâ€™approche simplifiÃ©e. Rappelez-vous que vous voulez Ã©valuer lâ€™Ã©galitÃ© des ordonnÃ©es Ã  lâ€™origine aprÃ¨s avoir dÃ©terminÃ© que les pentes Ã©taient Ã©gales. Ã‰prouver lâ€™Ã©galitÃ© des ordonnÃ©es Ã  lâ€™origine quand les pentes diffÃ¨rent (ou, si vous prÃ©fÃ©rez, quand il y a une interaction) est rarement sensÃ©, peut facilement Ãªtre mal interprÃ©tÃ©, et ne devrait Ãªtre effectuÃ© que rarement.\nDe retour aux donnÃ©es de anc1dat.csv, en comparant la relation entre lfkl et lage entre les sexes, nous avions obtenu les rÃ©sultats suivants pour le modÃ¨le complet avec interactions:\n\nAnova(model.full1, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 0.64444  1 794.8182 &lt; 2.2e-16 ***\nsex         0.00041  1   0.5043    0.4795    \nlage        0.07259  1  89.5312 4.588e-15 ***\nsex:lage    0.00027  1   0.3367    0.5632    \nResiduals   0.07135 88                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOn avait dÃ©jÃ  conclu que la pente ne varie pas entre les sexes (i.e.Â lâ€™interaction nâ€™est pas significative). Notez que la p-valeur associÃ©e au sexe (0.4795) nâ€™est pas significative non plus.\nDe lâ€™autre cÃ´tÃ©, selon lâ€™approche traditionnelle, lâ€™infÃ©rence quand Ã  lâ€™effet du sexe se fait Ã  partir du modÃ¨le rÃ©duit (le modÃ¨le ANCOVA sensus stricto):\n\nmodel.ancova &lt;- lm(lfkl ~ sex + lage, data = anc1dat)\nAnova(model.ancova, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df   F value Pr(&gt;F)    \n(Intercept) 1.13480  1 1410.1232 &lt;2e-16 ***\nsex         0.00149  1    1.8513 0.1771    \nlage        0.14338  1  178.1627 &lt;2e-16 ***\nResiduals   0.07162 89                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(model.ancova)\n\n\nCall:\nlm(formula = lfkl ~ sex + lage, data = anc1dat)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.093992 -0.018457 -0.000876  0.022491  0.081161 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      1.225533   0.032636  37.552   &lt;2e-16 ***\nsexMALE         -0.008473   0.006228  -1.361    0.177    \nlage             0.327253   0.024517  13.348   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02837 on 89 degrees of freedom\nMultiple R-squared:  0.696, Adjusted R-squared:  0.6892 \nF-statistic: 101.9 on 2 and 89 DF,  p-value: &lt; 2.2e-16\n\n\nDans ce modÃ¨le, sex nâ€™est pas significatif et on conclue donc que lâ€™ordonnÃ©e Ã  lâ€™origine ne diffÃ¨re pas entre les sexes. Notez que la pvaleur est plus petite (0.1771 vs 0.4795), ce qui reflÃ¨te la puissance accrue de lâ€™approche traditionnelle. Toutefois, les conclusions sont les mÃªmes: les ordonnÃ©es Ã  lâ€™origine ne diffÃ¨rent pas.\n\n\n\n\n\n\nExercice\n\n\n\nEn examinant les graphiques diagnostiques, vous noterez quâ€™il y a trois observations dont la valeur absolue du rÃ©sidu est grande (cas 19, 49, et 50). Ces observations pourraient avoir un effet disproportionnÃ© sur les rÃ©sultats de lâ€™analyse. Ã‰liminez-les et refaites lâ€™analyse. Les conclusions changent-elles ?\n\n\n\nmodel.ancova.nooutliers &lt;- lm(lfkl ~ sex + lage, data = anc1dat[c(-49, -50, -19),])\nAnova(model.ancova.nooutliers, type = 3)\n\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df   F value  Pr(&gt;F)    \n(Intercept) 1.09160  1 1896.5204 &lt; 2e-16 ***\nsex         0.00232  1    4.0374 0.04764 *  \nlage        0.13992  1  243.0946 &lt; 2e-16 ***\nResiduals   0.04950 86                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(model.ancova.nooutliers)\n\n\nCall:\nlm(formula = lfkl ~ sex + lage, data = anc1dat[c(-49, -50, -19), \n    ])\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.058397 -0.018469 -0.000976  0.020696  0.040288 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      1.224000   0.028106  43.549   &lt;2e-16 ***\nsexMALE         -0.010823   0.005386  -2.009   0.0476 *  \nlage             0.328604   0.021076  15.591   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02399 on 86 degrees of freedom\nMultiple R-squared:  0.7706,    Adjusted R-squared:  0.7653 \nF-statistic: 144.4 on 2 and 86 DF,  p-value: &lt; 2.2e-16\n\n\nOuch! Les rÃ©sultats changent. Il faudrait donc rejeter lâ€™hypothÃ¨se nulle et conclure que les ordonnÃ©es Ã  lâ€™origine diffÃ¨rent! Une conclusion qualitativement diffÃ©rente de celle obtenue en considÃ©rant toutes les donnÃ©es. Pourquoi? Il y a deux raisons possibles : (1) les valeurs extrÃªmes influencent beaucoup les rÃ©gressions ou (2) lâ€™exclusion des valeurs extrÃªmes permet dâ€™augmenter la puissance de dÃ©tection dâ€™une diffÃ©rence. La premiÃ¨re explication est moins plausible parce que les valeurs extrÃªmes nâ€™avaient pas une grande influence (leverage faible). Alors, la deuxiÃ¨me explication est plus plausible et vous pouvez le vÃ©rifier en faisant des rÃ©gressions pour chaque sexe sans et avec les valeurs extrÃªmes. Si vous le faites, vous noterez que les ordonnÃ©es Ã  lâ€™origine pour chaque sexe ne changent presque pas alors que leurs erreurs-types changent beaucoup.\n\n\n\n\n\n\nExercice\n\n\n\nAjustez une rÃ©gression simple entre lfkl et lage pour lâ€™ensemble complet de donnÃ©es et aussi pour le sous-ensemble sans les 3 valeurs dÃ©viantes. Comparez ces modÃ¨les avec les modÃ¨les dâ€™ANCOVA ajustÃ©s prÃ©cÃ©demment. Que concluez-vous ? Quel modÃ¨le, dâ€™aprÃ¨s vous, a le meilleur ajustement aux donnÃ©es ? Pourquoi ?\n\n\nLe modÃ¨le en excluant les valeurs extrÃªmes:\n\nmodel.linear.nooutliers&lt;-lm(lfkl ~ lage,data = anc1dat[c(-49, -50, -19),])\nsummary(model.linear.nooutliers)\n\n\nCall:\nlm(formula = lfkl ~ lage, data = anc1dat[c(-49, -50, -19), ])\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.055567 -0.017809 -0.002944  0.021272  0.044972 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.20378    0.02670   45.09   &lt;2e-16 ***\nlage         0.34075    0.02054   16.59   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02441 on 87 degrees of freedom\nMultiple R-squared:  0.7598,    Adjusted R-squared:  0.7571 \nF-statistic: 275.2 on 1 and 87 DF,  p-value: &lt; 2.2e-16\n\n\nPour la rÃ©gression simple (sans les valeurs extrÃªmes) on obtient un R 2 de 0.76 et une erreur-type des rÃ©sidus de 0.02441, En comparant Ã  lâ€™erreur-type des rÃ©sidus du modÃ¨le dâ€™ANCOVA (0.02399) on rÃ©alise que la qualitÃ© des prÃ©dictions est essentiellement la mÃªme, mÃªme en ajustant des ordonnÃ©es Ã  lâ€™origine diffÃ©rentes pour chaque groupe. Par consÃ©quent, les bÃ©nÃ©fices de lâ€™inclusion dâ€™un terme pour les diffÃ©rentes ordonnÃ©es Ã  lâ€™origine sont faibles alors que le coÃ»t, en terme de complexitÃ© du modÃ¨le, est Ã©levÃ© (33% dâ€™augmentation du nombre de termes pour un trÃ¨s faible amÃ©lioration de la qualitÃ© dâ€™ajustement). Si vous examinez les rÃ©sidus de ce modÃ¨le, vous trouverez quâ€™ils sont Ã  peu prÃ¨s O.K.)\nSi on ajuste une rÃ©gression simple sur toutes les donnÃ©es, on obtient:\n\nmodel.linear&lt;-lm(lfkl ~ lage, data = anc1dat)\nsummary(model.linear)\n\n\nCall:\nlm(formula = lfkl ~ lage, data = anc1dat)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.090915 -0.018975 -0.002587  0.021270  0.085273 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.21064    0.03089   39.19   &lt;2e-16 ***\nlage         0.33606    0.02376   14.14   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0285 on 90 degrees of freedom\nMultiple R-squared:  0.6897,    Adjusted R-squared:  0.6863 \nF-statistic: 200.1 on 1 and 90 DF,  p-value: &lt; 2.2e-16\n\n\nEncore une fois, lâ€™erreur-type des rÃ©sidus (0.0285) pour cette rÃ©gression unique est semblable Ã  la variance du modÃ¨le dâ€™ANCOVA (0.02837) et le modÃ¨le simplifiÃ© prÃ©dit presque aussi bien que le modÃ¨le plus complexe. (Ici encore, toutes les conditions dâ€™application semblent remplies, si ce nâ€™est de la valeur extrÃªme).\nDonc, dans les deux cas (avec ou sans les valeurs extrÃªmes), lâ€™addition dâ€™un terme supplÃ©mentaire pour le sexe nâ€™ajoute pas grand-chose. Il semble donc que le meilleur modÃ¨le soit celui de la rÃ©gression simple. Un estimÃ© raisonnablement prÃ©cis de la taille des esturgeons peut Ãªtre obtenu de la rÃ©gression commune sur lâ€™ensemble des rÃ©sultats.\nNote: Il est frÃ©quent que lâ€™Ã©limination de valeurs extrÃªmes en fasse apparaÃ®tre dâ€™autres. Câ€™est parce que ces valeurs extrÃªmes dÃ©pendent de la variabilitÃ© rÃ©siduelle. Si on Ã©limine les valeurs les plus dÃ©viantes, la variabilitÃ© rÃ©siduelle diminue, et certaines observations qui nâ€™Ã©taient pas si dÃ©viantes que cela deviennent proportionnellement plus dÃ©viantes. Notez aussi quâ€™en Ã©liminant des valeurs extrÃªmes, lâ€™effectif diminue et que la puissance dÃ©croÃ®t. Il faut donc Ãªtre prudent.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html#comparer-lajustement-de-modÃ¨les",
    "href": "36-ancova_glm.html#comparer-lajustement-de-modÃ¨les",
    "title": "\n9Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "\n9.6 Comparer lâ€™ajustement de modÃ¨les",
    "text": "9.6 Comparer lâ€™ajustement de modÃ¨les\nComme vous venez de le voir, le processus dâ€™ajustement de modÃ¨les est itÃ©ratif. La plupart du temps il y a plus dâ€™un modÃ¨le qui peut Ãªtre ajustÃ© aux donnÃ©es et câ€™est Ã  vous de choisir celui qui est le meilleur compromis entre la qualitÃ© dâ€™ajustement (quâ€™on essaie de maximiser) et la complexitÃ© (quâ€™on essaie de minimiser). La stratÃ©gie de base en ajustant des modÃ¨les linÃ©aires (ANOVA, rÃ©gression, ANCOVA) est de privilÃ©gier le modÃ¨le le plus simple si la qualitÃ© dâ€™ajustement nâ€™est pas significativement plus mauvaise. R peut calculer une statistique F vous permettant de comparer lâ€™ajustement de deux modÃ¨les. Dans ce cas, lâ€™hypothÃ¨se nulle est que la qualitÃ© dâ€™ajustement ne diffÃ¨re pas entre les deux modÃ¨les.\n\n\n\n\n\n\nExercice\n\n\n\nEn utilisant les donnÃ©es de anc1dat comparez lâ€™ajustement du modÃ¨le ANCOVA et de la rÃ©gression commune:\n\n\n\nanova(model.ancova,model.linear)\n\nAnalysis of Variance Table\n\nModel 1: lfkl ~ sex + lage\nModel 2: lfkl ~ lage\n  Res.Df      RSS Df  Sum of Sq      F Pr(&gt;F)\n1     89 0.071623                            \n2     90 0.073113 -1 -0.0014899 1.8513 0.1771\n\n\nLa fonction anova() utilise la diffÃ©rence entre la somme des carrÃ©s des deux modÃ¨les et la divise par la diffÃ©rence entre le nombre de degrÃ©s de libertÃ© pour obtenir un carrÃ© moyen. Ce carrÃ© moyen est utilisÃ© au numÃ©rateur et est divisÃ© par la variance rÃ©siduelle du modÃ¨le le plus complexe pour obtenir la statistique F. Dans ce cas-ci, le test de F nâ€™est pas significatif, et on conclut que les deux modÃ¨les ont une qualitÃ© dâ€™ajustement Ã©quivalente, et quâ€™on devrait donc privilÃ©gier le modÃ¨le le plus simple, la rÃ©gression linÃ©aire simple.\n\n\n\n\n\n\nExercice\n\n\n\nRefaites le mÃªme processus avec le donnÃ©es de anc3dat, ajustez le modÃ¨le complet avec interaction (LFKL~LAGE+LOCATE+LAGE:LOCATE) et sans interaction (LFKL~LAGE+LOCATE), Comparez lâ€™ajustement des deux modÃ¨les, que concluez vous?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmodel.full.anc3dat&lt;-lm(lfkl ~ lage + locate + lage:locate, data = anc3dat)\nmodel.ancova.anc3dat&lt;-lm(lfkl ~ lage + locate, data = anc3dat)\nanova(model.full.anc3dat,model.ancova.anc3dat)\n\nAnalysis of Variance Table\n\nModel 1: lfkl ~ lage + locate + lage:locate\nModel 2: lfkl ~ lage + locate\n  Res.Df      RSS Df  Sum of Sq      F    Pr(&gt;F)    \n1     88 0.051358                                   \n2     89 0.060448 -1 -0.0090901 15.575 0.0001592 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCette fois-ci, le modÃ¨le plus complexe sâ€™ajuste significativement mieux aux donnÃ©es. (Pas surprenant puisque nous avions prÃ©cÃ©demment conclu que lâ€™interaction est significative avec ces donnÃ©es.)",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html#bootstrap",
    "href": "36-ancova_glm.html#bootstrap",
    "title": "\n9Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "\n9.7 Bootstrap",
    "text": "9.7 Bootstrap\n\n############################################################\n######\n# Bootstrap analysis\n# Bootstrap analysis BCa confidence intervals\n# Preferable when parameter distribution is far from normal\n# Bootstrap 95% BCa CI for regression coefficients\nlibrary(boot)\n\n# To simplify future modifications of the code in this file,\n# copy the data to a generic mydata dataframe\nmydata &lt;- anc3dat\n\n# create a myformula variable containing the formula for the model to be fitted\nmyformula &lt;- as.formula(lfkl ~ lage + locate + lage:locate)\n\n# function to obtain regression coefficients for each iteration\nbs &lt;- function(formula, data, indices) {\n  d &lt;- data[indices, ]\n  fit &lt;- lm(formula, data = d)\n  return(coef(fit))\n}\n# bootstrapping with 1000 replications\nresults &lt;- boot(data = mydata, statistic = bs, R = 1000, formula = myformula)\n\n# view results\nresults\nboot_res &lt;- summary(results)\nrownames(boot_res) &lt;- names(results$t0)\nboot_res\n\nop &lt;- par(ask = TRUE)\nfor (i in 1:length(results$t0)) {\n  plot(results, index = i)\n  title(names(results$t0)[i])\n}\npar(op)\n\n# get 95% confidence intervals\nfor (i in 1:length(results$t0)) {\n  cat(\"\\n\", names(results$t0)[i],\"\\n\")\n  print(boot.ci(results, type = \"bca\", index = i))\n}",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "36-ancova_glm.html#permutation-test",
    "href": "36-ancova_glm.html#permutation-test",
    "title": "\n9Â  ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral\n",
    "section": "\n9.8 Permutation test",
    "text": "9.8 Permutation test\n\n############################################################\n##########\n# Permutation test\n#\n# using lmperm library\n# To simplify future modifications of the code in this file,\n# copy the data to a generic mydata dataframe\nmydata&lt;-anc3dat\n# create a myformula variable containing the formula for the\n# model to be fitted\nmyformula&lt;-as.formula(lfkl ~ lage + locate + lage:locate)\nrequire(lmPerm2)\n# Fit desired model on the desired dataframe\nmymodel &lt;- lm(myformula, data = mydata)\n# Calculate p-values for each term by permutation\n# Note that lmp centers numeric variable by default, so to\n# get results that are\n# consistent with standard models, it is necessary to set\ncenter=FALSE\nmymodelProb &lt;- lmp(myformula, data = mydata, center=FALSE,\nperm = \"Prob\")\nsummary(mymodel)\nsummary(mymodelProb)",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>ANCOVA et modÃ¨le linÃ©aire gÃ©nÃ©ral</span>"
    ]
  },
  {
    "objectID": "37-model_freq.html",
    "href": "37-model_freq.html",
    "title": "\n10Â  Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson\n",
    "section": "",
    "text": "10.1 Paquets et donnÃ©es requises pour le labo\nCe laboratoire nÃ©cessite:",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson</span>"
    ]
  },
  {
    "objectID": "37-model_freq.html#set-freq",
    "href": "37-model_freq.html#set-freq",
    "title": "\n10Â  Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson\n",
    "section": "",
    "text": "les paquets R:\n\nvcd\nvcdExtra\ncar\n\n\nles fichiers de donnÃ©es\n\nUSPopSurvey.csv\nloglin.csv\nsturgdat.csv",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson</span>"
    ]
  },
  {
    "objectID": "37-model_freq.html#organisation-des-donnÃ©es-3-formats",
    "href": "37-model_freq.html#organisation-des-donnÃ©es-3-formats",
    "title": "\n10Â  Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson\n",
    "section": "\n10.2 Organisation des donnÃ©es: 3 formats",
    "text": "10.2 Organisation des donnÃ©es: 3 formats\nLes rÃ©sultats de certaines expÃ©riences sont sous forme de frÃ©quences, par exemple le nombre de plantes infectÃ©es par un pathogÃ¨ne sous diffÃ©rents rÃ©gimes dâ€™infection, ou le nombre de tortues mÃ¢les et femelles qui Ã©closent Ã  diffÃ©rentes tempÃ©ratures (oui, chez les tortues le sexe dÃ©pends de la tempÃ©rature!), etc. La question statistique qui se pose gÃ©nÃ©ralement est de savoir si la proportion des observations dans chaque catÃ©gorie (infectÃ© vs non infectÃ©, mÃ¢le vs femelle, etc) diffÃ¨re significativement entre les traitements (rÃ©gime dâ€™infection ou tempÃ©rature dans les deux exemples). Pour rÃ©pondre Ã  cette question, on peut organiser les donnÃ©es de maniÃ¨re Ã  reflÃ©ter comment les observations se retrouvent dans chaque catÃ©gorie. Il existe 3 faÃ§ons dâ€™organiser ces donnÃ©es. Vous devriez Ãªtre capable de choisir la maniÃ¨re appropriÃ©e pour votre analyse, et savoir convertir entre elles avec R.\nLe fichier USPopSurvey.csv contient les donnÃ©e de recensement dâ€™une ville du midwest amÃ©ricain en 1980:\n\nUSPopSurvey &lt;- read.csv(\"data/USPopSurvey.csv\")\nUSPopSurvey\n\n   ageclass    sex frequency\n1       0-9 female     17619\n2     10-19 female     17947\n3     20-29 female     21344\n4     30-39 female     19138\n5     40-49 female     13135\n6     50-59 female     11617\n7     60-69 female     11053\n8     70-79 female      7712\n9       80+ female      4114\n10      0-9   male     17538\n11    10-19   male     18207\n12    20-29   male     21401\n13    30-39   male     18837\n14    40-49   male     12568\n15    50-59   male     10661\n16    60-69   male      9374\n17    70-79   male      5348\n18      80+   male      1926\n\n\nNotez quâ€™il y a 18 lignes et 3 colonnes dans ce fichier. Chaque ligne donne le nombre de personnes (frequency) pour un sexe et une classe dâ€™Ã¢ge. Il y a 239539 individus qui ont Ã©tÃ© classifiÃ©s selon les 18 catÃ©gories (2 sexes x 9 classes dâ€™Ã¢ge). Cette maniÃ¨re de reprÃ©senter les donnÃ©es est sous le format de frÃ©quences (frequency form). Câ€™est un format compact permettant dâ€™enregistrer les donnÃ©es quand il y a seulement des variables catÃ©goriques Ã  reprÃ©senter.\nLorsquâ€™il y a des variables continues, ce format ne peut Ãªtre utilisÃ©. Les donnÃ©es doivent Ãªtre enregistrÃ©e sous le format de cas (case form) dans laquelle chaque observation (individu) est reprÃ©sentÃ© par une ligne dans le fichier, et oÃ¹ chaque variable est reprÃ©sentÃ©e par une colonne. Le package vcdExtra contient la fonction expand.dft() qui permet de convertir de la forme de frÃ©quence Ã  la forme de cas. Par exemple, pour crÃ©er un data frame avec 239439 lignes et 2 colonnes (sex et ageclass) Ã  partir du data frame USPopSurvey:\n\nUSPopSurvey.caseform &lt;- expand.dft(USPopSurvey, freq = \"frequency\")\nhead(USPopSurvey.caseform)\n\n  ageclass    sex\n1      0-9 female\n2      0-9 female\n3      0-9 female\n4      0-9 female\n5      0-9 female\n6      0-9 female\n\ntail(USPopSurvey.caseform)\n\n       ageclass  sex\n239534      80+ male\n239535      80+ male\n239536      80+ male\n239537      80+ male\n239538      80+ male\n239539      80+ male\n\n\nCes donnÃ©es peuvent finalement Ãªtre organisÃ©es sous le format de tableau (table form) de contingence oÃ¹ chacune des n variables est reprÃ©sentÃ©e par une dimension dâ€™un tableau n-dimensionnel (dans notre exemple on a 2 variables, sexe et classe dâ€™Ã¢ge, et les rangÃ©es pourraient reprÃ©senter les classes dâ€™Ã¢ge et les colonnes chaque sexe). Les cellules de ce tableau contiennent les frÃ©quences. Le format tableau peut Ãªtre obtenu du format de frÃ©quence ou de cas par la commande xtabs() :\n\n# convert case form to table form\nxtabs(~ ageclass + sex, USPopSurvey.caseform)\n\n        sex\nageclass female  male\n   0-9    17619 17538\n   10-19  17947 18207\n   20-29  21344 21401\n   30-39  19138 18837\n   40-49  13135 12568\n   50-59  11617 10661\n   60-69  11053  9374\n   70-79   7712  5348\n   80+     4114  1926\n\n# convert frequency form to table form\nxtabs(frequency ~ ageclass + sex, data = USPopSurvey)\n\n        sex\nageclass female  male\n   0-9    17619 17538\n   10-19  17947 18207\n   20-29  21344 21401\n   30-39  19138 18837\n   40-49  13135 12568\n   50-59  11617 10661\n   60-69  11053  9374\n   70-79   7712  5348\n   80+     4114  1926\n\n\n\n(#tab:unnamed-chunk-1)Fonctions permettant la conversion de donnÃ©es de frÃ©quences entre les diffÃ©rents formats.\n\n\n\n\n\n\n\nDe (ligne) \\ Vers (colonne)\nCas\nFrÃ©quence\nTableau\n\n\n\nCas\n\nxtabs(~ A + B)\ntable(A, B)\n\n\nFrÃ©quence\nexpand.dft(X)\n\nxtabs(count ~ A + B)\n\n\nTableau\nexpand.dft(X)\nas.data.frame(X)",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson</span>"
    ]
  },
  {
    "objectID": "37-model_freq.html#visualiser-graphiquement-les-tableaux-de-contingence-et-test-dindÃ©pendance",
    "href": "37-model_freq.html#visualiser-graphiquement-les-tableaux-de-contingence-et-test-dindÃ©pendance",
    "title": "\n10Â  Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson\n",
    "section": "\n10.3 Visualiser graphiquement les tableaux de contingence et test dâ€™indÃ©pendance",
    "text": "10.3 Visualiser graphiquement les tableaux de contingence et test dâ€™indÃ©pendance\nLes tableaux de contingence peuvent servir Ã  Ã©prouver lâ€™hypothÃ¨se dâ€™indÃ©pendance des observations. Ceci Ã©quivaut Ã  rÃ©pondre Ã  la question: est-ce que la classification des observations selon une variable (par exemple sex) indÃ©pendante de la classification par une autre variable (par exemple ageclass). En autres mots, est-ce que la proportion des mÃ¢les et femelles indÃ©pendante de lâ€™Ã¢ge ou varie avec lâ€™Ã¢ge?\nLe package vcd inclut la fonction mosaic() qui permet de reprÃ©senter graphiquement le contenu dâ€™un tableau de contingence:\n\nlibrary(vcd)\nUSTable &lt;- xtabs(frequency ~ ageclass + sex, data = USPopSurvey) # save the table form as USTable dataframe\n# Mosaic plot of the contingency table\nmosaic(USTable)\n\n\n\nReprÃ©sentation mosaique de la proportion des sexes par classe dâ€™age\n\n\n\nCette mosaÃ¯que reprÃ©sente la proportion des observations dans chaque combinaison de catÃ©gories (ici il y a 18 catÃ©gories, 2 sexes x 9 classes dâ€™Ã¢ge). Les catÃ©gories contenant une plus grande proportion dâ€™observations sont reprÃ©sentÃ©es par de plus grands rectangles. Visuellement, on peut voir que la proportion des mÃ¢les et femelles est approximativement Ã©gale chez les jeunes, mais que la proportion des femelles augmente chez les personnes Ã¢gÃ©es.\nLe test de Chi carrÃ© permet dâ€™Ã©prouver lâ€™hypothÃ¨se nulle que la proportion des mÃ¢les et femelles ne change pas avec lâ€™Ã¢ge (est indÃ©pendante de lâ€™Ã¢ge):\n\n# Test of independence\nchisq.test(USTable) # runs chi square test of independence of sex and age class\n\n\n    Pearson's Chi-squared test\n\ndata:  USTable\nX-squared = 1162.6, df = 8, p-value &lt; 2.2e-16\n\n\nLa valeur p Ã©tant trÃ¨s faible, on rejette donc lâ€™hypothÃ¨se nulle que Ã¢ge et sexe sont indÃ©pendants. Ces graphiques mosaÃ¯ques peuvent Ãªtres colorÃ©s pour souligner les catÃ©gories qui contribuent le plus Ã  cette dÃ©pendance:\n\n# Mosaic plot of the contingency table with shading\nmosaic(USTable, shade=TRUE)\n\n\n\nReprÃ©sentation mosaique de la proportion des sexes par classe dâ€™age avec Ã©chelle de couleur\n\n\n\nLa couleur de chaque rectangle est proportionnelle Ã  la dÃ©viation des frÃ©quences observÃ©es de ce qui serait attendu si lâ€™Ã¢ge et le sexe Ã©taient indÃ©pendants. Les classes dâ€™Ã¢ge 40-49 et 50-59 ont un rapport des sexe approximativement Ã©gal Ã  celui de toutes les classes dâ€™Ã¢ge rÃ©unies. Il y a plus de jeunes mÃ¢les et de femelles Ã¢gÃ©es que si le rapport des sexe ne variait pas avec lâ€™Ã¢ge.et ces rectangles sont colorÃ©s en bleu. De lâ€™autre cÃ´tÃ©, il y a moins de jeunes femelles et de mÃ¢les Ã¢gÃ©s que si le rapport des sexe Ã©tait indÃ©pendant de lâ€™Ã¢ge, et ces rectangles sont en rouge. La valeur p Ã  la droite de la figure est pour le test de Chi carrÃ© qui Ã©prouve lâ€™hypothÃ¨se nulle dâ€™indÃ©pendance pour lâ€™ensemble des observations, toutes classes dâ€™Ã¢ge confondues.\nLâ€™estimation de la valeur p associÃ©e Ã  la statistique du Chi carrÃ© est approximative lorsque les frÃ©quences attendues sont faibles dans certaines cellules, et ce particuliÃ¨rement pour les tableaux de contingence 2x2. Deux options permettant des valeurs p plus exactes sont prÃ©fÃ©rÃ©es dans ce cas, et le choix dÃ©pends du nombre total dâ€™observations. Pour de grands Ã©chantillons (comme ici avec plus de 200,000 observations!), une approche par simulation de type Monte Carlo est suggÃ©rÃ©e et peut Ãªtre obtenue en ajoutant simulate.p.value=TRUE comme argument Ã  la fonction chisq.test() :\n\n# Monte-carlo estimation of p value (better for small n)\nchisq.test(USTable, simulate.p.value = TRUE, B = 10000)\n\n\n    Pearson's Chi-squared test with simulated p-value (based on 10000\n    replicates)\n\ndata:  USTable\nX-squared = 1162.6, df = NA, p-value = 9.999e-05\n\n\nIci, la simulation a Ã©tÃ© faite B=10000 fois, et la valeur de Chi carrÃ© observÃ©e avec les donnÃ©es rÃ©elles nâ€™a jamais Ã©tÃ© observÃ©e. Par consÃ©quent, p a Ã©tÃ© estimÃ© Ã  1/10001=9.999e-05, qui est beaucoup plus Ã©levÃ© que la valeur p estimÃ©e Ã  partir de la distribution thÃ©orique de Chi carrÃ© (p&lt; 2.2e-16). Cette diffÃ©rence est due au moins en partie Ã  un artÃ©facts de la simulation. Pour obtenir des valeurs p de lâ€™ordre de 1e-16, il faut effectuer au moins 10 16 simulations. Et je ne suis pas aussi patient que Ã§a!\nPour de petits tableaux de contingence avec des frÃ©quences attendues petites, le test exact de Fisher peut servir Ã  estimer la valeur p associÃ©e Ã  lâ€™hypothÃ¨se dâ€™indÃ©pendance. Mais ce test ne peut Ãªtre effectuÃ© avec de grands Ã©chantillons, comme ici:\n\n# Fisher exact test for contingency tables (small samples and small tables)\nfisher.test(USTable) # fails here because too many observations\n\nError in fisher.test(USTable): FEXACT error 40.\nOut of workspace.\n\nfisher.test(USTable, simulate.p.value = TRUE, B = 10000)\n\n\n    Fisher's Exact Test for Count Data with simulated p-value (based on\n    10000 replicates)\n\ndata:  USTable\np-value = 9.999e-05\nalternative hypothesis: two.sided",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson</span>"
    ]
  },
  {
    "objectID": "37-model_freq.html#rÃ©gression-de-poisson-une-alternative-au-test-de-chi-carrÃ©-pour-les-tableaux-de-contingence",
    "href": "37-model_freq.html#rÃ©gression-de-poisson-une-alternative-au-test-de-chi-carrÃ©-pour-les-tableaux-de-contingence",
    "title": "\n10Â  Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson\n",
    "section": "\n10.4 RÃ©gression de Poisson: une alternative au test de Chi carrÃ© pour les tableaux de contingence",
    "text": "10.4 RÃ©gression de Poisson: une alternative au test de Chi carrÃ© pour les tableaux de contingence\nRendu Ã  ce stade, vous devriez avoir appris Ã  apprÃ©cier la flexibilitÃ© et la gÃ©nÃ©ralitÃ© des modÃ¨les linÃ©aires, et rÃ©aliser que le test de t est un cas spÃ©cial dâ€™un modÃ¨le linÃ©aire avec une variable indÃ©pendante catÃ©gorique. Lâ€™analyse des tableaux de contingence par le test du Chi carrÃ© peut Ã©galement Ãªtre gÃ©nÃ©ralisÃ©. Un modÃ¨le linÃ©aire gÃ©nÃ©ralisÃ© pour une distribution de Poisson peut Ãªtre utilisÃ© quand la variable dÃ©pendante est une frÃ©quence dâ€™observations et les variables indÃ©pendantes sont catÃ©gorique (comme pour les tableaux de contingence, on parle alors de modÃ¨les log-linÃ©aires), continue (rÃ©gression Poisson), ou une combinaison de variables indÃ©pendante continues et catÃ©goriques (aussi appelÃ© rÃ©gression de Poisson, mais avec des variables catÃ©goriques en plus, analogue Ã  lâ€™ANCOVA sensu largo).\nCes modÃ¨les prÃ©disent le logarithme naturel de la frÃ©quence des observations en fonction des variables indÃ©pendantes. Comme pour les modÃ¨les linÃ©aires qui prÃ©sument de la normalitÃ© des rÃ©sidus, on peut Ã©valuer la qualitÃ© dâ€™ajustement du modÃ¨le (par AICc par exemple) et la signification statistique des termes du modÃ¨le (par exemple en comparant lâ€™ajustement dâ€™un modÃ¨le â€œcompletâ€ et celui dâ€™un modÃ¨le qui exclue un terme Ã  tester). On peut Ã©galement obtenir des estimÃ©s des paramÃ¨tre pour chaque terme dans le modÃ¨le, avec des intervalles de confiance et des valeur p pour lâ€™hypothÃ¨se nulle que ce terme nâ€™a pas dâ€™influence sur la frÃ©quence.\nLa fonction glm() avec lâ€™option family=poisson() permet lâ€™estimation, par la mÃ©thode du maximum de vraisemblance, de modÃ¨les linÃ©aires pour des frÃ©quences. Comparativement aux modÃ¨les linÃ©aires vus prÃ©cÃ©demment, une des particularitÃ© de ces modÃ¨les est que seuls les termes dâ€™interaction sont dâ€™intÃ©rÃªt. En partant des donnÃ©es de recensement en forme tableau, on peut ajuster un glm aux frÃ©quences observÃ©es par sexe et classe dâ€™Ã¢ge par:\n\nmymodel &lt;- glm(frequency ~ sex * ageclass, family = poisson(), data = USPopSurvey)\nsummary(mymodel)\n\n\nCall:\nglm(formula = frequency ~ sex * ageclass, family = poisson(), \n    data = USPopSurvey)\n\nCoefficients:\n                       Estimate Std. Error  z value Pr(&gt;|z|)    \n(Intercept)            9.776733   0.007534 1297.730  &lt; 2e-16 ***\nsexmale               -0.004608   0.010667   -0.432   0.6657    \nageclass10-19          0.018445   0.010605    1.739   0.0820 .  \nageclass20-29          0.191793   0.010179   18.842  &lt; 2e-16 ***\nageclass30-39          0.082698   0.010441    7.921 2.36e-15 ***\nageclass40-49         -0.293697   0.011528  -25.477  &lt; 2e-16 ***\nageclass50-59         -0.416508   0.011951  -34.850  &lt; 2e-16 ***\nageclass60-69         -0.466276   0.012134  -38.428  &lt; 2e-16 ***\nageclass70-79         -0.826200   0.013654  -60.511  &lt; 2e-16 ***\nageclass80+           -1.454582   0.017316  -84.004  &lt; 2e-16 ***\nsexmale:ageclass10-19  0.018991   0.014981    1.268   0.2049    \nsexmale:ageclass20-29  0.007275   0.014400    0.505   0.6134    \nsexmale:ageclass30-39 -0.011245   0.014803   -0.760   0.4475    \nsexmale:ageclass40-49 -0.039519   0.016416   -2.407   0.0161 *  \nsexmale:ageclass50-59 -0.081269   0.017136   -4.742 2.11e-06 ***\nsexmale:ageclass60-69 -0.160154   0.017633   -9.083  &lt; 2e-16 ***\nsexmale:ageclass70-79 -0.361447   0.020747  -17.422  &lt; 2e-16 ***\nsexmale:ageclass80+   -0.754343   0.029598  -25.486  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 5.3611e+04  on 17  degrees of freedom\nResidual deviance: 6.5463e-12  on  0  degrees of freedom\nAIC: 237.31\n\nNumber of Fisher Scoring iterations: 2\n\n\nLâ€™ajustement du modÃ¨le complet, avec Lâ€™interaction triple sex:ageclass interaction, permet Ã  la proportion des mÃ¢les et femelles de changer entre les classes dâ€™Ã¢ge, et donc dâ€™estimer exactement les frÃ©quences observÃ©es pour chaque combinaison de sexe et classe dâ€™Ã¢ge (notez que les rÃ©sidus (deviance residuals) sont tous 0, et que lâ€™estimÃ© de dÃ©viance rÃ©siduelle est Ã©galement approximativement zÃ©ro).\nUn masochiste peut utiliser le tableau des coefficients pour obtenir la frÃ©quence prÃ©dite pour les diffÃ©rentes catÃ©gories. Les frÃ©quences prÃ©dites, comme pour lâ€™ANOVA Ã  critÃ¨res multiple, sont obtenus en additionnant les coefficients appropriÃ©s. Puisque, en R, le premier niveau dâ€™une variable catÃ©gorique (facteur) en ordre alphabÃ©tique) est utilisÃ© comme rÃ©fÃ©rence, lâ€™ordonnÃ©e Ã  lâ€™origine (9.776733) est la valeur prÃ©dite pour le logarithme naturel de la frÃ©quence des femelles dans la premiÃ¨re classe dâ€™Ã¢ge (0 to 9). En effet, 9.776733 est approximativement Ã©gal Ã  17619, le nombre observÃ© de femelles dans cette classe dâ€™Ã¢ge.\nPour les mÃ¢les dans la classe dâ€™Ã¢ge 80+, il faut calcule lâ€™antilog du coefficient pour lâ€™ordonnÃ©e Ã  lâ€™origine (pour les femelles dans la premiÃ¨re classe dâ€™Ã¢ge), plus le coefficient pour sexmale (Ã©gal Ã  la diffÃ©rence du log de la frÃ©quence entre les femelles et les mÃ¢les), plus le coefficient pour la classe dâ€™Ã¢ge 80+ qui corresponds Ã  la diffÃ©rence de frÃ©quence entre cette classe dâ€™Ã¢ge et la classe dâ€™Ã¢ge de rÃ©fÃ©rence, plus le coefficient pour lâ€™interaction sexmale:ageclass80+ (qui corresponds Ã  la diffÃ©rence de proportion de mÃ¢les dans cette classe dâ€™Ã¢ge par rapport Ã  la classe dâ€™Ã¢ge de rÃ©fÃ©rence). Ceci donne: ln(frequency)=9.776733-0.004608-1.454582-0.754343=7.5632, et la frÃ©quence est Ã©gale Ã  e 7.5632 =1926\nIl y a de nombreuses valeur p dans ce tableau, mais elle ne sont en gÃ©nÃ©ral pas trÃ¨s utiles. Pour Ã©prouver lâ€™hypothÃ¨se que lâ€™effet du sexe sur la frÃ©quence est identique dans chaque classe dâ€™Ã¢ge (i.e.Â que sexe et Ã¢ge sont indÃ©pendants), vous devez ajuster un modÃ¨le qui exclut cette interaction (sex:ageclass) et dÃ©terminer comment lâ€™ajustement du modÃ¨le est affectÃ©.\nLa fonction Anova() du package car permet de prendre un raccourci:\n\nAnova(mymodel, type = 3, test = \"LR\")\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: frequency\n             LR Chisq Df Pr(&gt;Chisq)    \nsex               0.2  1     0.6657    \nageclass      21074.6  8     &lt;2e-16 ***\nsex:ageclass   1182.2  8     &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLes arguments type=3 and test=\"LR\" font en sorte que le test effectuÃ© pour comparer le modÃ¨le complet aux modÃ¨les rÃ©duits est les test de Chi carrÃ© sur le rapport de vraisemblance (Likelihood Ratio Chi-Square) Ã  partir de la variance rÃ©siduelle, et que câ€™est un test partiel, et non sÃ©quentiel.\nSelon ces tests, il nâ€™y a pas dâ€™effet principal de sex (p=0.667) mais il y a un effet principal de ageclass et une interaction significative sex:ageclass. Lâ€™interaction significative signifie que lâ€™effet du sexe sur la frÃ©quence varie selon les classes dâ€™Ã¢ge, bref que le rapport des sexe varie avec lâ€™Ã¢ge. Lâ€™effet principal de ageclass signifie que la frÃ©quence des individus varie avec lâ€™Ã¢ge dans la population recensÃ©e (i.e.Â que certaines classes dâ€™Ã¢ge sont plus populeuses que dâ€™autres). Lâ€™absence dâ€™un effet principal du sexe suggÃ¨re quâ€™il y a approximativement le mÃªme nombre de mÃ¢les et femelles dans lâ€™Ã©chantillon (quoique, puisquâ€™il y a une interaction, vous devez Ãªtre prudents en faisant cette dÃ©claration. Câ€™est â€œvraiâ€ au total, mais semble incorrect pour certaines classes dâ€™Ã¢ge).",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson</span>"
    ]
  },
  {
    "objectID": "37-model_freq.html#tester-une-hypothÃ¨se-extrinsÃ¨que",
    "href": "37-model_freq.html#tester-une-hypothÃ¨se-extrinsÃ¨que",
    "title": "\n10Â  Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson\n",
    "section": "\n10.5 Tester une hypothÃ¨se extrinsÃ¨que",
    "text": "10.5 Tester une hypothÃ¨se extrinsÃ¨que\nLe test dâ€™indÃ©pendance ci-dessus Ã©prouve une hypothÃ¨se intrinsÃ¨que parce que les proportions utilisÃ©es pour calculer les valeurs attendues et tester lâ€™indÃ©pendance sont celles observÃ©es (i.e.Â la proportion des mÃ¢les et femelles dans tout lâ€™Ã©chantillon, et la proportion des individus dans chaque classe dâ€™Ã¢ge).\nPour Ã©prouver lâ€™hypothÃ¨se (extrinsÃ¨que) que le rapport des sexes est 1:1 pour les individus les plus jeunes (ageclass 0-9), on doit produire le tableau 2X2 des frÃ©quences observÃ©es et attendues. Les frÃ©quences attendues sont obtenues simplement en divisant le total des mÃ¢les et femelles par 2.\nCode R pour crÃ©er et analyser un tableau de contingence 2X2 et Ã©prouver une hypothÃ¨se extrinsÃ¨que\n\n### Produce a table of obs vs exp for 0-9 age class\nPopn0.9 &lt;- rbind(c(17578, 17578), c(17619, 17538))\n### Run X2 test on above table\nchisq.test(Popn0.9, correct = F) ### X2 without Yates\nchisq.test(Popn0.9) ### X2 with Yates\n\n\n\n\n\n\n\nExercice\n\n\n\nÃ‰prouvez lâ€™hypothÃ¨se nulle que la proportion de mÃ¢les et femelles Ã  la naissance est Ã©gale. Que concluez-vous? Croyez-vous que ces donnÃ©es sont appropriÃ©es pour tester cette hypothÃ¨se?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nchisq.test(Popn0.9, correct = F)\n\n\n    Pearson's Chi-squared test\n\ndata:  Popn0.9\nX-squared = 0.093309, df = 1, p-value = 0.76\n\nchisq.test(Popn0.9)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  Popn0.9\nX-squared = 0.088758, df = 1, p-value = 0.7658\n\n\n\n\n\nNotez que pour un tableau 2X2, on devrait utiliser une correction de Yates ou un test de Fisher. Le test de Fisher ne pouvant Ãªtre utilisÃ© lorsque lâ€™Ã©chantillon dÃ©passe 200, on utilise la correction de Yates. Selon cette analyse, on accepte lâ€™hypothÃ¨se nulle que le rapport des sexes est 1:1Ã  la naissance. Ceci dit, ces donnÃ©es ne sont pas trÃ¨s appropriÃ©es pour Ã©prouver lâ€™hypothÃ¨se car la premiÃ¨re classe dâ€™Ã¢ge est trop grossiÃ¨re. Il est possible que le rapport des sexes Ã  la naissance soit diffÃ©rent de 1:1 mais que la mortalitÃ© diffÃ©rentielle des deux sexes compense au cours des 9 premiÃ¨res annÃ©es (par exemple si il y a plus de mÃ¢les Ã  la naissance, mais que les jeunes garÃ§ons ont une survie plus faible au cours de leurs 9 premiÃ¨res annÃ©es). Dans un tel cas, le rapport des sexes nâ€™est PAS de 1:1 Ã  la naissance, mais on accepte lâ€™hypothÃ¨se nulle Ã  partir des donnÃ©es dans la classe dâ€™Ã¢ge 0-9.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson</span>"
    ]
  },
  {
    "objectID": "37-model_freq.html#rÃ©gression-de-poisson-pour-lanalyse-de-tableaux-de-contingence-Ã -plusieurs-critÃ¨res",
    "href": "37-model_freq.html#rÃ©gression-de-poisson-pour-lanalyse-de-tableaux-de-contingence-Ã -plusieurs-critÃ¨res",
    "title": "\n10Â  Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson\n",
    "section": "\n10.6 RÃ©gression de Poisson pour lâ€™analyse de tableaux de contingence Ã  plusieurs critÃ¨res",
    "text": "10.6 RÃ©gression de Poisson pour lâ€™analyse de tableaux de contingence Ã  plusieurs critÃ¨res\nLe principe dâ€™Ã©prouver lâ€™indÃ©pendance en examinant les interactions peut Ãªtre utilisÃ© avec les tableaux de contingence Ã  plusieurs critÃ¨res. Par exemple, examinons si la tempÃ©rature (2 niveaux: base et haute) et lâ€™Ã©clairage (2 niveaux: bas et haut) affectent si des plantes sont infectÃ©es (2 niveaux: infectÃ© et non-infectÃ©) par un pathogÃ¨ne. On peut reprÃ©senter ces donnÃ©es par un tableau de contingence Ã  3 critÃ¨res (tempÃ©rature, lumiÃ¨re, statut dâ€™infection).\nLâ€™ajustement de modÃ¨les log-linÃ©aires Ã  des donnÃ©es de frÃ©quence implique que lâ€™on Ã©prouve plusieurs modÃ¨les en les comparant au modÃ¨le complet (saturÃ©). Une sÃ©rie de modÃ¨les contenant tous les termes sauf une des interactions qui nous intÃ©ressent est produite, et lâ€™ajustement de chaque modÃ¨le est comparÃ© Ã  celui du modÃ¨le complet. Si la rÃ©duction de la qualitÃ© dâ€™ajustement nâ€™est pas significative, cela implique que lâ€™interaction manquante contribue peu Ã  la qualitÃ© de lâ€™ajustement. Par contre, si le modÃ¨le rÃ©duit sâ€™ajuste nettement moins bien aux donnÃ©es, alors lâ€™interaction manquante contribue beaucoup Ã  lâ€™ajustement du modÃ¨le complet. Comme pour les tableaux de contingence 2X2, les termes qui nous intÃ©ressent le plus sont les interactions, pas les effets principaux, si lâ€™on teste pour lâ€™indÃ©pendance des diffÃ©rents facteurs.\nLe fichier loglin.csv contient les frÃ©quences (frequency) des plantes infectÃ©es ou non infectÃ©es (infected) Ã  basse et haute tempÃ©rature (temperature) Ã  basse et haute lumiÃ¨re (light). Pour visualiser ces donnÃ©es et dÃ©terminer si le taux dâ€™infection dÃ©pends de la lumiÃ¨re et de la tempÃ©rature, on peut faire une figure mosaÃ¯que et ajuster un modÃ¨le log-linÃ©aire:\n\nloglin &lt;- read.csv(\"data/loglin.csv\")\n# Convert from frequency form to table form for mosaic plot\nloglinTable &lt;- xtabs(frequency ~ temperature + light + infected, data = loglin)\n# Create mosaic plot to look at data\nmosaic(loglinTable, shade = TRUE)\n\n\n\nProportion de plantes infectÃ©es en fonction de la tempÃ©rature er la lumiÃ¨re\n\n\n\nCette expÃ©rience contrÃ´lÃ©e avec le mÃªme nombre de plantes Ã  chaque niveau de lumiÃ¨re et de tempÃ©rature produit une mosaÃ¯que oÃ¹ la surface occupÃ©e par les observations dans les quatre quadrants est Ã©gale. Ce qui nous intÃ©resse, le taux dâ€™infection par le pathogÃ¨ne, semble varier entre les quadrants (i.e.Â les niveaux de tempÃ©rature et de lumiÃ¨re). Le rectangle rouge dans le coin en bas Ã  gauche indique que le nombre de plantes infectÃ©es Ã  basse tempÃ©rature et haute lumiÃ¨re est plus faible quâ€™attendu si ces deux facteurs nâ€™influencent pas le taux dâ€™infection. MÃªme chose pour les conditions de basse lumiÃ¨re et de haute tempÃ©rature (coin supÃ©rieur droit). La valeur p au bas de lâ€™Ã©chelle reprÃ©sente un test dâ€™indÃ©pendance Ã©quivalent Ã  comparer le modÃ¨le complet au modÃ¨le excluant toutes les interactions et ne contenant que les effets principaux de la tempÃ©rature, la lumiÃ¨re, et le statut dâ€™infection sur le logarithme naturel du nombre dâ€™observations.\n\n# Fit full model\nfull.model &lt;- glm(frequency ~ temperature * light * infected, family = poisson(), data = loglin)\n# Test partial effect of terms in full model\nAnova(full.model, type = 3, test = \"LR\")\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: frequency\n                           LR Chisq Df Pr(&gt;Chisq)    \ntemperature                  9.1786  1  0.0024487 ** \nlight                       13.2829  1  0.0002678 ***\ninfected                     0.0000  1  0.9999999    \ntemperature:light            5.6758  1  0.0172008 *  \ntemperature:infected        29.0612  1  7.013e-08 ***\nlight:infected              20.2687  1  6.729e-06 ***\ntemperature:light:infected   1.0840  1  0.2978126    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLes probabilitÃ©s associÃ©es Ã  chaque terme sont ici calculÃ©es en comparant lâ€™ajustement du modÃ¨le complet Ã  un modÃ¨le qui exclue seulement le terme dâ€™intÃ©rÃªt. Plusieurs des termes sont ici sans vÃ©ritable intÃ©rÃªt puisque les frÃ©quences sont partiellement contrÃ´lÃ©es dans notre expÃ©rience. Puisque la question biologique porte sur le taux dâ€™infection, les seuls termes dâ€™intÃ©rÃªt sont les termes dâ€™interactions qui incluent le statut dâ€™infection (temperature:infected, light:infected et temperature:light:infected.\n\nLâ€™interation significative temperature:infected implique que le taux dâ€™infection nâ€™est pas indÃ©pendant de la tempÃ©rature. Dâ€™ailleurs il est apparent dans la mosaÃ¯que que le taux dâ€™infection (le nombre relatif de plantes infectÃ©es) est supÃ©rieur Ã  haute tempÃ©rature.\nLâ€™interaction significative light:infected implique que le taux dâ€™infection dÃ©pends de la lumiÃ¨re. La mosaÃ¯que illustre que la proportion des plantes infectÃ©es est plus Ã©levÃ©e en basse lumiÃ¨re.\nLâ€™interaction temperature:light:infected nâ€™est pas significative. Cela implique que lâ€™effet de la tempÃ©rature et de la lumiÃ¨re sur le taux dâ€™infection sont indÃ©pendants. Autrement dit, lâ€™effet de la lumiÃ¨re sur le taux dâ€™infection ne dÃ©pends pas de la tempÃ©rature, et vice versa.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson</span>"
    ]
  },
  {
    "objectID": "37-model_freq.html#ex-glm",
    "href": "37-model_freq.html#ex-glm",
    "title": "\n10Â  Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson\n",
    "section": "\n10.7 Exercice",
    "text": "10.7 Exercice\nLe fichier Sturgdat contient les donnÃ©es qui vous permettront dâ€™Ã©prouver lâ€™hypothÃ¨se que le nombre dâ€™esturgeons capturÃ© est indÃ©pendants du site, de lâ€™annÃ©e, et du sexe. Avant de commencer lâ€™analyse, les donnÃ©es devront Ãªtre rÃ©organisÃ©es pour pouvoir ajuster un modÃ¨le log-linÃ©aire:\n\n\n\n\n\n\nExercice\n\n\n\nOuvrez sturgdat.csv, puis utilisez la fonction table() pour obtenir les frÃ©quence dâ€™individus capturÃ©s par sex, location, et year . Sauvegardez ce tableau comme strugdat.table . Faites une figure mosaÃ¯que de ces donnÃ©es.\n\n\n\nsturgdat &lt;- read.csv(\"data/sturgdat.csv\")\n# Reorganize data from case form to table form\nsturgdat.table &lt;- with(sturgdat, table(sex, year, location))\n# display the table\nsturgdat.table\n\n, , location = CUMBERLAND  \n\n              year\nsex            1978 1979 1980\n  FEMALE         10   30   11\n  MALE           14   14    6\n\n, , location = THE_PAS     \n\n              year\nsex            1978 1979 1980\n  FEMALE          5   12   38\n  MALE           16   12   18\n\n# Create data frame while converting from table form to frequency form\nsturgdat.freq &lt;- as.data.frame(sturgdat.table)\n# display data frame\nsturgdat.freq\n\n            sex year     location Freq\n1  FEMALE       1978 CUMBERLAND     10\n2  MALE         1978 CUMBERLAND     14\n3  FEMALE       1979 CUMBERLAND     30\n4  MALE         1979 CUMBERLAND     14\n5  FEMALE       1980 CUMBERLAND     11\n6  MALE         1980 CUMBERLAND      6\n7  FEMALE       1978 THE_PAS         5\n8  MALE         1978 THE_PAS        16\n9  FEMALE       1979 THE_PAS        12\n10 MALE         1979 THE_PAS        12\n11 FEMALE       1980 THE_PAS        38\n12 MALE         1980 THE_PAS        18\n\n# Look at the data as mosaic plot\n# mosaic using the table created above\nmosaic(sturgdat.table, shade = TRUE)\n\n\n\nFrÃ©quence de femelles et males en fonction de lâ€™annÃ©e et du lieu\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nÃ€ partir de ces donnÃ©es en format de frÃ©quence, ajustez le modÃ¨le loglinÃ©aire complet et le tableau dâ€™anova avec les statistique de Chi carrÃ© pour les termes du modÃ¨les. Est-ce que lâ€™interaction triple (location:year:sex) est significative? Est-ce que le rapport des sexes varien entre les sites ou dâ€™une annÃ©e Ã  lâ€™autre?.\n\n\n\n# Fit full model\nfull.model &lt;- glm(Freq ~ sex * year * location, data = sturgdat.freq, family = \"poisson\")\nsummary(full.model)\n\n\nCall:\nglm(formula = Freq ~ sex * year * location, family = \"poisson\", \n    data = sturgdat.freq)\n\nCoefficients:\n                                              Estimate Std. Error z value\n(Intercept)                                    2.30259    0.31623   7.281\nsexMALE                                        0.33647    0.41404   0.813\nyear1979                                       1.09861    0.36515   3.009\nyear1980                                       0.09531    0.43693   0.218\nlocationTHE_PAS                               -0.69315    0.54772  -1.266\nsexMALE        :year1979                      -1.09861    0.52554  -2.090\nsexMALE        :year1980                      -0.94261    0.65498  -1.439\nsexMALE        :locationTHE_PAS                0.82668    0.65873   1.255\nyear1979:locationTHE_PAS                      -0.22314    0.64550  -0.346\nyear1980:locationTHE_PAS                       1.93284    0.64593   2.992\nsexMALE        :year1979:locationTHE_PAS      -0.06454    0.83986  -0.077\nsexMALE        :year1980:locationTHE_PAS      -0.96776    0.87942  -1.100\n                                              Pr(&gt;|z|)    \n(Intercept)                                    3.3e-13 ***\nsexMALE                                        0.41641    \nyear1979                                       0.00262 ** \nyear1980                                       0.82732    \nlocationTHE_PAS                                0.20569    \nsexMALE        :year1979                       0.03658 *  \nsexMALE        :year1980                       0.15011    \nsexMALE        :locationTHE_PAS                0.20950    \nyear1979:locationTHE_PAS                       0.72957    \nyear1980:locationTHE_PAS                       0.00277 ** \nsexMALE        :year1979:locationTHE_PAS       0.93875    \nsexMALE        :year1980:locationTHE_PAS       0.27114    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance:  5.7176e+01  on 11  degrees of freedom\nResidual deviance: -2.6645e-15  on  0  degrees of freedom\nAIC: 77.28\n\nNumber of Fisher Scoring iterations: 3\n\nAnova(full.model, type = 3)\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: Freq\n                  LR Chisq Df Pr(&gt;Chisq)    \nsex                 0.6698  1  0.4131256    \nyear               13.8895  2  0.0009637 ***\nlocation            1.6990  1  0.1924201    \nsex:year            4.6930  2  0.0957024 .  \nsex:location        1.6323  1  0.2013888    \nyear:location      25.2580  2  3.276e-06 ***\nsex:year:location   1.6677  2  0.4343666    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCe tableau a trois critÃ¨res: sex, location et year . Donc le modÃ¨les compelt (saturÃ©) contient 7 termes: trois effets principaux (sex, location et year), trois interactions du second degrÃ© (double) (sex:year, sex:location et year: location) et une interaction du troisiÃ¨me degrÃ© (triple)(sex:year:location). La dÃ©viance nulle est 57.17574, la dÃ©viance rÃ©siduelle du modÃ¨le complet est, sans surprise, 0. La dÃ©viance pouvant Ãªtre attribuÃ©e Ã  lâ€™interaction triple est 1.6677, non significative.\nQuâ€™est ce que cela implique? Sâ€™il y a des interactions doubles, alors elles ne dÃ©pendent pas de la troisiÃ¨me variable. Par exemple, si le rapport des sexe des esturgeons varie dâ€™une annÃ©e Ã  lâ€™autre (une interaction sex:year), alors cette tendance est la mÃªme aux 2 stations.\nPuisquâ€™il nâ€™y a pas dâ€™interaction triple, il est (statistiquement) justifiÃ© de combiner les donnÃ©es pour Ã©prouver les interactions du second degrÃ©. Par exemple, pour tester lâ€™effet sex:location, on peut combiner les annÃ©es. Pour tester lâ€™effet sex:year, on peut combiner les sites. Cette aggrÃ©gation a pour effet dâ€™augmenter la puissance, et est analogue Ã  la stratÃ©gie en ANOVA Ã  critÃ¨res multiples. Lâ€™approche de la rÃ©gression de Poisson permet de faire lâ€™Ã©quivalent simplement en ajustant le modÃ¨le sans lâ€™interaction du troisiÃ¨me degrÃ©.\n\nAjustez le modÃ¨le en excluant lâ€™interaction du troisiÃ¨me degrÃ©:\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\no2int.model &lt;- glm(Freq ~ sex + year + location + sex:year + sex:location + year:location, data = sturgdat.freq, family = \"poisson\")\nAnova(o2int.model, type = 3)\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: Freq\n              LR Chisq Df Pr(&gt;Chisq)    \nsex             1.8691  1  0.1715807    \nyear           15.1289  2  0.0005186 ***\nlocation        1.5444  1  0.2139568    \nsex:year       15.5847  2  0.0004129 ***\nsex:location    2.1762  1  0.1401583    \nyear:location  28.3499  2  6.981e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nLâ€™interaction sex:location nâ€™explique pas une portion significative de la dÃ©viance, alors que les deux autres sont significatives. Le rapport des sexes ne varie pas entre les sites, mais il varie selon les annÃ©es. Lâ€™interaction year:location est aussi significative (voir plus pas pour son interprÃ©tation).\nDevriez vous tenter de simplifier le modÃ¨le encore plus? Les vrais statisticiens sont divisÃ©s sur cette question. Tous sâ€™entendent cependant sur le fait que conserver des interactions non significatives dans un modÃ¨le peut rÃ©duire la puissance. De lâ€™autre cÃ´tÃ©, le retrait des interactions non significatives peut rendre lâ€™interprÃ©tation plus dÃ©licate lorsque les observations ne sont pas bien balancÃ©es (i.e.Â il y a de la colinÃ©aritÃ© entre les termes du modÃ¨le).\n\nAjustez le modÃ¨le sans lâ€™interaction sex:location :\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\no2int.model2 &lt;- glm(Freq ~ sex + year + location + sex:year + year:location, data = sturgdat.freq, family = \"poisson\")\nAnova(o2int.model2, type = 3)\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: Freq\n              LR Chisq Df Pr(&gt;Chisq)    \nsex             5.0970  1  0.0239677 *  \nyear           16.1226  2  0.0003155 ***\nlocation        0.2001  1  0.6546011    \nsex:year       13.9883  2  0.0009173 ***\nyear:location  26.7534  2  1.551e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nLes deux interactions sont significatives et ce modÃ¨le semble le meilleur. Ce modÃ¨le est:\n\\[ln[f_{(ijk)} ] = location + sex + year + sex:year + location:year\\]\nComment ces effets peuvent-ils Ãªtre interprÃ©tÃ©s biologiquement? Souvenez vous que, comme dans les test dâ€™indÃ©pendance, on nâ€™est pas vraiment intÃ©ressÃ© aux effets principaux, seulement par les interactions. Par exemple, lâ€™effet principal de location tnous dit que le nombre total dâ€™esturgeons capturÃ© (le total des 2 sexes pendant les 3 annÃ©es dâ€™Ã©chantillonnage) diffÃ¨re entre les 2 sites. Cela nâ€™est pas vraiment surprenant et peu intÃ©ressant en lâ€™absence dâ€™information sur lâ€™effort de pÃªche. Cependant, lâ€™interaction sex:year nous dit que le rapport des sexes a changÃ© dâ€™une annÃ©e Ã  lâ€™autre. Et puisque lâ€™interaction du troisiÃ¨me degrÃ© nâ€™est pas significative, on sait que ce changement dans le temps est approximativement le mÃªme dans les deux sites. Un rÃ©sultat possiblement intÃ©ressant. Pourquoi? Comme lâ€™expliquer?\nLâ€™interaction location:year nous dit que le nombre dâ€™esturgeons nâ€™a pas seulementt variÃ© dâ€™une annÃ©e Ã  lâ€™autre, mais que la tendance dans le temps diffÃ¨re entre les deux sites. Ceci pourrait reflÃ©ter une diffÃ©rence dâ€™effort de pÃªche Ã  un des sites durant lâ€™une des campagnes dâ€™Ã©chantillonnage, ou un impact Ã  seulement un des deux sites la derniÃ¨re annÃ©e par exemple. Mais cette tendance est la mÃªme pour les mÃ¢les et les femelles (donc nâ€™a pas affectÃ© le rapport des sexes) puisque lâ€™interaction triple nâ€™est pas significative.",
    "crumbs": [
      "DonnÃ©es",
      "ModÃ¨les linÃ©aires",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Analyse de donnÃ©es de frÃ©quence: Tableaux de contingence, modÃ¨les log-linÃ©aires et rÃ©gression de Poisson</span>"
    ]
  },
  {
    "objectID": "901-bibliographie.html",
    "href": "901-bibliographie.html",
    "title": "RÃ©fÃ©rences",
    "section": "",
    "text": "Paquets R\nCe livre a utilisÃ© les paquets R (excluant leurs dÃ©pendances) listÃ© dans le tableau TableÂ 1. Comme recommandÃ© par lâ€™Ã©quipe de de dÃ©veloppement de â€˜tidyverseâ€™, seul le paquets â€˜tidyverseâ€™ est citÃ© et non pas chacun de ses composants.\nTableÂ 1: Paquets utilisÃ©s dans le livre\n\n\n\n\n\n\n\n\n\nPaquets\nVersion\nCitation\n\n\n\nbase\n4.4.1\nR Core Team (2024)\n\n\nboot\n1.3.30\n\nA. C. Davison et D. V. Hinkley (1997); Angelo Canty et B. D. Ripley (2024)\n\n\n\ncar\n3.1.2\nFox et Weisberg (2019a)\n\n\neffects\n4.2.2\n\nFox (2003); Fox et Hong (2009); Fox et Weisberg (2018); Fox et Weisberg (2019b)\n\n\n\nemoji\n15.0\nHvitfeldt (2022)\n\n\ngrateful\n0.2.4\nFrancisco Rodriguez-Sanchez et Connor P. Jackson (2023)\n\n\nknitr\n1.47\n\nXie (2014); Xie (2015); Xie (2024)\n\n\n\nlme4\n1.1.35.3\nBates et al. (2015)\n\n\nlmPerm\n2.1.0\nWheeler et Torchiano (2016)\n\n\nlmtest\n0.9.40\nZeileis et Hothorn (2002)\n\n\nmultcomp\n1.4.25\nHothorn et al. (2008)\n\n\nMuMIn\n1.47.5\nBartoÅ„ (2023)\n\n\nperformance\n0.12.0\nLÃ¼decke et al. (2021)\n\n\npwr\n1.3.0\nChampely (2020)\n\n\nquestionr\n0.7.8\nBarnier et al. (2023)\n\n\nreshape\n0.8.9\n(reshape?)\n\n\nrmarkdown\n2.27\n\nXie et al. (2018); Xie et al. (2020); Allaire et al. (2024)\n\n\n\nsimpleboot\n1.1.7\nPeng (2019)\n\n\ntidyverse\n2.0.0\nWickham et al. (2019)\n\n\nvcd\n1.4.12\n\nMeyer et al. (2006); Zeileis et al. (2007); Meyer et al. (2023)\n\n\n\nvcdExtra\n0.8.5\nFriendly (2023)",
    "crumbs": [
      "DonnÃ©es",
      "RÃ©fÃ©rences"
    ]
  },
  {
    "objectID": "901-bibliographie.html#bibliographie",
    "href": "901-bibliographie.html#bibliographie",
    "title": "RÃ©fÃ©rences",
    "section": "Bibliographie",
    "text": "Bibliographie\n\n\nA. C. Davison, and D. V. Hinkley. 1997. Bootstrap methods and their\napplications. Cambridge University Press, Cambridge.\n\n\nAllaire, J., Y. Xie, C. Dervieux, J. McPherson, J. Luraschi, K. Ushey,\nA. Atkins, H. Wickham, J. Cheng, W. Chang, and R. Iannone. 2024. rmarkdown: Dynamic documents for r.\n\n\nAngelo Canty, and B. D. Ripley. 2024. boot:\nBootstrap r (s-plus) functions.\n\n\nBarnier, J., F. Briatte, and J. Larmarange. 2023. questionr: Functions to make surveys processing\neasier.\n\n\nBartoÅ„, K. 2023. MuMIn:\nMulti-model inference.\n\n\nBates, D., M. MÃ¤chler, B. Bolker, and S. Walker. 2015. Fitting linear\nmixed-effects models using lme4. Journal\nof Statistical Software 67:1â€“48.\n\n\nChampely, S. 2020. pwr: Basic functions for power analysis.\n\n\nDouglas, A. 2023. An introduction to\nr.\n\n\nFox, J. 2003. Effect\ndisplays in R for generalised linear models. Journal of\nStatistical Software 8:1â€“27.\n\n\nFox, J., and J. Hong. 2009. Effect displays in\nR for multinomial and proportional-odds logit models:\nExtensions to the effects package.\nJournal of Statistical Software 32:1â€“24.\n\n\nFox, J., and S. Weisberg. 2018. Visualizing fit and lack of\nfit in complex regression models with predictor effect plots and partial\nresiduals. Journal of Statistical Software 87:1â€“27.\n\n\nFox, J., and S. Weisberg. 2019a. An\nR companion to applied regression. Third. Sage,\nThousand Oaks CA.\n\n\nFox, J., and S. Weisberg. 2019b. An\nr companion to applied regression. 3rd edition. Sage, Thousand Oaks\nCA.\n\n\nFrancisco Rodriguez-Sanchez, and Connor P. Jackson. 2023. grateful: Facilitate citation of r packages.\n\n\nFriendly, M. 2023. vcdExtra: â€œvcdâ€ extensions and additions.\n\n\nHothorn, T., F. Bretz, and P. Westfall. 2008. Simultaneous inference in\ngeneral parametric models. Biometrical Journal 50:346â€“363.\n\n\nHvitfeldt, E. 2022. emoji: Data and function to work with emojis.\n\n\nLÃ¼decke, D., M. S. Ben-Shachar, I. Patil, P. Waggoner, and D. Makowski.\n2021. performance: An R package for\nassessment, comparison and testing of statistical models. Journal of\nOpen Source Software 6:3139.\n\n\nMeyer, D., A. Zeileis, and K. Hornik. 2006. The strucplot framework:\nVisualizing multi-way contingency tables with vcd. Journal of\nStatistical Software 17:1â€“48.\n\n\nMeyer, D., A. Zeileis, K. Hornik, and M. Friendly. 2023. vcd: Visualizing categorical data.\n\n\nPeng, R. D. 2019. simpleboot: Simple bootstrap routines.\n\n\nR Core Team. 2024. R:\nA language and environment for statistical computing. R Foundation\nfor Statistical Computing, Vienna, Austria.\n\n\nWheeler, B., and M. Torchiano. 2016. lmPerm: Permutation tests for linear models.\n\n\nWickham, H., M. Averick, J. Bryan, W. Chang, L. D. McGowan, R. FranÃ§ois,\nG. Grolemund, A. Hayes, L. Henry, J. Hester, M. Kuhn, T. L. Pedersen, E.\nMiller, S. M. Bache, K. MÃ¼ller, J. Ooms, D. Robinson, D. P. Seidel, V.\nSpinu, K. Takahashi, D. Vaughan, C. Wilke, K. Woo, and H. Yutani. 2019.\nWelcome to the tidyverse. Journal of Open Source Software\n4:1686.\n\n\nXie, Y. 2014. knitr: A comprehensive tool\nfor reproducible research in R. in V. Stodden, F.\nLeisch, and R. D. Peng, editors. Implementing reproducible computational\nresearch. Chapman; Hall/CRC.\n\n\nXie, Y. 2015. Dynamic documents with\nR and knitr. 2nd edition. Chapman; Hall/CRC, Boca\nRaton, Florida.\n\n\nXie, Y. 2024. knitr: A general-purpose package for dynamic\nreport generation in r.\n\n\nXie, Y., J. J. Allaire, and G. Grolemund. 2018. R markdown: The definitive\nguide. Chapman; Hall/CRC, Boca Raton, Florida.\n\n\nXie, Y., C. Dervieux, and E. Riederer. 2020. R markdown\ncookbook. Chapman; Hall/CRC, Boca Raton, Florida.\n\n\nZeileis, A., and T. Hothorn. 2002. Diagnostic checking in\nregression relationships. R News 2:7â€“10.\n\n\nZeileis, A., D. Meyer, and K. Hornik. 2007. Residual-based shadings\nfor visualizing (conditional) independence. Journal of Computational\nand Graphical Statistics 16:507â€“525.",
    "crumbs": [
      "DonnÃ©es",
      "RÃ©fÃ©rences"
    ]
  },
  {
    "objectID": "902-donnees.html",
    "href": "902-donnees.html",
    "title": "Annexe A â€” DonnÃ©es utilisÃ©es dans le livre",
    "section": "",
    "text": "check what is done for BIO8940",
    "crumbs": [
      "DonnÃ©es",
      "Annexes",
      "<span class='chapter-number'>A</span>Â  <span class='chapter-title'>DonnÃ©es utilisÃ©es dans le livre</span>"
    ]
  }
]